{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RAG ì„±ëŠ¥ í‰ê°€ ğŸ“Š\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 1. ê°œìš” ë° í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 1.1 RAG í‰ê°€ê°€ ì¤‘ìš”í•œ ì´ìœ \n",
    "\n",
    "**RAG(Retrieval-Augmented Generation)** ì‹œìŠ¤í…œì€ ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ê°ê´€ì ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì²´ê³„ì ì¸ í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### ì£¼ìš” í‰ê°€ ëª©í‘œ:\n",
    "- **ê²€ìƒ‰ í’ˆì§ˆ**: ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì°¾ëŠ”ê°€?\n",
    "- **ìƒì„± í’ˆì§ˆ**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ì˜ í™œìš©í•˜ëŠ”ê°€?\n",
    "- **ì¢…í•© ì„±ëŠ¥**: ì‚¬ìš©ìì—ê²Œ ì–¼ë§ˆë‚˜ ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ”ê°€?\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_evaluation.png\" alt=\"rag\" align=\"center\" border=\"0\"  width=\"1000\" height=auto>\n",
    "</center>\n",
    "\n",
    "[ì¶œì²˜] https://arxiv.org/abs/2405.07437\n",
    "\n",
    "### 1.2 í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# pip install ragas langchain langchain-openai langchain-chroma python-dotenv\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "\n",
    "# LangSmith ì¶”ì  ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "print(f\"LangSmith ì¶”ì : {os.getenv('LANGSMITH_TRACING')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. RAG í‰ê°€ì˜ í•µì‹¬ ê°œë…\n",
    "\n",
    "### 2.1 í‰ê°€ ì°¨ì› (Evaluation Dimensions)\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| í‰ê°€ ì˜ì—­ | ì„¸ë¶€ ì§€í‘œ | ì„¤ëª… |\n",
    "|-----------|-----------|------|\n",
    "| **ê²€ìƒ‰ (Retrieval)** | Context Relevancy | ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ê°€? |\n",
    "|  | Context Recall | ì •ë‹µì— í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ ê²€ìƒ‰ë˜ì—ˆëŠ”ê°€? |\n",
    "| **ìƒì„± (Generation)** | Faithfulness | ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ì„œì— ì¶©ì‹¤í•œê°€? |\n",
    "|  | Answer Relevancy | ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ê°€? |\n",
    "| **ì¢…í•©** | Answer Correctness | ìƒì„±ëœ ë‹µë³€ì´ ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ”ê°€? |\n",
    "\n",
    "</div>\n",
    "\n",
    "### 2.2 í‰ê°€ ë°©ë²•ë¡ \n",
    "\n",
    "#### A. Reference-Free í‰ê°€\n",
    "- **ì¥ì **: ì •ë‹µ ë°ì´í„° ì—†ì´ë„ í‰ê°€ ê°€ëŠ¥\n",
    "- **ë°©ë²•**: LLM-as-Judge ë°©ì‹ í™œìš©\n",
    "- **ë„êµ¬**: RAGAS, LangSmith ë“±\n",
    "\n",
    "#### B. Reference-Based í‰ê°€\n",
    "- **ì¥ì **: ê°ê´€ì ì´ê³  ì¼ê´€ëœ í‰ê°€\n",
    "- **ë°©ë²•**: ì •ë‹µê³¼ ë¹„êµí•˜ì—¬ í‰ê°€\n",
    "- **ì§€í‘œ**: BLEU, ROUGE, Semantic Similarity ë“±\n",
    "\n",
    "---\n",
    "\n",
    "## 3. RAGAS í”„ë ˆì„ì›Œí¬ ì†Œê°œ\n",
    "\n",
    "### 3.1 RAGASë€?\n",
    "\n",
    "**RAGAS (Retrieval-Augmented Generation Assessment)** ëŠ” RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í‰ê°€ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ì£¼ìš” íŠ¹ì§•:\n",
    "- âœ… **Reference-Free**: ì •ë‹µ ì—†ì´ë„ í‰ê°€ ê°€ëŠ¥\n",
    "- âœ… **LLM-as-Judge**: GPT-4 ë“±ì„ í™œìš©í•œ ìë™ í‰ê°€\n",
    "- âœ… **êµ¬ì„±ìš”ì†Œë³„ í‰ê°€**: ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê°œë³„ì ìœ¼ë¡œ í‰ê°€\n",
    "- âœ… **LangChain í†µí•©**: ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ê³¼ ì‰½ê²Œ ì—°ë™\n",
    "\n",
    "### 3.2 RAGAS í•µì‹¬ ì§€í‘œ\n",
    "\n",
    "```python\n",
    "from ragas.metrics import (\n",
    "    context_relevancy,      # ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ì„±\n",
    "    context_recall,         # ì»¨í…ìŠ¤íŠ¸ íšŒìƒë¥ \n",
    "    faithfulness,          # ì¶©ì‹¤ë„\n",
    "    answer_relevancy,      # ë‹µë³€ ê´€ë ¨ì„±\n",
    "    answer_correctness     # ë‹µë³€ ì •í™•ì„±\n",
    ")\n",
    "```\n",
    "\n",
    "#### ì§€í‘œë³„ ìƒì„¸ ì„¤ëª…:\n",
    "\n",
    "1. **Context Relevancy (ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ì„±)**\n",
    "   - ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ì§€ ì¸¡ì •\n",
    "   - ê³„ì‚°ì‹: `ê´€ë ¨ ë¬¸ì¥ ìˆ˜ / ì „ì²´ ë¬¸ì¥ ìˆ˜`\n",
    "\n",
    "2. **Context Recall (ì»¨í…ìŠ¤íŠ¸ ê²€ì¶œë¥ )**\n",
    "   - ì •ë‹µ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ê²€ìƒ‰ë˜ì—ˆëŠ”ì§€ ì¸¡ì •\n",
    "   - ì •ë‹µ(ground truth) í•„ìš”\n",
    "\n",
    "3. **Faithfulness (ì¶©ì‹¤ë„)**\n",
    "   - ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ì„œì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œì§€ ì¸¡ì •\n",
    "   - í™˜ê°(hallucination) ê²€ì¶œì— ì¤‘ìš”\n",
    "\n",
    "4. **Answer Relevancy (ë‹µë³€ ê´€ë ¨ì„±)**\n",
    "   - ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ì§€ ì¸¡ì •\n",
    "\n",
    "5. **Answer Correctness (ë‹µë³€ ì •í™•ì„±)**\n",
    "   - ìƒì„±ëœ ë‹µë³€ì´ ì •ë‹µê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ì¸¡ì •\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ì‹¤ìŠµ 1: ê¸°ë³¸ RAG ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "\n",
    "### 4.1 ë¬¸ì„œ ì¤€ë¹„ ë° ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_documents(file_paths):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    documents = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            loader = TextLoader(path, encoding='utf-8')\n",
    "            documents.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {path}: {e}\")\n",
    "    return documents\n",
    "\n",
    "# ì˜ˆì‹œ: í•œêµ­ì–´ ë¬¸ì„œ ë¡œë“œ\n",
    "korean_files = glob('./data/*_KR.md')\n",
    "documents = load_documents(korean_files)\n",
    "\n",
    "print(f\"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}\")\n",
    "if documents:\n",
    "    print(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:\\n{documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ë¬¸ì„œ ë¶„í•  (Text Splitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ í…ìŠ¤íŠ¸ì— ìµœì í™”ëœ ë¶„í• ê¸° ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    separators=['\\n\\n', '\\n', r'(?<=[.!?])\\s+'],  # ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• \n",
    "    chunk_size=300,           # ì²­í¬ í¬ê¸°\n",
    "    chunk_overlap=0,         # ì¤‘ë³µ ì˜ì—­\n",
    "    is_separator_regex=True,  # ì •ê·œì‹ ì‚¬ìš©\n",
    "    keep_separator=True       # êµ¬ë¶„ì ìœ ì§€\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í•  ì‹¤í–‰\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(split_docs)}\")\n",
    "print(f\"\\nì²« ë²ˆì§¸ ì²­í¬:\")\n",
    "print(f\"ë©”íƒ€ë°ì´í„°: {split_docs[0].metadata}\")\n",
    "print(f\"ë‚´ìš©: {split_docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"rag_evaluation_demo\",\n",
    "    persist_directory=\"./local_chroma_db\",\n",
    "    collection_metadata={'hnsw:space': 'cosine'}  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "print(f\"ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {len(vector_store.get()['ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 RAG ì²´ì¸ êµ¬ì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸\n",
    "    temperature=0,        # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # ìƒìœ„ 5ê°œ ë¬¸ì„œ ê²€ìƒ‰\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. \n",
    "ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "ì»¨í…ìŠ¤íŠ¸:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€:\n",
    "\"\"\")\n",
    "\n",
    "# RAG ì²´ì¸ êµ¬ì„±\n",
    "def format_docs(docs):\n",
    "    \"\"\"ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def rag_chain(question: str) -> dict:\n",
    "    \"\"\"RAG ì²´ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    # 1. ë¬¸ì„œ ê²€ìƒ‰\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    # 2. ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„\n",
    "    context = format_docs(retrieved_docs)\n",
    "    \n",
    "    # 3. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    response = llm.invoke(\n",
    "        prompt_template.format_prompt(\n",
    "            context=context, \n",
    "            question=question\n",
    "        )\n",
    "    ).content\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"answer\": response,\n",
    "        \"retrieved_docs\": retrieved_docs\n",
    "    }\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_question = \"ë¦¬ë¹„ì•ˆì˜ ì„¤ë¦½ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\"\n",
    "result = rag_chain(test_question)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {result['question']}\")\n",
    "print(f\"ë‹µë³€: {result['answer']}\")\n",
    "print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_docs'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±\n",
    "\n",
    "### 5.1 ìˆ˜ë™ ë°ì´í„°ì…‹ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rivian í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±\n",
    "rivian_evaluation_questions = [\n",
    "    {\n",
    "        \"question\": \"Rivianì´ ì„¤ë¦½ëœ ì—°ë„ì™€ ì„¤ë¦½ìëŠ” ëˆ„êµ¬ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì€ 2009ë…„ 6ì›”ì— R. J. ìŠ¤ìºë¦°ì§€ì— ì˜í•´ ì„¤ë¦½ë˜ì—ˆë‹¤. ì²˜ìŒì—ëŠ” Mainstream Motorsë¡œ ì„¤ë¦½ë˜ì—ˆìœ¼ë‚˜ 2011ë…„ì— Rivian Automotiveë¡œ ì‚¬ëª…ì„ ë³€ê²½í–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ ë³¸ì‚¬ëŠ” ì–´ë””ì— ìœ„ì¹˜í•˜ê³  ìˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì˜ ë³¸ì‚¬ëŠ” ë¯¸êµ­ ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼ ì–´ë°”ì¸(Irvine, California)ì— ìœ„ì¹˜í•˜ê³  ìˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ 2023ë…„ ìƒì‚°ëŸ‰ê³¼ ìˆ˜ìµì€ ì–¼ë§ˆì¸ê°€?\",\n",
    "        \"ground_truth\": \"2023ë…„ Rivianì˜ ìƒì‚°ëŸ‰ì€ 57,232ëŒ€ì´ê³ , ìˆ˜ìµì€ 44ì–µ 3ì²œë§Œ ë¯¸êµ­ ë‹¬ëŸ¬ì˜€ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ ì£¼ìš” ì œí’ˆì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì˜ ì£¼ìš” ì œí’ˆì€ ì „ê¸° ìë™ì°¨ì™€ ë°°í„°ë¦¬ì´ë‹¤. ì£¼ìš” ì°¨ëŸ‰ ëª¨ë¸ë¡œëŠ” R1T(í”½ì—… íŠ¸ëŸ­), R1S(SUV), ì „ê¸° ë°°ë‹¬ ë°´(EDV), R2(ì†Œí˜• SUV), R3(ì†Œí˜• SUV) ë“±ì´ ìˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"R1T ëª¨ë¸ì˜ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"R1TëŠ” 4ê°œì˜ ì „ê¸° ëª¨í„°ê°€ ì¥ì°©ëœ í”½ì—… íŠ¸ëŸ­ì´ë‹¤. ë°°í„°ë¦¬ í¬ê¸°ëŠ” 105 kWhì—ì„œ 180 kWhê¹Œì§€ ë‹¤ì–‘í•˜ë©°, 2021ë…„ ë§ì— ë°°ì†¡ì´ ì‹œì‘ë˜ì–´ Rivianì„ ì™„ì „ ì „ê¸° í”½ì—…ì„ ì†Œë¹„ì ì‹œì¥ì— ì¶œì‹œí•œ ìµœì´ˆì˜ ìë™ì°¨ ì œì¡°ì—…ì²´ë¡œ ë§Œë“¤ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ ì£¼ìš” ì œì¡° ê³µì¥ì€ ì–´ë””ì— ìˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì˜ ì£¼ìš” ì œì¡° ê³µì¥ì€ ì¼ë¦¬ë…¸ì´ ì£¼ ë…¸ë©€(Normal, Illinois)ì— ìˆë‹¤. ì´ ê³µì¥ì€ 2017ë…„ì— ì´ì „ Mitsubishi Motors ì œì¡° ê³µì¥ì„ 1,600ë§Œ ë‹¬ëŸ¬ì— ì¸ìˆ˜í•œ ê²ƒìœ¼ë¡œ, ì°¨ëŸ‰ ë¶€í’ˆ ìƒì‚°ê³¼ ì¡°ë¦½ì„ ìˆ˜í–‰í•œë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ IPOëŠ” ì–¸ì œ ì´ë£¨ì–´ì¡Œê³  ì–¼ë§ˆë¥¼ ì¡°ë‹¬í–ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì˜ IPOëŠ” 2021ë…„ 11ì›”ì— ì´ë£¨ì–´ì¡Œìœ¼ë©°, 135ì–µ ë‹¬ëŸ¬ë¥¼ ì¡°ë‹¬í•˜ì—¬ ìƒì¥ íšŒì‚¬ê°€ ë˜ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ 2023ë…„ ìˆœì†ì‹¤ì€ ì–¼ë§ˆì¸ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì˜ 2023ë…„ ìˆœì†ì‹¤ì€ 54ì–µ ë¯¸êµ­ ë‹¬ëŸ¬ì˜€ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"R2 ëª¨ë¸ì˜ ì¶œì‹œ ì˜ˆì •ì¼ì€ ì–¸ì œì¸ê°€?\",\n",
    "        \"ground_truth\": \"R2ëŠ” ë” ì‘ê³  ì €ë ´í•œ SUVë¡œ, ìƒˆë¡œìš´ í”Œë«í¼ì—ì„œ 2026ë…„ ì´ˆì— ì¶œì‹œë  ì˜ˆì •ì´ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ ì¶©ì „ ë„¤íŠ¸ì›Œí¬ ì´ë¦„ì€ ë¬´ì—‡ì´ê³  ì–¸ì œ ì‹œì‘ë˜ì—ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì˜ ì¶©ì „ ë„¤íŠ¸ì›Œí¬ëŠ” Rivian Adventure Networkì´ë‹¤. 2022ë…„ì— ë¯¸êµ­ì—ì„œ ì¶©ì „ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‹œì‘í–ˆìœ¼ë©°, 2024ë…„ì— ë‹¤ë¥¸ ì°¨ëŸ‰ì—ë„ ê°œë°©í–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Volkswagenê³¼ Rivianì˜ íŒŒíŠ¸ë„ˆì‹­ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"2024ë…„ 6ì›”, Volkswagen Groupì€ ì „ê¸° ì•„í‚¤í…ì²˜ ë° ì†Œí”„íŠ¸ì›¨ì–´ ê¸°ìˆ  ê°œë°œì„ ëª©í‘œë¡œ Rivianì— ìµœëŒ€ 50ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•  ì˜í–¥ì„ ë°œí‘œí–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ 2023ë…„ ì§ì› ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€?\",\n",
    "        \"ground_truth\": \"2023ë…„ 12ì›” ê¸°ì¤€ìœ¼ë¡œ Rivianì˜ ì§ì› ìˆ˜ëŠ” 16,790ëª…ì´ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì´ NACS(ë¶ë¯¸ ì¶©ì „ í‘œì¤€)ë¥¼ ì±„íƒí•œë‹¤ê³  ë°œí‘œí•œ ì‹œê¸°ëŠ” ì–¸ì œì¸ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì€ 2023ë…„ 6ì›”ì— Teslaì˜ ë¶ë¯¸ ì¶©ì „ ì‹œìŠ¤í…œ(NACS) ì±„íƒì„ ë°œí‘œí–ˆìœ¼ë©°, 2025ë…„ ëª¨ë¸ ì—°ë„ë¶€í„° ë¶ë¯¸ì—ì„œ ì°¨ëŸ‰ì— NACSë¥¼ ì±„íƒí•  ì˜ˆì •ì´ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Electric Delivery Van (EDV)ì€ ì£¼ë¡œ ì–´ë–¤ ìš©ë„ë¡œ ì„¤ê³„ë˜ì—ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Electric Delivery Van (EDV)ì€ ìƒì—…ìš© ì „ê¸° ë°´ìœ¼ë¡œ, ì£¼ë¡œ Amazonìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ì‚¬ìš©ë˜ê³  ìˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ 2020ë…„ë¶€í„° 2023ë…„ê¹Œì§€ ìˆ˜ìµ ì„±ì¥ì„ ì„¤ëª…í•˜ì‹œì˜¤.\",\n",
    "        \"ground_truth\": \"Rivianì˜ ìˆ˜ìµì€ 2020ë…„ 0ë‹¬ëŸ¬ì—ì„œ ì‹œì‘í•˜ì—¬, 2021ë…„ 5,500ë§Œ ë‹¬ëŸ¬, 2022ë…„ 16ì–µ 5,800ë§Œ ë‹¬ëŸ¬, 2023ë…„ 44ì–µ 3,400ë§Œ ë‹¬ëŸ¬ë¡œ ê¸‰ê²©í•œ ì„±ì¥ì„ ë³´ì˜€ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ ìµœëŒ€ ì£¼ì£¼ë“¤ì€ ëˆ„êµ¬ì¸ê°€?\",\n",
    "        \"ground_truth\": \"2023ë…„ 12ì›” í˜„ì¬ Rivianì˜ ìµœëŒ€ ì£¼ì£¼ëŠ” Amazon, T. Rowe Price International, The Vanguard Group, BlackRock ë° Fidelity Investmentsì˜€ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì´ ì§ë©´í•œ ì£¼ìš” ì†Œì†¡ë“¤ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì€ ì—¬ëŸ¬ ì†Œì†¡ì— ì§ë©´í–ˆë‹¤. 2020ë…„ 7ì›” Teslaê°€ ë…ì  ì •ë³´ ë„ìš©ê³¼ ì§ì› ì˜ì…ì„ ì£¼ì¥í•˜ë©° ì†Œì†¡ì„ ì œê¸°í–ˆê³ , 2021ë…„ 3ì›” Illinois Automobile Dealers Associationì´ ì§ì ‘ íŒë§¤ì— ëŒ€í•´ ì†Œì†¡í–ˆìœ¼ë©°, 2021ë…„ 11ì›” ì „ VP Laura Schwabì´ ì°¨ë³„ í˜ì˜ë¡œ ì†Œì†¡ì„ ì œê¸°í–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì´ 2024ë…„ì— ë°œí‘œí•œ ì¸ë ¥ ê°ì¶• ê³„íšì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"2024ë…„ 2ì›”, Rivianì€ ê¸‰ì—¬ ì§ì› 10% ê°ì¶•ì„ ë°œí‘œí–ˆë‹¤. ì´ì „ì—ë„ 2022ë…„ 7ì›”ì— 6%ì˜ ì¸ë ¥ ê°ì¶•ì„ ë°œí‘œí•œ ë°” ìˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Rivianì˜ ì„œë¹„ìŠ¤ ì§€ì—­ê³¼ ê±°ë˜ì†Œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Rivianì˜ ì„œë¹„ìŠ¤ ì§€ì—­ì€ ë¶ë¯¸ì´ë©°, NASDAQì—ì„œ RIVN í‹°ì»¤ë¡œ ê±°ë˜ë˜ëŠ” ìƒì¥íšŒì‚¬ì´ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"R3 ëª¨ë¸ì— ëŒ€í•´ ì•Œë ¤ì§„ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"R3ëŠ” 2024ë…„ 3ì›”ì— ê³µê°œëœ ì¶œì‹œ ì˜ˆì •ì¸ ì „ê¸° ì†Œí˜• SUVì´ë‹¤. ë” ì‘ì€ ê°€ê²©ëŒ€ì˜ R2 SUVì™€ í•¨ê»˜ ë°œí‘œë˜ì—ˆì§€ë§Œ, êµ¬ì²´ì ì¸ ì¶œì‹œ ì¼ì •ì€ ëª…ì‹œë˜ì§€ ì•Šì•˜ë‹¤.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"ìƒì„±ëœ Rivian í‰ê°€ ì§ˆë¬¸ ìˆ˜: {len(rivian_evaluation_questions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesla í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±\n",
    "tesla_evaluation_questions = [\n",
    "    {\n",
    "        \"question\": \"TeslaëŠ” ì–¸ì œ ëˆ„êµ¬ì— ì˜í•´ ì„¤ë¦½ë˜ì—ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"TeslaëŠ” 2003ë…„ 7ì›” 1ì¼ì— Martin Eberhardì™€ Marc Tarpenningì— ì˜í•´ Tesla Motorsë¡œ ì„¤ë¦½ë˜ì—ˆë‹¤. Nikola Teslaë¥¼ ê¸°ë¦¬ê¸° ìœ„í•´ ëª…ëª…ë˜ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Elon MuskëŠ” ì–¸ì œ Teslaì˜ CEOê°€ ë˜ì—ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Elon MuskëŠ” 2004ë…„ Teslaì˜ ì´ˆê¸° ìê¸ˆ ì¡°ë‹¬ì„ ì£¼ë„í•˜ì—¬ 2008ë…„ 10ì›”ì— CEOê°€ ë˜ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaì˜ ì²« ë²ˆì§¸ ì–‘ì‚° ì°¨ëŸ‰ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Teslaì˜ ì²« ë²ˆì§¸ ì–‘ì‚° ì°¨ëŸ‰ì€ Roadsterë¡œ, 2008ë…„ì— ìƒì‚°ì´ ì‹œì‘ë˜ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Model SëŠ” ì–¸ì œ ì¶œì‹œë˜ì—ˆê³  ì–´ë–¤ íŠ¹ì§•ì´ ìˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Model SëŠ” 2012ë…„ 6ì›”ì— ì¶œì‹œëœ ê³ ê¸‰ ì„¸ë‹¨ì´ë‹¤. ë¦¬í”„íŠ¸ë°± ì°¨ì²´ ìŠ¤íƒ€ì¼ê³¼ ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìœ¼ë©°, ì—¬ëŸ¬ ìë™ì°¨ ìƒì„ ë°›ì•˜ê³  ë…¸ë¥´ì›¨ì´ì™€ ì „ ì„¸ê³„ì—ì„œ ê°€ì¥ ë§ì´ íŒ”ë¦° ì „ê¸° ìë™ì°¨ê°€ ë˜ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"TeslaëŠ” ì–¸ì œ IPOë¥¼ ì§„í–‰í–ˆê³  ì–¼ë§ˆë¥¼ ì¡°ë‹¬í–ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"TeslaëŠ” 2010ë…„ 6ì›” NASDAQì— ìƒì¥í•˜ì—¬ 2ì–µ 2,600ë§Œ ë‹¬ëŸ¬ë¥¼ ì¡°ë‹¬í–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaì˜ ì£¼ìš” ì œì¡° ê³µì¥ë“¤ì€ ì–´ë””ì— ìœ„ì¹˜í•˜ê³  ìˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Teslaì˜ ì£¼ìš” ì œì¡° ê³µì¥ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤: Tesla í”„ë¦¬ëª¬íŠ¸ ê³µì¥(ìº˜ë¦¬í¬ë‹ˆì•„, 2010), Gigafactory ë„¤ë°”ë‹¤(2016), Gigafactory ë‰´ìš•(2017), Gigafactory ìƒí•˜ì´(2019), Gigafactory ë² ë¥¼ë¦°(2022), Gigafactory í…ì‚¬ìŠ¤(2022)ì´ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Model 3ì˜ ê°œë°œê³¼ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Model 3ëŠ” 2016ë…„ 4ì›”ì— ê³µê°œëœ ì¤‘í˜•ì°¨ë¡œ, ì¼ì£¼ì¼ ë§Œì— 325,000ê±´ ì´ìƒì˜ ì˜ˆì•½ì´ ì ‘ìˆ˜ë˜ì—ˆë‹¤. 'ìƒì‚° ì§€ì˜¥'ìœ¼ë¡œ ë¬˜ì‚¬ëœ ìƒì‚° ë¬¸ì œë¡œ ì§€ì—°ì´ ë°œìƒí–ˆì§€ë§Œ, 2018ë…„ ë§ê¹Œì§€ ì„¸ê³„ì—ì„œ ê°€ì¥ ë§ì´ íŒ”ë¦° ì „ê¸° ìë™ì°¨(2018-2021)ê°€ ë˜ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaì˜ í˜„ì¬ ì°¨ëŸ‰ ë¼ì¸ì—…ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"2024ë…„ 11ì›” í˜„ì¬ TeslaëŠ” Model S, Model X, Model 3, Model Y, Semi ë° Cybertruckì˜ 6ê°€ì§€ ì°¨ëŸ‰ ëª¨ë¸ì„ ì œê³µí•œë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Tesla Autopilotì€ ì–¸ì œ ë°œí‘œë˜ì—ˆê³  ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Tesla Autopilotì€ 2014ë…„ì— ë°œí‘œëœ ìš´ì „ì ì§€ì› ì‹œìŠ¤í…œì´ë‹¤. Teslaì—ì„œ ê°œë°œí•œ ê³ ê¸‰ ìš´ì „ì ì§€ì› ì‹œìŠ¤í…œ(ADAS)ìœ¼ë¡œ, ë¶€ë¶„ì ì¸ ì°¨ëŸ‰ ìë™í™”ë¥¼ ì˜ë¯¸í•œë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Tesla EnergyëŠ” ì–´ë–»ê²Œ ì„¤ë¦½ë˜ì—ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Tesla EnergyëŠ” 2016ë…„ 11ì›” Teslaê°€ SolarCityë¥¼ 26ì–µ ë‹¬ëŸ¬ì— ì¸ìˆ˜í•˜ì—¬ ì„¤ë¦½ë˜ì—ˆë‹¤. íƒœì–‘ ì—ë„ˆì§€ ìƒì„± ì‹œìŠ¤í…œê³¼ ë°°í„°ë¦¬ ì—ë„ˆì§€ ì €ì¥ ì œí’ˆì„ ê°œë°œ, êµ¬ì¶•, íŒë§¤ ë° ì„¤ì¹˜í•œë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaì˜ ì¶©ì „ ë„¤íŠ¸ì›Œí¬ëŠ” ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Teslaì˜ ì¶©ì „ ë„¤íŠ¸ì›Œí¬ëŠ” Supercharger ë„¤íŠ¸ì›Œí¬ì™€ Destination ì¶©ì „ ìœ„ì¹˜ ë„¤íŠ¸ì›Œí¬ê°€ ìˆë‹¤. SuperchargerëŠ” 2012ë…„ì— ë„ì…ëœ ê³ ì „ì•• DC ê¸‰ì† ì¶©ì „ ë„¤íŠ¸ì›Œí¬ì´ê³ , Destination ì¶©ì „ì€ í˜¸í…”, ë ˆìŠ¤í† ë‘ ë° ì‡¼í•‘ ì„¼í„°ì— ìˆëŠ” ë” ëŠë¦° ì¶©ì „ê¸°ì´ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Model YëŠ” ì–¸ì œ ì¶œì‹œë˜ì—ˆê³  ì–´ë–¤ íŠ¹ì§•ì´ ìˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Model YëŠ” 2019ë…„ 3ì›”ì— ì†Œê°œëœ ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤ë²„ SUVë¡œ, ë°°ì†¡ì€ 2020ë…„ 3ì›”ì— ì‹œì‘ë˜ì—ˆë‹¤. ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ë©°, ê³ ê¸‰ Model X SUVë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"TeslaëŠ” 2023ë…„ì— ë°°í„°ë¦¬ ì „ê¸° ìë™ì°¨ ì‹œì¥ì—ì„œ ëª‡ í¼ì„¼íŠ¸ì˜ ì ìœ ìœ¨ì„ ì°¨ì§€í–ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"2023ë…„ì— TeslaëŠ” ë°°í„°ë¦¬ ì „ê¸° ìë™ì°¨ ì‹œì¥ì—ì„œ ê°€ì¥ í° ì ìœ ìœ¨ì¸ 19.9%ë¥¼ ì°¨ì§€í–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Semi íŠ¸ëŸ­ì˜ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Tesla SemiëŠ” í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•œë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡Œë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Cybertruckì€ ì–¸ì œ ë°œí‘œë˜ê³  ë°°ì†¡ì´ ì‹œì‘ë˜ì—ˆëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"Cybertruckì€ 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­ìœ¼ë¡œ, 2023ë…„ 11ì›”ì— ë°°ì†¡ì´ ì‹œì‘ë˜ì—ˆë‹¤. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µëœë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaê°€ Bitcoinì— íˆ¬ìí•œ ì‹œê¸°ì™€ ê·œëª¨ëŠ” ì–´ë–»ê²Œ ë˜ëŠ”ê°€?\",\n",
    "        \"ground_truth\": \"2021ë…„ ì´ˆ, TeslaëŠ” Bitcoinì— 15ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí–ˆë‹¤. í™˜ê²½ ë¬¸ì œë¡œ ì¸í•´ ì ì‹œ ê²°ì œ ìˆ˜ë‹¨ìœ¼ë¡œ í—ˆìš©í•˜ë‹¤ê°€ ì¤‘ë‹¨í–ˆìœ¼ë©°, 2022ë…„ 7ì›”ê¹Œì§€ Bitcoin ë³´ìœ ëŸ‰ì˜ ì•½ 75%ë¥¼ ë§¤ê°í–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"ë¶ë¯¸ ì¶©ì „ í‘œì¤€(NACS)ì´ë€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"ë¶ë¯¸ ì¶©ì „ í‘œì¤€(NACS)ì€ Teslaì—ì„œ ê°œë°œí•œ ì „ê¸° ìë™ì°¨ ì¶©ì „ ì»¤ë„¥í„° ì‹œìŠ¤í…œì´ë‹¤. 2023ë…„ 5ì›”ê³¼ 2024ë…„ 2ì›” ì‚¬ì´ì— ë¶ë¯¸ EV ì œì¡°ì—…ì²´ë“¤ì´ Teslaì˜ ë¶ë¯¸ ì¶©ì „ í‘œì¤€ìœ¼ë¡œ ì „í™˜í•  ê³„íšì„ ë°œí‘œí–ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaì˜ ë¡œë´‡ ê³µí•™ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"TeslaëŠ” ëŒ€í˜• ì£¼ì¡° ê¸°ê³„(Giga Press)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í˜• ë‹¨ì¼ í”¼ìŠ¤ í•˜ì²´ë¥¼ ë§Œë“ ë‹¤. ë˜í•œ 2022ë…„ë¶€í„° Optimusë¼ëŠ” íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì„ ê°œë°œí•´ ì™”ë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Teslaì˜ ì „ëµì€ ë°°í„°ë¦¬ ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ê³ ê°€, ì†ŒëŸ‰ ì°¨ëŸ‰ìœ¼ë¡œ ì‹œì‘í•œ ë‹¤ìŒ ë” ì €ë ´í•˜ê³  ëŒ€ëŸ‰ ì°¨ëŸ‰ì„ ì œê³µí•˜ëŠ” ê²ƒì´ë‹¤. TeslaëŠ” ìë™ì°¨ì˜ í•˜ë“œì›¨ì–´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê³  ì›¹ì‚¬ì´íŠ¸ì™€ íšŒì‚¬ ì†Œìœ  ë§¤ì¥ì„ í†µí•´ ì§ì ‘ ì°¨ëŸ‰ì„ íŒë§¤í•˜ë©°, ìˆ˜ì§ì ìœ¼ë¡œ í†µí•©ë˜ì–´ ë§ì€ êµ¬ì„± ìš”ì†Œë¥¼ ìì²´ ê°œë°œí•œë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Teslaê°€ ìµœê·¼ ë°œí‘œí•œ ë¯¸ë˜ ì°¨ëŸ‰ë“¤ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "        \"ground_truth\": \"Teslaê°€ ìµœê·¼ ë°œí‘œí•œ ë¯¸ë˜ ì°¨ëŸ‰ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤: Roadster 2ì„¸ëŒ€(2025ë…„ ì¶œì‹œ ì˜ˆì •), Tesla ì°¨ì„¸ëŒ€ ì°¨ëŸ‰(2025ë…„ ìƒë°˜ê¸° ë°°ì†¡ ì˜ˆì •), Cybercab(2026ë…„ ì¶œì‹œ ì˜ˆì •ì¸ 2ì¸ìŠ¹ ììœ¨ ì£¼í–‰ì°¨), Robovan(ë¯¸ë˜ ê°œë°œì„ ìœ„í•´ ê³„íšëœ ì „ê¸° ììœ¨ ë°´)ì´ë‹¤.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"ìƒì„±ëœ Tesla í‰ê°€ ì§ˆë¬¸ ìˆ˜: {len(tesla_evaluation_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 RAGAS ìë™ ë°ì´í„°ì…‹ ìƒì„±\n",
    "\n",
    "- uv add rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.persona import Persona\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# LLMê³¼ ì„ë² ë”© ë˜í¼ ì„¤ì •\n",
    "generator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.2)\n",
    ")\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(\n",
    "    OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# í•œêµ­ì–´ í˜ë¥´ì†Œë‚˜ ì •ì˜ (ë” ìƒì„¸í•˜ê²Œ)\n",
    "personas = [\n",
    "    Persona(\n",
    "        name=\"graduate_researcher\",\n",
    "        role_description=\"\"\"ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì„ ì—°êµ¬í•˜ëŠ” í•œêµ­ì¸ ë°•ì‚¬ê³¼ì • ì—°êµ¬ì›ì…ë‹ˆë‹¤. \n",
    "        ì „ê¸°ì°¨ ì •ì±…, ì‹œì¥ ë™í–¥, ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” ë¶„ì„ì  ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤. \n",
    "        í•™ìˆ ì  ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë©° ë°ì´í„°ì™€ ê·¼ê±°ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œë§Œ ì†Œí†µí•©ë‹ˆë‹¤.\"\"\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"masters_student\",\n",
    "        role_description=\"\"\"ì „ê¸°ì°¨ ì‚°ì—…ì„ ê³µë¶€í•˜ëŠ” í•œêµ­ì¸ ì„ì‚¬ê³¼ì • í•™ìƒì…ë‹ˆë‹¤. \n",
    "        ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì˜ ê¸°ì´ˆ ê°œë…ê³¼ íŠ¸ë Œë“œë¥¼ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ë©°, \n",
    "        ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…ì„ ì„ í˜¸í•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œë§Œ ì†Œí†µí•©ë‹ˆë‹¤.\"\"\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"industry_analyst\",\n",
    "        role_description=\"\"\"í•œêµ­ ìë™ì°¨ íšŒì‚¬ì—ì„œ ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì„ ë¶„ì„í•˜ëŠ” ì£¼ë‹ˆì–´ ì—°êµ¬ì›ì…ë‹ˆë‹¤. \n",
    "        ì‹¤ë¬´ì ì¸ ì‹œì¥ ë°ì´í„°, ê²½ìŸì‚¬ ë™í–¥, ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ì— ê´€ì‹¬ì´ ë§ìœ¼ë©°, \n",
    "        ì‹¤í–‰ ê°€ëŠ¥í•œ ì •ë³´ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œë§Œ ì†Œí†µí•©ë‹ˆë‹¤.\"\"\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"policy_researcher\",\n",
    "        role_description=\"\"\"í•œêµ­ ì •ë¶€ê¸°ê´€ì—ì„œ ì „ê¸°ì°¨ ì •ì±…ì„ ì—°êµ¬í•˜ëŠ” ì—°êµ¬ì›ì…ë‹ˆë‹¤. \n",
    "        ë¯¸êµ­ì˜ ì „ê¸°ì°¨ ê´€ë ¨ ì •ì±…, ì¸ì„¼í‹°ë¸Œ, ê·œì œì— ëŒ€í•´ ê´€ì‹¬ì´ ë§ìœ¼ë©°, \n",
    "        í•œêµ­ ì •ì±…ì— ì ìš© ê°€ëŠ¥í•œ ì‹œì‚¬ì ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ë¡œë§Œ ì†Œí†µí•©ë‹ˆë‹¤.\"\"\",\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "\n",
    "# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ì˜ì–´ ë²„ì „) í™•ì¸\n",
    "synthesizer = SingleHopSpecificQuerySynthesizer(llm=generator_llm)\n",
    "\n",
    "synthesizer.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜\n",
    "korean_prompts = await synthesizer.adapt_prompts(\n",
    "    language=\"korean\", \n",
    "    llm=generator_llm\n",
    ")\n",
    "synthesizer.set_prompts(**korean_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(korean_prompts['query_answer_generation_prompt'].instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.multi_hop.specific import MultiHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.multi_hop.abstract import MultiHopAbstractQuerySynthesizer\n",
    "\n",
    "\n",
    "async def create_korean_query_distribution():\n",
    "    \"\"\"í•œêµ­ì–´ ìµœì í™”ëœ Query Distribution ìƒì„±\"\"\"\n",
    "    \n",
    "    # Query Synthesizerë“¤ì„ í•œêµ­ì–´ë¡œ ì ì‘\n",
    "    synthesizers = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.6),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.2),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.2)\n",
    "    ]\n",
    "    \n",
    "    # ê° synthesizerì˜ í”„ë¡¬í”„íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì ì‘\n",
    "    korean_query_distribution = []\n",
    "    for synthesizer, weight in synthesizers:\n",
    "        try:\n",
    "            # í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ ì ì‘\n",
    "            korean_prompts = await synthesizer.adapt_prompts(\n",
    "                language=\"korean\", \n",
    "                llm=generator_llm\n",
    "            )\n",
    "            synthesizer.set_prompts(**korean_prompts)\n",
    "            print(f\"{synthesizer.__class__.__name__} í•œêµ­ì–´ ì ì‘ ì™„ë£Œ\")\n",
    "            korean_query_distribution.append((synthesizer, weight))\n",
    "        except Exception as e:\n",
    "            print(f\"{synthesizer.__class__.__name__} í•œêµ­ì–´ ì ì‘ ì‹¤íŒ¨: {e}\")\n",
    "            # ì ì‘ì— ì‹¤íŒ¨í•´ë„ ì›ë³¸ synthesizerëŠ” í¬í•¨\n",
    "            korean_query_distribution.append((synthesizer, weight))\n",
    "    \n",
    "    return korean_query_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestsetGenerator ì´ˆê¸°í™” (ê¸°ë³¸ êµ¬ì„±)\n",
    "testset_generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    persona_list=personas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•©ì„± ë°ì´í„°ì…‹ ìƒì„±\n",
    "async def generate_korean_testset(split_docs, testset_size=60):\n",
    "    \"\"\"í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±\"\"\"\n",
    "    \n",
    "    # 1. í•œêµ­ì–´ ì ì‘ëœ Query Distribution ìƒì„±\n",
    "    korean_query_distribution = await create_korean_query_distribution()\n",
    "        \n",
    "    # 2. í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± (query_distribution ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©)\n",
    "    synthetic_dataset = testset_generator.generate_with_langchain_docs(\n",
    "        documents=split_docs,\n",
    "        testset_size=testset_size,\n",
    "        query_distribution=korean_query_distribution  # ì˜¬ë°”ë¥¸ ë§¤ê°œë³€ìˆ˜\n",
    "    )\n",
    "    \n",
    "    return synthetic_dataset\n",
    "\n",
    "\n",
    "synthetic_dataset = await generate_korean_testset(split_docs, testset_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ í™•ì¸\n",
    "df = synthetic_dataset.to_pandas()\n",
    "print(f\"ìƒì„±ëœ í•©ì„± ë°ì´í„°ì…‹ í¬ê¸°: {len(df)}\")\n",
    "print(f\"\\nì»¬ëŸ¼: {list(df.columns)}\")\n",
    "print(f\"\\nì²« ë²ˆì§¸ ìƒ˜í”Œ:\")\n",
    "print(f\"ì§ˆë¬¸: {df.iloc[0]['user_input']}\")\n",
    "print(f\"ì •ë‹µ: {df.iloc[0]['reference']}\")\n",
    "\n",
    "# CSVë¡œ ì €ì¥\n",
    "df.to_csv('./data/synthetic_testset.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 í‰ê°€ìš© ë°ì´í„°ì…‹ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "def create_evaluation_dataset(questions_data, rag_chain_func):\n",
    "    \"\"\"í‰ê°€ìš© ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    evaluation_data = []\n",
    "    \n",
    "    # ê° ì§ˆë¬¸ì— ëŒ€í•´ RAG ì²´ì¸ì„ ì‹¤í–‰í•˜ê³  í‰ê°€ ë°ì´í„° êµ¬ì„±\n",
    "    for item in questions_data:\n",
    "        if \"question\" in item: # ìˆ˜ë™ ë°ì´í„°ì…‹ì˜ ê²½ìš°\n",
    "            question = item[\"question\"]\n",
    "            ground_truth = item.get(\"ground_truth\", \"\")\n",
    "        else: # í•©ì„± ë°ì´í„°ì…‹ì˜ ê²½ìš°\n",
    "            question = item[\"user_input\"]\n",
    "            ground_truth = item[\"reference\"]\n",
    "\n",
    "        # RAG ì²´ì¸ ì‹¤í–‰\n",
    "        result = rag_chain_func(question)\n",
    "        \n",
    "        # í‰ê°€ ë°ì´í„° êµ¬ì„±\n",
    "        eval_sample = {\n",
    "            \"user_input\": question,\n",
    "            \"response\": result[\"answer\"],\n",
    "            \"retrieved_contexts\": [doc.page_content for doc in result[\"retrieved_docs\"]],\n",
    "            \"reference\": ground_truth\n",
    "        }\n",
    "        \n",
    "        evaluation_data.append(eval_sample)\n",
    "        \n",
    "        print(f\"ì²˜ë¦¬ ì™„ë£Œ: {question[:50]}...\")\n",
    "    \n",
    "    return EvaluationDataset.from_list(evaluation_data)\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„ : ì˜µì…˜ 1 - ìˆ˜ë™ ë°ì´í„°ì…‹ ì‚¬ìš©\n",
    "# evaluation_questions = rivian_evaluation_questions + tesla_evaluation_questions\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„ : ì˜µì…˜ 2 - í•©ì„± ë°ì´í„°ì…‹ ì‚¬ìš©\n",
    "evaluation_questions = synthetic_dataset.to_list()  # í•©ì„± ë°ì´í„°ì…‹ì„ í‰ê°€ ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ìš©\n",
    "\n",
    "print(f\"ì´ {len(evaluation_questions)}ê°œì˜ í‰ê°€ ì§ˆë¬¸ì´ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±\n",
    "eval_dataset = create_evaluation_dataset(evaluation_questions, rag_chain) \n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í™•ì¸\n",
    "eval_df = eval_dataset.to_pandas()\n",
    "print(f\"\\ní‰ê°€ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ:\")\n",
    "print(f\"- ìƒ˜í”Œ ìˆ˜: {len(eval_df)}\")\n",
    "print(f\"- ì»¬ëŸ¼: {list(eval_df.columns)}\")\n",
    "\n",
    "# ì €ì¥\n",
    "eval_df.to_csv('./data/evaluation_dataset.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ì‹¤ìŠµ 3: RAGAS í‰ê°€ ìˆ˜í–‰\n",
    "\n",
    "### 6.1 ê¸°ë³¸ í‰ê°€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    LLMContextRecall,\n",
    "    Faithfulness, \n",
    "    AnswerRelevancy,\n",
    "    ContextPrecision,\n",
    "    FactualCorrectness\n",
    ")\n",
    "\n",
    "# í‰ê°€ìš© LLM ì„¤ì •\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    ")\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ ì„ íƒ\n",
    "metrics = [\n",
    "    LLMContextRecall(llm=evaluator_llm),           # ì»¨í…ìŠ¤íŠ¸ ê²€ì¶œìœ¨\n",
    "    Faithfulness(llm=evaluator_llm),               # ì¶©ì‹¤ë„\n",
    "    AnswerRelevancy(llm=evaluator_llm),            # ë‹µë³€ ê´€ë ¨ì„±\n",
    "    ContextPrecision(llm=evaluator_llm),           # ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„\n",
    "    FactualCorrectness(llm=evaluator_llm)          # ì‚¬ì‹¤ì  ì •í™•ì„±\n",
    "]\n",
    "\n",
    "print(\"RAGAS í‰ê°€ ì‹œì‘...\")\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "results = evaluate(\n",
    "    dataset=eval_dataset[:10],  # ì²˜ìŒ 10ê°œ ìƒ˜í”Œë¡œ í‰ê°€ (í…ŒìŠ¤íŠ¸ ëª©ì )\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=generator_embeddings\n",
    ")\n",
    "\n",
    "print(\"í‰ê°€ ì™„ë£Œ!\")\n",
    "print(f\"\\nì „ì²´ í‰ê°€ ê²°ê³¼:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ìƒì„¸ ê²°ê³¼ ë¶„ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "results_df = results.to_pandas()\n",
    "\n",
    "print(f\"\\nìƒì„¸ í‰ê°€ ê²°ê³¼:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ê° ìƒ˜í”Œë³„ ìƒì„¸ ê²°ê³¼\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"\\n[ìƒ˜í”Œ {idx+1}]\")\n",
    "    print(f\"ì§ˆë¬¸: {row['user_input'][:100]}...\")\n",
    "    print(f\"ë‹µë³€: {row['response'][:100]}...\")\n",
    "    \n",
    "    # ì§€í‘œë³„ ì ìˆ˜ ì¶œë ¥\n",
    "    for col in results_df.columns:\n",
    "        if col not in ['user_input', 'response', 'retrieved_contexts', 'reference']:\n",
    "            if pd.notna(row[col]):\n",
    "                print(f\"  {col}: {row[col]:.3f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í†µê³„ ìš”ì•½\n",
    "print(f\"\\nğŸ“Š í‰ê°€ ì§€í‘œ í†µê³„:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "numeric_columns = results_df.select_dtypes(include=[np.number]).columns \n",
    "summary_stats = results_df[numeric_columns].describe()\n",
    "\n",
    "for metric in numeric_columns:\n",
    "    mean_score = summary_stats.loc['mean', metric]\n",
    "    std_score = summary_stats.loc['std', metric]\n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  í‰ê· : {mean_score:.3f} (Â±{std_score:.3f})\")\n",
    "    print(f\"  ë²”ìœ„: {summary_stats.loc['min', metric]:.3f} ~ {summary_stats.loc['max', metric]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ë©”íŠ¸ë¦­ë³„ í•µì‹¬ í‰ê°€ ìš”ì†Œ\n",
    "\n",
    "| ë©”íŠ¸ë¦­ | í‰ê°€ ëŒ€ìƒ | í•µì‹¬ ì§ˆë¬¸ | ì •ì˜ |\n",
    "|--------|-----------|-----------|------|\n",
    "| **LLMContextRecall** | ê²€ìƒ‰ í’ˆì§ˆ | \"í•„ìš”í•œ ì •ë³´ê°€ ì˜ ê²€ìƒ‰ë˜ì—ˆëŠ”ê°€?\" | ì°¸ì¡° ë‹µë³€(reference)ì˜ ì£¼ì¥ë“¤ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ì˜í•´ ì–¼ë§ˆë‚˜ ì˜ ì§€ì›ë˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **Faithfulness** | ìƒì„± í’ˆì§ˆ | \"ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ì¶©ì‹¤í•œê°€?\" | ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œì§€(ì¼ì¹˜í•˜ëŠ”ì§€) ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **AnswerRelevancy** | ë‹µë³€ í’ˆì§ˆ | \"ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?\" | ìƒì„±ëœ ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **ContextPrecision** | ê²€ìƒ‰ ì •ë°€ë„ | \"ê²€ìƒ‰ëœ ê²ƒë“¤ì´ ì‹¤ì œë¡œ ìœ ìš©í•œê°€?\" | ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì¤‘ ì§ˆë¬¸ê³¼ ì‹¤ì œë¡œ ê´€ë ¨ëœ ê²ƒë“¤ì˜ ë¹„ìœ¨ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |\n",
    "| **FactualCorrectness** | ì‚¬ì‹¤ ì •í™•ì„± | \"ë‹µë³€ì´ ì‚¬ì‹¤ì ìœ¼ë¡œ ì •í™•í•œê°€?\" | ìƒì„±ëœ ì‘ë‹µê³¼ ì°¸ì¡° ë‹µë³€ ê°„ì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥\n",
    "results_df.to_csv('./data/ragas_evaluation_results.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kt-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
