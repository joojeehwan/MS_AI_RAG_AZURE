{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이브리드 검색(Hybrid Search)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 개념 이해\n",
    "\n",
    "### 1.1 검색 방식 분류\n",
    "\n",
    "#### 🔍 **의미론적 검색 (Semantic Search)**\n",
    "- **정의**: 벡터 임베딩을 활용한 의미 기반 검색\n",
    "- **특징**: \n",
    "  - 동의어와 문맥적 의미를 파악\n",
    "  - 자연어 질의에 효과적\n",
    "  - 유사도 기반 매칭\n",
    "- **장점**: 의미적 연관성이 높은 문서 검색\n",
    "- **단점**: 정확한 키워드 매칭 약함\n",
    "\n",
    "#### 🔍 **키워드 검색 (Keyword Search)**\n",
    "- **정의**: BM25 알고리즘 기반 키워드 매칭 검색\n",
    "- **특징**:\n",
    "  - 직접적인 단어/구문 매칭\n",
    "  - 계산 효율성 높음\n",
    "  - 전통적인 정보검색 방식\n",
    "- **장점**: 정확한 키워드 매칭, 빠른 처리 속도\n",
    "- **단점**: 의미적 유사성 파악 제한적\n",
    "\n",
    "#### 🔍 **하이브리드 검색 (Hybrid Search)**\n",
    "- **정의**: 키워드 검색과 의미론적 검색의 결합\n",
    "- **특징**:\n",
    "  - EnsembleRetriever를 통한 구현\n",
    "  - 가중치 조정으로 성능 최적화\n",
    "  - 두 검색 방식의 시너지 효과\n",
    "- **장점**: 포괄적이고 정확한 검색 결과\n",
    "- **단점**: 구현 복잡도 증가, 계산 비용 상승\n",
    "\n",
    "### 1.2 BM25 알고리즘 이해\n",
    "\n",
    "BM25는 TF-IDF의 확장된 버전으로, 다음 공식을 사용합니다:\n",
    "\n",
    "```markdown\n",
    "BM25(qi, D) = IDF(qi) × (f(qi, D) × (k1 + 1)) / (f(qi, D) + k1 × (1 - b + b × |D| / avgdl))\n",
    "```\n",
    "\n",
    "- `f(qi, D)`: 문서 D에서 단어 qi의 빈도\n",
    "- `|D|`: 문서 D의 길이\n",
    "- `avgdl`: 평균 문서 길이\n",
    "- `k1, b`: 조정 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 환경 설정\n",
    "\n",
    "### 2.1 필수 라이브러리 설치\n",
    "\n",
    "```bash\n",
    "# 기본 라이브러리\n",
    "pip install langchain langchain-community langchain-openai\n",
    "pip install langchain-chroma\n",
    "\n",
    "# 검색 및 평가 라이브러리\n",
    "pip install rank_bm25 kiwipiepy\n",
    "pip install ranx ranx-k\n",
    "\n",
    "# 데이터 처리\n",
    "pip install pandas numpy matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 기본 라이브러리 Import\n",
    "- uv pip install ranx-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # 한글 폰트 인식 - Windows\n",
    "# import matplotlib \n",
    "# font_name = matplotlib.font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "# matplotlib.rc('font', family=font_name)\n",
    "\n",
    "# 한글 폰트 인식 - Mac\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='AppleGothic')\n",
    "\n",
    "# 마이너스 부호 인식\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)\n",
    "\n",
    "# LangChain 핵심\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 데이터 처리\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 한국어 처리\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# 평가\n",
    "import ranx\n",
    "import ranx_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 데이터 준비\n",
    "\n",
    "### 3.1 텍스트 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_files(file_patterns):\n",
    "    \"\"\"\n",
    "    다양한 형식의 텍스트 파일을 로드\n",
    "    \n",
    "    Args:\n",
    "        file_patterns (list): 파일 패턴 리스트\n",
    "    \n",
    "    Returns:\n",
    "        list: Document 객체 리스트\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for pattern in file_patterns:\n",
    "        files = glob(pattern)\n",
    "        for file_path in files:\n",
    "            try:\n",
    "                loader = TextLoader(file_path, encoding='utf-8')\n",
    "                docs = loader.load()\n",
    "                documents.extend(docs)\n",
    "                print(f\"✅ {file_path} 로드 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {file_path} 로드 실패: {e}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# 로드할 문서의 패턴 정의\n",
    "# 예시: 'data/*.txt', 'data/*.json' 등\n",
    "# 현재는 'data/*_KR.md' 패턴만 사용\n",
    "file_patterns = [\n",
    "    'data/*_KR.md',\n",
    "    # 'data/*.txt',\n",
    "    # 'data/*.json'\n",
    "]\n",
    "raw_documents = load_text_files(file_patterns)\n",
    "print(f\"총 {len(raw_documents)}개 문서 로드됨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 문서 분할 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_splitter():\n",
    "    \"\"\"\n",
    "    한국어 최적화된 텍스트 분할기 생성\n",
    "    \"\"\"\n",
    "    return RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        encoding_name=\"cl100k_base\",\n",
    "        separators=['\\n\\n', '\\n', r'(?<=[.!?])\\s+'],\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        is_separator_regex=True,\n",
    "        keep_separator=True,\n",
    "    )\n",
    "\n",
    "def preprocess_documents(documents, company_mapping=None):\n",
    "    \"\"\"\n",
    "    문서 전처리 및 메타데이터 추가\n",
    "    \n",
    "    Args:\n",
    "        documents (list): 원본 문서 리스트\n",
    "        company_mapping (dict): 회사명 매핑 정보\n",
    "    \n",
    "    Returns:\n",
    "        list: 전처리된 Document 객체 리스트\n",
    "    \"\"\"\n",
    "    text_splitter = create_text_splitter()\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    processed_docs = []\n",
    "    for chunk in chunks:\n",
    "        # 메타데이터 추가\n",
    "        source_file = chunk.metadata.get('source', '')\n",
    "        \n",
    "        # 회사명 추출\n",
    "        if company_mapping:\n",
    "            company = 'unknown'\n",
    "            for keyword, name in company_mapping.items():\n",
    "                if keyword in source_file.lower():\n",
    "                    company = name\n",
    "                    break\n",
    "        else:\n",
    "            company = 'default'\n",
    "        \n",
    "        # Document 객체 생성\n",
    "        doc = Document(\n",
    "            page_content=f\"<Document>\\n{chunk.page_content}\\n</Document>\\n<Source>이 문서는 '{company}'에 대한 문서입니다.</Source>\",\n",
    "            metadata={\n",
    "                **chunk.metadata,\n",
    "                'company': company,\n",
    "                'language': 'ko',\n",
    "                'chunk_length': len(chunk.page_content)\n",
    "            }\n",
    "        )\n",
    "        processed_docs.append(doc)\n",
    "    \n",
    "    return processed_docs\n",
    "\n",
    "# 회사명 매핑 정보\n",
    "# 예시: 'tesla' -> '테슬라', 'rivian' -> '리비안'\n",
    "# 실제 사용 시에는 더 많은 회사명을 추가할 수 있음\n",
    "company_mapping = {\n",
    "    '테슬라': '테슬라(tesla)',\n",
    "    '리비안': '리비안(rivian)',\n",
    "}\n",
    "\n",
    "processed_docs = preprocess_documents(raw_documents, company_mapping)\n",
    "print(f\"총 {len(processed_docs)}개 청크 생성됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "for i, doc in enumerate(processed_docs[:3]+ processed_docs[-3:]):\n",
    "    print(f\"\\n[청크 {i+1}]\")\n",
    "    print(f\"회사: {doc.metadata['company']}\")\n",
    "    print(f\"내용: {doc.page_content}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 검색 방법론\n",
    "\n",
    "### 4.1 의미론적 검색 (Semantic Search)\n",
    "\n",
    "#### 4.1.1 벡터 저장소 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def create_or_load_vector_store(documents, collection_name=\"hybrid_search_db\"):\n",
    "    \"\"\"\n",
    "    Chroma 벡터 저장소 생성 (기존 컬렉션이 있으면 로드하고, 없으면 새로 생성)\n",
    "    \n",
    "    Args:\n",
    "        documents (list): Document 객체 리스트\n",
    "        collection_name (str): 컬렉션 이름\n",
    "    \n",
    "    Returns:\n",
    "        Chroma: 벡터 저장소 객체\n",
    "\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    persist_directory = \"./local_chroma_db\"\n",
    "    \n",
    "    # 디렉토리와 컬렉션 파일이 존재하는지 확인\n",
    "    if os.path.exists(persist_directory):\n",
    "        try:\n",
    "            # 기존 컬렉션 로드 시도\n",
    "            vector_store = Chroma(\n",
    "                collection_name=collection_name,\n",
    "                embedding_function=embeddings,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "            \n",
    "            # 컬렉션에 문서가 있는지 확인\n",
    "            if vector_store._collection.count() > 0:\n",
    "                print(f\"✅ 기존 벡터 저장소 로드 완료: {vector_store._collection.count()}개 문서\")\n",
    "                return vector_store\n",
    "        except Exception as e:\n",
    "            print(f\"기존 컬렉션 로드 실패: {e}\")\n",
    "    \n",
    "    # 새로운 벡터 저장소 생성\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_metadata={'hnsw:space': 'cosine'}\n",
    "    )\n",
    "    print(f\"✅ 새 벡터 저장소 생성 완료: {vector_store._collection.count()}개 문서\")\n",
    "    return vector_store\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "vector_store = create_or_load_vector_store(processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 의미론적 검색 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(vector_store, query, k=5):\n",
    "    \"\"\"\n",
    "    의미론적 검색 실행\n",
    "    \n",
    "    Args:\n",
    "        vector_store: Chroma 벡터 저장소\n",
    "        query (str): 검색 쿼리\n",
    "        k (int): 반환할 문서 수\n",
    "    \n",
    "    Returns:\n",
    "        list: 검색된 Document 객체 리스트\n",
    "    \"\"\"\n",
    "    # 검색기 생성\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # 검색 실행\n",
    "    results = retriever.invoke(query)\n",
    "        \n",
    "    return results\n",
    "\n",
    "# 검색 테스트\n",
    "query = \"리비안은 언제 설립되었나요?\"\n",
    "semantic_results = semantic_search(vector_store, query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"🔍 의미론적 검색 결과 ({len(semantic_results)}개)\")\n",
    "for i, doc in enumerate(semantic_results, 1):\n",
    "    print(f\"\\n[{i}] 회사: {doc.metadata.get('company', 'N/A')}\")\n",
    "    print(f\"내용: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 키워드 검색 (Keyword Search)\n",
    "\n",
    "#### 4.2.1 한국어 토크나이저 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_korean_tokenizer():\n",
    "    \"\"\"\n",
    "    한국어 토크나이저 설정\n",
    "    \n",
    "    Returns:\n",
    "        Kiwi: 한국어 토크나이저 객체\n",
    "    \"\"\"\n",
    "    kiwi = Kiwi()\n",
    "    \n",
    "    # 사용자 정의 단어 추가\n",
    "    custom_words = [\n",
    "        ('리비안', 'NNP'),  # 고유명사\n",
    "        ('테슬라', 'NNP'),  # 고유명사\n",
    "        ('전기차', 'NNG'),  # 일반명사\n",
    "    ]\n",
    "    \n",
    "    for word, pos in custom_words:\n",
    "        kiwi.add_user_word(word, pos)\n",
    "        print(f\"✅ 단어 추가: {word} ({pos})\")\n",
    "    \n",
    "    return kiwi\n",
    "\n",
    "def korean_tokenizer(text, kiwi_model):\n",
    "    \"\"\"\n",
    "    한국어 토크나이저 함수\n",
    "    \n",
    "    Args:\n",
    "        text (str): 토큰화할 텍스트\n",
    "        kiwi_model: Kiwi 모델 객체\n",
    "    \n",
    "    Returns:\n",
    "        list: 토큰 리스트\n",
    "    \"\"\"\n",
    "    return [token.form for token in kiwi_model.tokenize(text)]\n",
    "\n",
    "# 토크나이저 설정\n",
    "kiwi_model = setup_korean_tokenizer()\n",
    "\n",
    "# 토큰화 테스트\n",
    "test_text = \"리비안은 언제 설립되었나요?\"\n",
    "tokens = korean_tokenizer(test_text, kiwi_model)\n",
    "print(f\"원문: {test_text}\")\n",
    "print(f\"토큰: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 BM25 검색기 생성\n",
    "- uv pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_retriever(documents, kiwi_model, k=5):\n",
    "    \"\"\"\n",
    "    BM25 검색기 생성\n",
    "    \n",
    "    Args:\n",
    "        documents (list): Document 객체 리스트\n",
    "        kiwi_model: Kiwi 토크나이저\n",
    "        k (int): 반환할 문서 수\n",
    "    \n",
    "    Returns:\n",
    "        BM25Retriever: BM25 검색기 객체\n",
    "    \"\"\"\n",
    "    def preprocess_func(text):\n",
    "        return korean_tokenizer(text, kiwi_model)\n",
    "    \n",
    "    # BM25 검색기 생성\n",
    "    bm25_retriever = BM25Retriever.from_documents(\n",
    "        documents=documents,\n",
    "        preprocess_func=preprocess_func,\n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ BM25 검색기 생성 완료: {len(documents)}개 문서 인덱싱\")\n",
    "    return bm25_retriever\n",
    "\n",
    "# BM25 검색기 생성\n",
    "bm25_retriever = create_bm25_retriever(processed_docs, kiwi_model, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 테스트\n",
    "keyword_results = bm25_retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"🔍 키워드 검색 결과 ({len(keyword_results)}개)\")\n",
    "for i, doc in enumerate(keyword_results, 1):\n",
    "    print(f\"\\n[{i}] 회사: {doc.metadata.get('company', 'N/A')}\")\n",
    "    print(f\"내용: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 BM25 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bm25_scores(bm25_retriever, query, kiwi_model, top_k=5):\n",
    "    \"\"\"\n",
    "    BM25 점수 분석\n",
    "    \n",
    "    Args:\n",
    "        bm25_retriever: BM25 검색기\n",
    "        query (str): 검색 쿼리\n",
    "        kiwi_model: Kiwi 토크나이저\n",
    "        top_k (int): 상위 k개 결과\n",
    "    \"\"\"\n",
    "    # 쿼리 토큰화\n",
    "    tokenized_query = korean_tokenizer(query, kiwi_model)\n",
    "    print(f\"쿼리 토큰: {tokenized_query}\")\n",
    "    \n",
    "    # BM25 점수 계산\n",
    "    doc_scores = bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "    \n",
    "    # 점수 정렬\n",
    "    doc_scores_sorted = sorted(\n",
    "        enumerate(doc_scores), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📊 상위 {top_k}개 문서의 BM25 점수:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for rank, (idx, score) in enumerate(doc_scores_sorted[:top_k], 1):\n",
    "        doc = bm25_retriever.docs[idx]\n",
    "        print(f\"[{rank}] 점수: {score:.4f}\")\n",
    "        print(f\"    회사: {doc.metadata.get('company', 'N/A')}\")\n",
    "        print(f\"    내용: {doc.page_content[:100]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# BM25 점수 분석\n",
    "analyze_bm25_scores(bm25_retriever, query, kiwi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 하이브리드 검색 (Hybrid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_retriever(vector_store, bm25_retriever, weights=None):\n",
    "    \"\"\"\n",
    "    하이브리드 검색기 생성\n",
    "    \n",
    "    Args:\n",
    "        vector_store: 벡터 저장소\n",
    "        bm25_retriever: BM25 검색기\n",
    "        weights (list): 가중치 [의미론적, 키워드]\n",
    "    \n",
    "    Returns:\n",
    "        EnsembleRetriever: 하이브리드 검색기\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [0.5, 0.5]  # 기본값: 동일한 가중치\n",
    "    \n",
    "    # 의미론적 검색기 생성\n",
    "    semantic_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    # 앙상블 검색기 생성\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[semantic_retriever, bm25_retriever],\n",
    "        weights=weights\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ 하이브리드 검색기 생성 완료\")\n",
    "    print(f\"   가중치: 의미론적 {weights[0]}, 키워드 {weights[1]}\")\n",
    "    \n",
    "    return ensemble_retriever\n",
    "\n",
    "# 하이브리드 검색기 생성\n",
    "hybrid_retriever = create_hybrid_retriever(vector_store, bm25_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 테스트\n",
    "hybrid_results = hybrid_retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"🔍 하이브리드 검색 결과 ({len(hybrid_results)}개)\")\n",
    "for i, doc in enumerate(hybrid_results, 1):\n",
    "    print(f\"\\n[{i}] 회사: {doc.metadata.get('company', 'N/A')}\")\n",
    "    print(f\"내용: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 평가 및 비교\n",
    "\n",
    "### 5.1 평가 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_dataset(file_path):\n",
    "    \"\"\"\n",
    "    평가 데이터셋 로드\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): 평가 데이터 파일 경로\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: 평가 데이터셋\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"지원하지 않는 파일 형식\")\n",
    "        \n",
    "        print(f\"✅ 평가 데이터셋 로드: {len(df)}개 질문\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터셋 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 평가 데이터셋 로드\n",
    "\n",
    "eval_df = load_evaluation_dataset(\"./data/synthetic_testset.csv\")\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_evaluation_data(df):\n",
    "    \"\"\"\n",
    "    평가 데이터 전처리\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): 원본 데이터프레임\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (질문 리스트, 정답 문서 리스트)\n",
    "    \"\"\"\n",
    "    questions = df['user_input'].tolist()\n",
    "    \n",
    "    # 정답 문서 파싱\n",
    "    reference_contexts = []\n",
    "    for contexts in df['reference_contexts']:\n",
    "        if isinstance(contexts, str):\n",
    "            # 문자열을 리스트로 변환\n",
    "            context_list = eval(contexts)\n",
    "        else:\n",
    "            context_list = contexts\n",
    "        \n",
    "        # Document 객체로 변환\n",
    "        docs = [Document(page_content=ctx) for ctx in context_list]\n",
    "        reference_contexts.append(docs)\n",
    "    \n",
    "    return questions, reference_contexts\n",
    "\n",
    "# 평가 데이터 전처리\n",
    "questions, reference_contexts = prepare_evaluation_data(eval_df)\n",
    "\n",
    "# 평가 데이터 확인\n",
    "for i, (q, refs) in enumerate(zip(questions[:3], reference_contexts[:3])):\n",
    "    print(f\"\\n[질문 {i+1}]\")\n",
    "    print(f\"질문: {q}\")\n",
    "    print(f\"정답 문서: {len(refs)}개\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] 내용: {ref.page_content[:50]}...\")  # 내용 일부만 출력\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 평가 데이터 확인\n",
    "for i, (q, refs) in enumerate(zip(questions[-3:], reference_contexts[-3:])):\n",
    "    print(f\"\\n[질문 {i+1}]\")\n",
    "    print(f\"질문: {q}\")\n",
    "    print(f\"정답 문서: {len(refs)}개\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] 내용: {ref.page_content[:50]}...\")  # 내용 일부만 출력\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ranx 라이브러리를 사용한 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document_content(doc_content):\n",
    "    \"\"\"\n",
    "    문서 내용을 정규화하여 매칭 가능하도록 처리\n",
    "    \"\"\"\n",
    "    if not doc_content:\n",
    "        return \"\"\n",
    "    \n",
    "    # 문자열로 변환\n",
    "    content = str(doc_content)\n",
    "    \n",
    "    # <Document> 태그 제거\n",
    "    content = content.replace('<Document>', '').replace('</Document>', '')\n",
    "    \n",
    "    # 시작과 끝의 공백/개행 제거\n",
    "    content = content.strip()\n",
    "    \n",
    "    # 연속된 공백을 단일 공백으로 변경\n",
    "    import re\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    \n",
    "    # 처음 100자만 사용 (고유 식별을 위해)\n",
    "    return content[:100]\n",
    "\n",
    "def evaluate_with_ranx(retriever, questions, reference_contexts, k=5):\n",
    "    \"\"\"\n",
    "    ranx 라이브러리를 사용한 검색 성능 평가\n",
    "    \"\"\"\n",
    "    # ranx 설치 확인\n",
    "    try:\n",
    "        from ranx import Qrels, Run, evaluate\n",
    "    except ImportError:\n",
    "        print(\"❌ ranx 라이브러리를 설치해주세요: pip install ranx\")\n",
    "        return None\n",
    "    \n",
    "    def extract_clean_content(doc):\n",
    "        \"\"\"문서에서 깔끔한 내용을 추출\"\"\"\n",
    "        if doc is None:\n",
    "            return None\n",
    "            \n",
    "        # 문자열인 경우\n",
    "        if isinstance(doc, str):\n",
    "            return clean_document_content(doc)\n",
    "        \n",
    "        # 딕셔너리인 경우\n",
    "        if isinstance(doc, dict):\n",
    "            # 여러 필드 시도\n",
    "            for field in ['page_content', 'content', 'text', 'body']:\n",
    "                if field in doc:\n",
    "                    return clean_document_content(doc[field])\n",
    "        \n",
    "        # 문서 객체인 경우 (예: Langchain Document)\n",
    "        if hasattr(doc, 'page_content'):\n",
    "            return clean_document_content(doc.page_content)\n",
    "        elif hasattr(doc, 'content'):\n",
    "            return clean_document_content(doc.content)\n",
    "        \n",
    "        # 마지막 수단: 객체를 문자열로 변환\n",
    "        return clean_document_content(str(doc))\n",
    "    \n",
    "    # 데이터 형식 변환\n",
    "    qrels_dict = {}\n",
    "    run_dict = {}\n",
    "    \n",
    "    print(\"🔄 검색 및 평가 데이터 준비 중...\")\n",
    "    \n",
    "    total_matches = 0\n",
    "    total_queries = len(questions)\n",
    "    \n",
    "    for i, (question, ref_docs) in enumerate(zip(questions, reference_contexts)):\n",
    "        query_id = f\"q_{i+1}\"\n",
    "        \n",
    "        try:\n",
    "            # 검색 실행\n",
    "            retrieved_docs = retriever.invoke(question)\n",
    "            \n",
    "            # 정답 문서 내용 정규화\n",
    "            ref_doc_contents = set()\n",
    "            for ref_doc in ref_docs:\n",
    "                clean_content = extract_clean_content(ref_doc)\n",
    "                if clean_content:\n",
    "                    ref_doc_contents.add(clean_content)\n",
    "            \n",
    "            # 검색된 문서 내용 정규화 및 점수 부여\n",
    "            retrieved_doc_scores = {}\n",
    "            found_relevant = 0\n",
    "            \n",
    "            for j, ret_doc in enumerate(retrieved_docs[:k]):\n",
    "                clean_content = extract_clean_content(ret_doc)\n",
    "                if clean_content:\n",
    "                    # 점수는 순위 기반 (1위가 가장 높은 점수)\n",
    "                    score = k - j\n",
    "                    retrieved_doc_scores[clean_content] = score\n",
    "                    \n",
    "                    # 정답 문서에 포함되어 있는지 확인\n",
    "                    if clean_content in ref_doc_contents:\n",
    "                        found_relevant += 1\n",
    "            \n",
    "            # Qrels 형식: 정답 문서들에 대해 관련성 점수 1 부여\n",
    "            qrels_dict[query_id] = {content: 1 for content in ref_doc_contents}\n",
    "            \n",
    "            # Run 형식: 검색 결과의 점수\n",
    "            run_dict[query_id] = retrieved_doc_scores\n",
    "            \n",
    "            total_matches += found_relevant\n",
    "            \n",
    "            print(f\"✅ 질문 {i+1} 처리 완료\")\n",
    "            print(f\"  질문: {question[:50]}...\")\n",
    "            print(f\"  검색된 문서 수: {len(retrieved_docs[:k])}\")\n",
    "            print(f\"  정답 문서 수: {len(ref_doc_contents)}\")\n",
    "            print(f\"  발견된 관련 문서 수: {found_relevant}\")\n",
    "            \n",
    "            # 디버깅 정보 (매칭 확인용)\n",
    "            if found_relevant > 0:\n",
    "                print(f\"  ✅ 매칭 성공!\")\n",
    "            else:\n",
    "                print(f\"  ❌ 매칭 실패\")\n",
    "                # 첫 번째 정답과 검색 결과 비교\n",
    "                if ref_doc_contents and retrieved_doc_scores:\n",
    "                    first_ref = list(ref_doc_contents)[0]\n",
    "                    first_ret = list(retrieved_doc_scores.keys())[0]\n",
    "                    print(f\"    정답[0]: '{first_ref[:50]}...'\")\n",
    "                    print(f\"    검색[0]: '{first_ret[:50]}...'\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 질문 {i+1} 처리 중 오류: {e}\")\n",
    "            # 빈 결과로 설정\n",
    "            qrels_dict[query_id] = {}\n",
    "            run_dict[query_id] = {}\n",
    "            continue\n",
    "    \n",
    "    print(f\"📊 전체 매칭 통계: {total_matches}개 문서가 {total_queries}개 질문에서 매칭됨\")\n",
    "    \n",
    "    # 빈 결과 확인\n",
    "    empty_qrels = [q for q, docs in qrels_dict.items() if not docs]\n",
    "    empty_runs = [q for q, docs in run_dict.items() if not docs]\n",
    "    \n",
    "    if empty_qrels:\n",
    "        print(f\"⚠️  정답이 없는 쿼리: {empty_qrels}\")\n",
    "    if empty_runs:\n",
    "        print(f\"⚠️  검색 결과가 없는 쿼리: {empty_runs}\")\n",
    "    \n",
    "    # ranx 객체 생성\n",
    "    try:\n",
    "        qrels = Qrels(qrels_dict, name=\"Retrieval_Evaluation\")\n",
    "        run = Run(run_dict, name=\"Retriever_Results\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ranx 객체 생성 오류: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 평가 메트릭 계산\n",
    "    metrics = [f\"hit_rate@{k}\", f\"ndcg@{k}\", f\"map@{k}\", \"mrr\"]\n",
    "    \n",
    "    try:\n",
    "        results = evaluate(qrels, run, metrics)\n",
    "        \n",
    "        print(\"\\n📊 ranx 평가 결과:\")\n",
    "        print(\"=\" * 40)\n",
    "        for metric, score in results.items():\n",
    "            print(f\"  {metric:<15}: {score:.4f}\")\n",
    "        \n",
    "        # 추가 통계\n",
    "        print(f\"\\n📈 매칭 통계:\")\n",
    "        print(f\"  전체 매칭 문서 수: {total_matches}\")\n",
    "        print(f\"  평균 매칭률: {total_matches / (total_queries * k):.2%}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 평가 계산 오류: {e}\")\n",
    "        \n",
    "        # 개별 메트릭으로 재시도\n",
    "        results = {}\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                score = evaluate(qrels, run, metric)\n",
    "                results[metric] = score\n",
    "                print(f\"  {metric:<15}: {score:.4f}\")\n",
    "            except Exception as metric_error:\n",
    "                print(f\"  {metric:<15}: ERROR - {metric_error}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "\n",
    "# 평가 실행\n",
    "ranx_results = evaluate_with_ranx(\n",
    "    hybrid_retriever, \n",
    "    questions, \n",
    "    reference_contexts,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ranx 이슈 사항**\n",
    "\n",
    "- **ID 매칭 의존성**: 정확한 문서 ID 일치가 필요\n",
    "- **의미적 유사도 무시**: 내용이 비슷해도 ID가 다르면 0점\n",
    "- **청킹 방식 변화 대응 불가**: 청크 크기나 방식이 바뀌면 평가 불가능\n",
    "- **실제 사용 환경과 괴리**: 실제로는 의미적 관련성이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ranx-k 라이브러리 활용한 평가\n",
    "\n",
    "- ROUGE 점수 기반 평가 \n",
    "- 아이디어: 텍스트 오버랩을 통한 직접적 유사도 측정\n",
    "\n",
    "- **ranx-k 설치 방법**\n",
    "\n",
    "    ```bash\n",
    "    # ranx-k 라이브러리 설치\n",
    "    pip install ranx-k\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranx-k 라이브러리 import\n",
    "from ranx_k.evaluation import evaluate_with_ranx_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranx-k 평가 실행 (rouge 점수가 높은 경우) -> 문자열 유사도 기반 평가\n",
    "ranx_k_results = evaluate_with_ranx_similarity(\n",
    "    retriever=hybrid_retriever,\n",
    "    questions=questions,\n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranx-k 평가 실행 (embedding 점수가 높은 경우) -> 의미적 유사도 기반 평가\n",
    "ranx_k_results = evaluate_with_ranx_similarity(\n",
    "    retriever=hybrid_retriever,\n",
    "    questions=questions,\n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='embedding',  \n",
    "    embedding_model=\"BAAI/bge-m3\",\n",
    "    similarity_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 검색 방법 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_methods(vector_store, bm25_retriever, questions, reference_contexts, k=5):\n",
    "    \"\"\"\n",
    "    다양한 검색 방법 성능 비교\n",
    "    \n",
    "    Args:\n",
    "        vector_store: 벡터 저장소\n",
    "        bm25_retriever: BM25 검색기\n",
    "        questions (list): 질문 리스트\n",
    "        reference_contexts (list): 정답 문서 리스트\n",
    "        k (int): 평가할 상위 k개 결과\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: 비교 결과\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # 검색 방법들 정의\n",
    "    bm25_retriever.k = k\n",
    "    retrievers = {\n",
    "        \"의미론적 검색\": vector_store.as_retriever(search_kwargs={\"k\": k}),\n",
    "        \"키워드 검색\": bm25_retriever,\n",
    "        \"하이브리드 (5:5)\": create_hybrid_retriever(vector_store, bm25_retriever, [0.5, 0.5]),\n",
    "        \"하이브리드 (7:3)\": create_hybrid_retriever(vector_store, bm25_retriever, [0.7, 0.3]),\n",
    "        \"하이브리드 (3:7)\": create_hybrid_retriever(vector_store, bm25_retriever, [0.3, 0.7]),\n",
    "    }\n",
    "    \n",
    "    for method_name, retriever in retrievers.items():\n",
    "        print(f\"🔄 {method_name} 평가 중...\")\n",
    "        \n",
    "        # ranx-k 평가 실행 (rouge 점수가 높은 경우) -> 문자열 유사도 기반 평가\n",
    "        ranx_k_results = evaluate_with_ranx_similarity(\n",
    "            retriever=retriever,\n",
    "            questions=questions,\n",
    "            reference_contexts=reference_contexts,\n",
    "            k=k,\n",
    "            method='kiwi_rouge',  \n",
    "            similarity_threshold=0.8,\n",
    "        )\n",
    "        \n",
    "        # 평가 결과 정리 \n",
    "        result = {\n",
    "            \"method\": method_name,\n",
    "            \"hit_rate\": ranx_k_results.get(\"hit_rate@5\", 0),\n",
    "            \"ndcg\": ranx_k_results.get(\"ndcg@5\", 0),\n",
    "            \"map\": ranx_k_results.get(\"map@5\", 0),\n",
    "            \"mrr\": ranx_k_results.get(\"mrr\", 0),\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    # 결과 DataFrame 생성\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.set_index(\"method\", inplace=True)\n",
    "    results_df.sort_values(by=\"hit_rate\", ascending=False, inplace=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# 검색 방법 성능 비교\n",
    "comparison_results = compare_retrieval_methods(vector_store, bm25_retriever, questions, reference_contexts, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison_results(comparison_df):\n",
    "    \"\"\"\n",
    "    검색 방법 비교 결과 시각화\n",
    "    \n",
    "    Args:\n",
    "        comparison_df (pandas.DataFrame): 비교 결과 데이터프레임\n",
    "\n",
    "        result = {\n",
    "            \"method\": method_name,\n",
    "            \"hit_rate\": ranx_k_results.get(\"hit_rate@5\", 0),\n",
    "            \"ndcg\": ranx_k_results.get(\"ndcg@5\", 0),\n",
    "            \"map\": ranx_k_results.get(\"map@5\", 0),\n",
    "            \"mrr\": ranx_k_results.get(\"mrr\", 0),\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # 그래프 생성\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 8))\n",
    "    sns.barplot(x=comparison_df.index, y='hit_rate', data=comparison_df, ax=ax[0])\n",
    "    ax[0].set_title('Hit Rate@5')\n",
    "    ax[0].set_ylabel('Hit Rate')\n",
    "    ax[0].set_xlabel('Retrieval Method')        \n",
    "    ax[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    sns.barplot(x=comparison_df.index, y='ndcg', data=comparison_df, ax=ax[1])\n",
    "    ax[1].set_title('NDCG@5')\n",
    "    ax[1].set_ylabel('NDCG')\n",
    "    ax[1].set_xlabel('Retrieval Method')\n",
    "    ax[1].tick_params(axis='x', rotation=45)                \n",
    "\n",
    "    sns.barplot(x=comparison_df.index, y='map', data=comparison_df, ax=ax[2])\n",
    "    ax[2].set_title('MAP@5')\n",
    "    ax[2].set_ylabel('MAP')         \n",
    "    ax[2].set_xlabel('Retrieval Method')\n",
    "    ax[2].tick_params(axis='x', rotation=45)    \n",
    "\n",
    "    sns.barplot(x=comparison_df.index, y='mrr', data=comparison_df, ax=ax[3])\n",
    "    ax[3].set_title('MRR')\n",
    "    ax[3].set_ylabel('MRR')\n",
    "    ax[3].set_xlabel('Retrieval Method')\n",
    "    ax[3].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 그래프 출력\n",
    "    plt.savefig(\"retrieval_comparison_results.png\")\n",
    "\n",
    "# 검색 방법 비교 결과 시각화\n",
    "visualize_comparison_results(comparison_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kt-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
