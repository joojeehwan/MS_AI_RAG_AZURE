{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChain의 개념과 주요 컴포넌트 이해\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain이란 \n",
    "\n",
    "핵심 내용:\n",
    "- **LangChain**은 LLM 기반 애플리케이션 개발을 위한 프레임워크\n",
    "\n",
    "- **Chain**은 작업을 순차적으로 실행하는 파이프라인 구조를 제공\n",
    "\n",
    "- **Agent**는 자율적 의사결정이 가능한 실행 단위\n",
    "\n",
    "결론:\n",
    "- LangChain은 Chain과 Agent라는 두 가지 핵심 기능을 통해 LLM 애플리케이션 개발을 효율적으로 지원\n",
    "\n",
    "\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"https://python.langchain.com/svg/langchain_stack_112024_dark.svg\" \n",
    "            alt=\"langchain_stack\" \n",
    "            width=\"600\" \n",
    "            style=\"border: 0;\">\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 컴포넌트 \n",
    "\n",
    "- LangChain **주요 컴포넌트**: LLM/ChatModel, Prompt, Memory, Tool, Document Loader, Text Splitter, Embedding, Vectorstore\n",
    "\n",
    "- **언어 처리 기능**은 LLM/ChatModel이 중심이 되며, Prompt와 Memory로 대화를 관리\n",
    "\n",
    "- **문서 처리와 검색**은 Document Loader, Text Splitter, Embedding, Vectorstore가 담당\n",
    "\n",
    "- **모듈성**이 핵심 특징으로, 독립적인 컴포넌트들을 조합해 RAG와 같은 복잡한 시스템을 구현 가능 \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 모델 (Models)\n",
    "- LLM, ChatModel 등으로 구분\n",
    "- OpenAI, Anthropic, Google 등 다양한 모델을 지원\n",
    "- 텍스트 생성, 대화, 요약 등의 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 모델을 사용하여 대화 생성\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3, top_p=0.95)\n",
    "\n",
    "# 모델에 메시지를 보내고 응답을 받기\n",
    "response = model.invoke(\"안녕하세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-BnyQTgz7SuX4UTm6LyjjxgzCAizZq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7db03d0c-544d-4bd8-b474-d2e602650c45-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 객체(AIMessage): 메시지(content)와 메타데이터(response_metadata 등)를 포함\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "# 응답 객체의 메시지 내용 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타데이터:  {'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-BnyQTgz7SuX4UTm6LyjjxgzCAizZq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# 응답 객체의 메타데이터 출력\n",
    "print(\"메타데이터: \", response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 메시지 (Messages)\n",
    "- Chat Model에서 사용할 수 있는 통합된 메시지 형식을 제공\n",
    "- 각 모델 제공자의 특정 메시지 형식을 신경 쓰지 않고도 다양한 채팅 모델을 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. HumanMessage`\n",
    "- 사용자 역할에 해당 (user, human 등)\n",
    "- 사용자의 입력을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  \"Glory\"는 한국어로 보통 \"영광\"이라고 번역합니다. 문맥에 따라 \"영예\", \"명예\", \"찬란함\" 등으로도 번역될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 사용자 메시지 생성\n",
    "human_message = HumanMessage(content=\"Glory를 한국어로 번역해주세요.\")\n",
    "\n",
    "# 번역 요청 및 응답 받기\n",
    "response = model.invoke([human_message])  # 메시지 리스트로 전달\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"는 한국어로 보통 \"영광\"이라고 번역됩니다. 상황에 따라 \"영예,\" \"명예,\" 또는 \"찬란함\" 등으로도 표현될 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 17, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-BnyV0wwrbCer0issDssPSw1qu57KT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--63413a41-5b3e-4dfc-800b-1e6a52826009-0', usage_metadata={'input_tokens': 17, 'output_tokens': 44, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열을 입력하면, 자동으로 HumanMessage로 변환하여 요청\n",
    "model.invoke(\"Glory를 한국어로 번역해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. AIMessage`\n",
    "- AI 모델의 응답을 표현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"는 한국어로 보통 \"영광\"이라고 번역합니다. 문맥에 따라 \"영예\", \"명예\", \"찬란함\" 등으로도 번역될 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 17, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BnyUSzBgv58HNHNdw5tLci1SeZRGI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a2ca0cae-7097-488e-8253-b94cb1a66a77-0', usage_metadata={'input_tokens': 17, 'output_tokens': 45, 'total_tokens': 62, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI 모델의 응답 객체를 출력 \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Glory\"는 한국어로 보통 \"영광\"이라고 번역합니다. 문맥에 따라 \"영예\", \"명예\", \"찬란함\" 등으로도 번역될 수 있습니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 응답 텍스트 부분을 출력\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 17,\n",
       " 'output_tokens': 45,\n",
       " 'total_tokens': 62,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 사용량 출력\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. SystemMessage`\n",
    "- 시스템 역할에 해당 (system, developer 등)\n",
    "- AI 모델의 동작과 제약사항을 정의하는데 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='당신은 영어를 한국어로 번역하는 AI 어시스턴트입니다.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage \n",
    "\n",
    "# 시스템 메시지 생성\n",
    "system_msg = SystemMessage(content=\"당신은 영어를 한국어로 번역하는 AI 어시스턴트입니다.\")\n",
    "\n",
    "# 메시지 객체 확인\n",
    "system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  영광\n"
     ]
    }
   ],
   "source": [
    "# 번역 요청 (HumanMessage)과 시스템 메시지(SystemMessage)를 함께 사용\n",
    "human_message = HumanMessage(content=\"Glory\")\n",
    "messages = [\n",
    "    system_msg, \n",
    "    human_message\n",
    "    ]\n",
    "\n",
    "# 모델에 메시지를 보내고 응답 받기\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 프롬프트 템플릿 (Prompt Template)\n",
    "- 프롬프트 템플릿을 통해 일관된 입력 형식을 제공\n",
    "    1. 사용자의 입력과 파라미터를 언어 모델이 이해할 수 있는 형태로 변환하는 도구\n",
    "    2. 언어 모델에게 전달할 지시문을 만드는 틀\n",
    "- 변수를 포함한 동적 프롬프트 생성이 가능\n",
    "    1. 모든 템플릿은 딕셔너리 형태의 입력을 받아서 처리\n",
    "    2. 출력은 PromptValue 형태로 반환되며, 이는 문자열이나 메시지 리스트로 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. 문자열 프롬프트 템플릿 (String PromptTemplate)`\n",
    "- 가장 기본적인 형태\n",
    "- 단일 문자열을 형식화하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='고양이에 대한 이야기를 해줘')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 템플릿 생성 \n",
    "# \"{topic}에 대한 이야기를 해줘\"라는 템플릿을 사용하여\n",
    "# topic이라는 변수를 포함하는 프롬프트를 생성\n",
    "template = PromptTemplate.from_template(\"{topic}에 대한 이야기를 해줘\")\n",
    "\n",
    "# 템플릿 사용\n",
    "# \"고양이\"라는 주제를 사용하여 프롬프트 생성\n",
    "# invoke 메서드를 통해 템플릿에 값을 전달\n",
    "prompt = template.invoke({\"topic\": \"고양이\"})\n",
    "\n",
    "# 템플릿 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. 채팅 프롬프트 템플릿 (ChatPromptTemplate)`\n",
    "- 여러 메시지를 포함하는 대화형 템플릿을 만들 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='당신은 도움이 되는 비서입니다', additional_kwargs={}, response_metadata={}), HumanMessage(content='인공지능에 대해 설명해주세요', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 채팅 템플릿 생성\n",
    "# 여기서는 시스템 메시지와 사용자 메시지를 포함하여 정의\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "    (\"user\", \"{subject}에 대해 설명해주세요\")\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\"subject\": \"인공지능\"})\n",
    "\n",
    "# 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. 메시지 플레이스홀더 (MessagesPlaceholder)`\n",
    "- 기존 메시지 목록을 템플릿의 특정 위치에 삽입할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 도움이 되는 비서입니다', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='안녕하세요! 제 이름은 스티브입니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='제 이름을 기억하나요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 메시지 플레이스홀더가 있는 템플릿\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "    MessagesPlaceholder(\"chat_history\")   # 채팅 기록을 플레이스홀더로 사용 (예: 이전 대화 내용) -> 이 위치에 메시지 목록을 추가할 수 있음\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\n",
    "    \"chat_history\": [\n",
    "        HumanMessage(content=\"안녕하세요! 제 이름은 스티브입니다.\"),\n",
    "        AIMessage(content=\"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        HumanMessage(content=\"제 이름을 기억하나요?\")\n",
    "        ]\n",
    "})\n",
    "\n",
    "# 출력\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 출력 파서 (Output Parser)\n",
    "1. **역할과 기능**\n",
    "    - 모델의 텍스트 출력을 구조화된 데이터로 변환\n",
    "    - 채팅 모델과 LLM의 출력을 정규화\n",
    "    - 다운스트림 작업을 위한 데이터 형식 변환\n",
    "\n",
    "2. **사용 시 고려사항**\n",
    "    - OpenAI function calling과 같은 기능이 있는 경우, 해당 기능을 우선 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울의 특징에 대해 알려드리겠습니다.\n",
      "\n",
      "1. **대한민국의 수도**: 서울은 한국의 정치, 경제, 문화, 교육의 중심지로서 국가의 행정 및 정부기관이 밀집해 있습니다.\n",
      "\n",
      "2. **인구 밀집 지역**: 서울은 약 천만 명 이상의 인구가 살고 있는 대도시로, 세계에서 인구밀도가 높은 도시 중 하나입니다.\n",
      "\n",
      "3. **역사와 현대의 조화**: 경복궁, 창덕궁 같은 조선 시대의 궁궐과 한옥마을이 남아 있는 반면, 강남 같은 지역은 현대적인 고층 빌딩과 첨단 산업 단지가 발달해 있습니다.\n",
      "\n",
      "4. **경제 중심지**: 삼성, LG, 현대 등 대기업 본사가 위치해 있으며, 금융, 서비스업 그리고 스타트업 산업도 활발합니다.\n",
      "\n",
      "5. **교통 인프라**: 지하철, 버스, 고속도로 등이 잘 발달되어 있어 서울 내 이동이 편리하며, 인천국제공항과 김포국제공항을 통해 국제적인 연결성이 좋습니다.\n",
      "\n",
      "6. **문화와 관광**: 다양한 박물관, 미술관, 공연장과 더불어 명동, 홍대, 인사동 같은 쇼핑 및 문화 명소가 유명합니다.\n",
      "\n",
      "7. **교육의 중심지**: 서울대학교, 연세대학교, 고려대학교 등 명문 대학들이 있어 교육 환경이 뛰어납니다.\n",
      "\n",
      "8. **환경과 공원**: 한강공원, 남산공원 등 도시 속 자연 공간이 잘 조성되어 시민들이 휴식할 수 있습니다.\n",
      "\n",
      "이 외에도 서울은 빠른 변화와 혁신의 도시로서 많은 사람들이 모여 다양한 문화와 트렌드를 만들어가는 역동적인 도시입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 기본적인 문자열 파서 사용\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate.from_template(\"도시 {city}의 특징을 알려주세요\")\n",
    "\n",
    "# 모델 정의\n",
    "model = ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "# 체인 구성 (LCEL)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 체인 실행\n",
    "result = chain.invoke({\"city\": \"서울\"})\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 구조화된 출력 (with_structured_output 메소드)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "MBC 구독\n",
    "무역협회 \"관세 전쟁에 3분기 수출 경기 위축 전망\"\n",
    "입력2025.06.30. 오전 11:16  수정2025.06.30. 오전 11:24 기사원문\n",
    "송재원 기자\n",
    "송재원 기자\n",
    " 추천\n",
    "댓글\n",
    "본문 요약봇\n",
    "텍스트 음성 변환 서비스 사용하기\n",
    "글자 크기 변경하기\n",
    "SNS 보내기\n",
    "인쇄하기\n",
    "\n",
    "\n",
    "수출 기업들의 3분기 체감 경기가 지속적으로 악화하는 추세를 보일 것으로 전망됐습니다.\n",
    "\n",
    "한국무역협회가 15개 품목 2천여 개 수출기업에게 3분기 수출 전망을 조사한 결과, 수출산업경기전망지수, EBSI가 기준인 100을 넘지 못해, 수출경기가 전 분기보다 악화될 것으로 예상하는 기업이 더 많은 것으로 나타났습니다.\n",
    "\n",
    "무역협회는 미국의 관세 조치에 따른 불확실성이 지속되는 가운데 글로벌 성장세는 둔화하고 환율 변동성은 확대되면서 수출 기업들의 체감 경기가 지속해 부진하게 나타나고 있다고 분석했습니다.\n",
    "\n",
    "수출산업경기전망지수는 지난해 4분기 103.4를 기록한 이후 올해 들어서는 계속 100 밑을 나타내고 있습니다.\n",
    "\n",
    "분야별로 보면 가전 52.7, 자동차·부품 56.0, 전기·전자제품 65.2로 수치가 낮았던 반면 반도체는 147.1, 선박은 135.5, 생활용품은 132.0로 나타나 산업별로 경기 전망이 엇갈렸습니다.\n",
    "\n",
    "송재원(jwon@mbc.co.kr)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic 클래스로 출력 구조를 정의\n",
    "class CityInfo(BaseModel):\n",
    "    \"\"\"도시 정보를 담는 스키마\"\"\"\n",
    "    name: str = Field(description=\"도시 이름\")\n",
    "    description: str = Field(description=\"도시의 특징\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. 출력 스키마 정의\n",
    "class NewsInfo(BaseModel):\n",
    "    \"\"\"뉴스에서 추출한 정보를 담는 스키마\"\"\"    \n",
    "    title: str = Field(description=\"뉴스 제목\")\n",
    "    content: str = Field(description=\"뉴스 본문. 원문 그대로 유지해서 추출.\")\n",
    "    journalist: str = Field(description=\"기자의 이름\")\n",
    "    email: str = Field(description=\"기자의 이메일\")\n",
    "    datetime: str = Field(description=\"뉴스 입력 시간\")\n",
    "\n",
    "# 2. 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(\"다음 뉴스에서 주요한 정보를 추출하세요. 뉴스: {article}\")\n",
    "\n",
    "# 3. 모델 생성 및 구조화된 출력 바인딩\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "structured_model = model.with_structured_output(NewsInfo)\n",
    "\n",
    "# 4. 프롬프트와 모델 체인 연결\n",
    "chain = prompt | structured_model\n",
    "\n",
    "# 5. 체인 실행\n",
    "result = chain.invoke({\"article\": article})\n",
    "\n",
    "# # 6. 결과 출력 (CityInfo 객체)\n",
    "# print(result)\n",
    "# print(\"-\" * 20)\n",
    "# print(f\"도시 이름: {result.name}\")\n",
    "# print(f\"특징: {result.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '무역협회 \"관세 전쟁에 3분기 수출 경기 위축 전망\"',\n",
       " 'content': '수출 기업들의 3분기 체감 경기가 지속적으로 악화하는 추세를 보일 것으로 전망됐습니다.\\n\\n한국무역협회가 15개 품목 2천여 개 수출기업에게 3분기 수출 전망을 조사한 결과, 수출산업경기전망지수, EBSI가 기준인 100을 넘지 못해, 수출경기가 전 분기보다 악화될 것으로 예상하는 기업이 더 많은 것으로 나타났습니다.\\n\\n무역협회는 미국의 관세 조치에 따른 불확실성이 지속되는 가운데 글로벌 성장세는 둔화하고 환율 변동성은 확대되면서 수출 기업들의 체감 경기가 지속해 부진하게 나타나고 있다고 분석했습니다.\\n\\n수출산업경기전망지수는 지난해 4분기 103.4를 기록한 이후 올해 들어서는 계속 100 밑을 나타내고 있습니다.\\n\\n분야별로 보면 가전 52.7, 자동차·부품 56.0, 전기·전자제품 65.2로 수치가 낮았던 반면 반도체는 147.1, 선박은 135.5, 생활용품은 132.0로 나타나 산업별로 경기 전망이 엇갈렸습니다.',\n",
       " 'journalist': '송재원',\n",
       " 'email': 'jwon@mbc.co.kr',\n",
       " 'datetime': '2025-06-30T11:16:00'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 메모리 (Memory)\n",
    "- 대화 기록을 저장하고 관리\n",
    "- 컨텍스트 유지를 위한 다양한 메모리 타입을 제공\n",
    "- 대화 요약, 버퍼링 등의 기능을 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# 메모리 기반 히스토리 구현\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"메모리 기반 채팅 메시지 히스토리\"\"\"\n",
    "\n",
    "    # 메시지 목록\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    \n",
    "    # 메시지 추가\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "    \n",
    "    # 메시지 목록 초기화 \n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "# 세션 저장소  (redis, ... sql, nosql, ... )\n",
    "store = {}\n",
    "\n",
    "# 세션 ID로 히스토리 가져오기\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"세션 ID에 해당하는 채팅 메시지 히스토리를 반환합니다.\"\"\"\n",
    "\n",
    "    # 세션 ID가 저장소에 없으면 새 InMemoryHistory 객체 생성\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "        \n",
    "    # 해당 세션 ID의 히스토리 반환\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅 모델과 프롬프트 설정\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 {subject}에 능숙한 비서입니다\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "# 히스토리 관리 추가\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,    # 실행 체인\n",
    "    get_session_history,  # 세션 ID에 해당하는 히스토리 가져오는 함수\n",
    "    input_messages_key=\"question\",     # 입력 메시지 키\n",
    "    history_messages_key=\"history\"     # 히스토리 메시지 키\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1+2는 3입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bo0LVzNYLyBCwDNCXLSdRmlUSAjdd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d70dfe6e-0359-4213-819e-e197713e871d-0' usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"1+2는 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2는 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2는 3입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bo0LVzNYLyBCwDNCXLSdRmlUSAjdd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d70dfe6e-0359-4213-819e-e197713e871d-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1+2의 결과인 3에 숫자 2를 곱하면 6입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 61, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bo0MIUof26pIwbmRqfZBFHOjaEjOR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--7568ae33-0521-4a3f-a445-942ad28efba3-0' usage_metadata={'input_tokens': 61, 'output_tokens': 21, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 히스토리 이용해서 대화 진행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"여기에 숫자 2를 곱하면 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2는 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2는 3입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bo0LVzNYLyBCwDNCXLSdRmlUSAjdd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d70dfe6e-0359-4213-819e-e197713e871d-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='여기에 숫자 2를 곱하면 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2의 결과인 3에 숫자 2를 곱하면 6입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 61, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bo0MIUof26pIwbmRqfZBFHOjaEjOR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7568ae33-0521-4a3f-a445-942ad28efba3-0', usage_metadata={'input_tokens': 61, 'output_tokens': 21, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 에이전트 (Agent)\n",
    "- 자율적 의사결정이 가능한 실행 단위\n",
    "- LangChain에서는 Agent 클래스를 통해 에이전트 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 10543543535430, 'b': 205345350}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m10543748880780.0\u001b[0m\u001b[32;1m\u001b[1;3m10543543535430과 205345350을 더하면 10543748880780입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '10543543535430과 205345350을 더하면 얼마인가요?',\n",
       " 'output': '10543543535430과 205345350을 더하면 10543748880780입니다.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# 프롬프트 템플릿 생성 - ReAct 에이전트에 필요한 변수들 포함\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절한 수학 선생님입니다.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")    # 에이전트가 도구 호출 결과를 기록할 플레이스홀더\n",
    "])\n",
    "\n",
    "# 도구 정의\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"두 숫자를 더하는 도구\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"두 숫자를 빼는 도구\"\"\"\n",
    "    return a - b\n",
    "\n",
    "# 도구 목록 생성\n",
    "tools = [\n",
    "    add,\n",
    "    subtract\n",
    "]\n",
    "\n",
    "# 에이전트 생성 (도구 호출)\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=ChatOpenAI(model='gpt-4.1-mini'),\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# 에이전트 실행 도구 정의\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,      # 도구 호출 에이전트\n",
    "    tools=tools,      # 도구 목록\n",
    "    verbose=True,     # 상세 로그 출력\n",
    "    )\n",
    "\n",
    "# 에이전트 실행\n",
    "agent_executor.invoke({\"input\": \"10543543535430과 205345350을 더하면 얼마인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [실습]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 다음 조건을 만족하는 새로운 ChatPromptTemplate을 만드세요.\n",
    "   - 시스템 메시지: \"당신은 친절한 과학 선생님입니다\"\n",
    "   - 대화 기록을 포함\n",
    "   - 사용자 질문을 받을 수 있는 형식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. StrOutputParser를 사용하여 다음을 구현해보세요.\n",
    "   - 앞의 프롬프트 템플릿을 사용하여 체인 구성 및 실행\n",
    "   - \"섭씨온도와 화씨온도 관계\"를 설명해 달라고 요청하는 프롬프트 작성 \n",
    "   - 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktds-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
