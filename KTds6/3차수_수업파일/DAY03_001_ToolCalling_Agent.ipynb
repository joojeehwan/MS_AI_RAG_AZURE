{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Tool Calling (Function Calling) + ì—ì´ì „íŠ¸(Agent) ê°œë…\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env í™˜ê²½ë³€ìˆ˜`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing ì„¤ì •`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "# Langsmith tracing ì—¬ë¶€ë¥¼ í™•ì¸ (true: langsmith ì¶”ì²™ í™œì„±í™”, false: langsmith ì¶”ì²™ ë¹„í™œì„±í™”)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Tool Calling**\n",
    "\n",
    "- **Tool Calling**ì€ LLMì´ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ **í•¨ìˆ˜ í˜¸ì¶œ ë©”ì»¤ë‹ˆì¦˜**\n",
    "\n",
    "- LLMì€ ì •ì˜ëœ ë„êµ¬ë‚˜ í•¨ìˆ˜ë¥¼ í†µí•´ **ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ í†µì‹ **í•˜ê³  ì‘ì—…ì„ ìˆ˜í–‰\n",
    "\n",
    "- **Tool calling**ì€ ëª¨ë¸ì´ ì‹œìŠ¤í…œê³¼ ì§ì ‘ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê¸°ëŠ¥\n",
    "\n",
    "- **êµ¬ì¡°í™”ëœ ì¶œë ¥**ì„ í†µí•´ APIë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì™€ ê°™ì€ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±\n",
    "\n",
    "- **ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ì‘ë‹µ**ìœ¼ë¡œ ì‹œìŠ¤í…œ ê°„ íš¨ìœ¨ì  í†µì‹  ê°€ëŠ¥\n",
    "\n",
    "\n",
    "![Tool Calling Concept](https://python.langchain.com/assets/images/tool_calling_concept-552a73031228ff9144c7d59f26dedbbf.png)\n",
    "\n",
    "\n",
    "[ì°¸ì¡°] https://python.langchain.com/docs/concepts/tool_calling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **Tool Creation** (`@tool` ë°ì½”ë ˆì´í„° ì‚¬ìš©)\n",
    "\n",
    "- **@tool ë°ì½”ë ˆì´í„°**ë¡œ í•¨ìˆ˜ì— ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ê°€\n",
    "\n",
    "- **í•¨ìˆ˜ì™€ ìŠ¤í‚¤ë§ˆ** ê°„ ìë™ ì—°ê²°ë¡œ ë„êµ¬ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ê°„ë‹¨í•œ ë‚ ì”¨ ì˜ˆì œ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"ì„œìš¸\", \"ë¶€ì‚°\", \"ëŒ€êµ¬\", \"ì¸ì²œ\", \"ê´‘ì£¼\"]):\n",
    "    \"\"\"í•œêµ­ ì£¼ìš” ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    weather_data = {\n",
    "        \"ì„œìš¸\": \"ë§‘ìŒ\",\n",
    "        \"ë¶€ì‚°\": \"íë¦¼\",\n",
    "        \"ëŒ€êµ¬\": \"ë§‘ìŒ\",\n",
    "        \"ì¸ì²œ\": \"ë¹„\",\n",
    "        \"ê´‘ì£¼\": \"êµ¬ë¦„ë§ìŒ\"\n",
    "    }\n",
    "    \n",
    "    if city in weather_data:\n",
    "        return f\"{city} ë‚ ì”¨ëŠ” {weather_data[city]}\"\n",
    "    else:\n",
    "        raise AssertionError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.tools.structured.StructuredTool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(get_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for get_weather\ncity\n  Input should be 'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ' or 'ê´‘ì£¼' [type=literal_error, input_value='ëŒ€ì „', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ë„êµ¬ ì‹¤í–‰\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mget_weather\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mëŒ€ì „\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:598\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    592\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    595\u001b[39m     **kwargs: Any,\n\u001b[32m    596\u001b[39m ) -> Any:\n\u001b[32m    597\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:882\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    881\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    883\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    884\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:844\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    842\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    848\u001b[39m         tool_kwargs = tool_kwargs | {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:759\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    752\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    753\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    756\u001b[39m ):\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:640\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    638\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    642\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\pydantic\\main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for get_weather\ncity\n  Input should be 'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ' or 'ê´‘ì£¼' [type=literal_error, input_value='ëŒ€ì „', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/literal_error"
     ]
    }
   ],
   "source": [
    "# ë„êµ¬ ì‹¤í–‰\n",
    "get_weather.invoke(\"ëŒ€ì „\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) DB ê²€ìƒ‰ ì˜ˆì œ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"db_korean_cosine_metadata\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¿¼ë¦¬: ë¦¬ë¹„ì•ˆì€ ì–¸ì œ ì‚¬ì—…ì„ ì‹œì‘í–ˆë‚˜ìš”?\n",
      "ê²€ìƒ‰ ê²°ê³¼:\n",
      "- <Document>\n",
      "- **íšŒì‚¬ ìœ í˜•:** ìƒì¥\n",
      "- **ê±°ë˜ì†Œ:** NASDAQ: RIVN\n",
      "- **ì„¤ë¦½:** 2009ë…„ 6ì›”, í”Œë¡œë¦¬ë‹¤ ì£¼ ë¡ledge\n",
      "- **ì„¤ë¦½ì:** R. J. ìŠ¤ìºë¦°ì§€\n",
      "- **ë³¸ì‚¬:** ë¯¸êµ­ ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼ ì–´ë°”ì¸\n",
      "- **ì„œë¹„ìŠ¤ ì§€ì—­:** ë¶ë¯¸\n",
      "- **ì£¼ìš” ì¸ë¬¼:** R. J. ìŠ¤ìºë¦°ì§€ (CEO)\n",
      "- **ì œí’ˆ:** ì „ê¸° ìë™ì°¨, ë°°í„°ë¦¬\n",
      "- **ìƒì‚°ëŸ‰ (2023):** 57,232ëŒ€\n",
      "- **ì„œë¹„ìŠ¤:** ì „ê¸° ìë™ì°¨ ì¶©ì „, ìë™ì°¨ ë³´í—˜\n",
      "- **ìˆ˜ìµ (2023):** 44ì–µ 3ì²œë§Œ ë¯¸êµ­ ë‹¬ëŸ¬\n",
      "- **ìˆœì´ìµ (2023):** -54ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\n",
      "- **ì´ ìì‚° (2023):** 168ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\n",
      "</Document>\n",
      "<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ 'ë¦¬ë¹„ì•ˆ'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source> [ì¶œì²˜: data\\ë¦¬ë¹„ì•ˆ_KR.md]\n",
      "- <Document>\n",
      "Rivian Automotive, Inc.ëŠ” 2009ë…„ì— ì„¤ë¦½ëœ ë¯¸êµ­ì˜ ì „ê¸° ìë™ì°¨ ì œì¡°ì—…ì²´, ìë™ì°¨ ê¸°ìˆ  ë° ì•¼ì™¸ ë ˆí¬ë¦¬ì—ì´ì…˜ íšŒì‚¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "**ì£¼ìš” ì •ë³´:**\n",
      "</Document>\n",
      "<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ 'ë¦¬ë¹„ì•ˆ'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source> [ì¶œì²˜: data\\ë¦¬ë¹„ì•ˆ_KR.md]\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰ê¸° ì§€ì •í•˜ì—¬ í…ŒìŠ¤íŠ¸ \n",
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"ë¦¬ë¹„ì•ˆì€ ì–¸ì œ ì‚¬ì—…ì„ ì‹œì‘í–ˆë‚˜ìš”?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query)\n",
    "\n",
    "print(f\"ì¿¼ë¦¬: {query}\")\n",
    "print(\"ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e8cc506b-7b09-436c-892f-f5fb6c3a64bb', metadata={'source': 'data\\\\ë¦¬ë¹„ì•ˆ_KR.md', 'company': 'ë¦¬ë¹„ì•ˆ', 'language': 'ko'}, page_content=\"<Document>\\n- **íšŒì‚¬ ìœ í˜•:** ìƒì¥\\n- **ê±°ë˜ì†Œ:** NASDAQ: RIVN\\n- **ì„¤ë¦½:** 2009ë…„ 6ì›”, í”Œë¡œë¦¬ë‹¤ ì£¼ ë¡ledge\\n- **ì„¤ë¦½ì:** R. J. ìŠ¤ìºë¦°ì§€\\n- **ë³¸ì‚¬:** ë¯¸êµ­ ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼ ì–´ë°”ì¸\\n- **ì„œë¹„ìŠ¤ ì§€ì—­:** ë¶ë¯¸\\n- **ì£¼ìš” ì¸ë¬¼:** R. J. ìŠ¤ìºë¦°ì§€ (CEO)\\n- **ì œí’ˆ:** ì „ê¸° ìë™ì°¨, ë°°í„°ë¦¬\\n- **ìƒì‚°ëŸ‰ (2023):** 57,232ëŒ€\\n- **ì„œë¹„ìŠ¤:** ì „ê¸° ìë™ì°¨ ì¶©ì „, ìë™ì°¨ ë³´í—˜\\n- **ìˆ˜ìµ (2023):** 44ì–µ 3ì²œë§Œ ë¯¸êµ­ ë‹¬ëŸ¬\\n- **ìˆœì´ìµ (2023):** -54ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\\n- **ì´ ìì‚° (2023):** 168ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\\n</Document>\\n<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ 'ë¦¬ë¹„ì•ˆ'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source>\"),\n",
       " Document(id='c2c7dbe9-b8a6-4dca-9ae5-e284009b89b2', metadata={'company': 'ë¦¬ë¹„ì•ˆ', 'language': 'ko', 'source': 'data\\\\ë¦¬ë¹„ì•ˆ_KR.md'}, page_content=\"<Document>\\nRivian Automotive, Inc.ëŠ” 2009ë…„ì— ì„¤ë¦½ëœ ë¯¸êµ­ì˜ ì „ê¸° ìë™ì°¨ ì œì¡°ì—…ì²´, ìë™ì°¨ ê¸°ìˆ  ë° ì•¼ì™¸ ë ˆí¬ë¦¬ì—ì´ì…˜ íšŒì‚¬ì…ë‹ˆë‹¤.\\n\\n**ì£¼ìš” ì •ë³´:**\\n</Document>\\n<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ 'ë¦¬ë¹„ì•ˆ'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source>\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DB ê²€ìƒ‰í•˜ëŠ” ì‚¬ìš©ì ì •ì˜ ë„êµ¬ ìƒì„±\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_db(query: str):\n",
    "    \"\"\"ë¦¬ë¹„ì•ˆ, í…ŒìŠ¬ë¼ íšŒì‚¬ì— ëŒ€í•œ ì •ë³´ë¥¼ ê´€ë ¨ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return chroma_k_retriever.invoke(query)\n",
    "\n",
    "# ë„êµ¬ ì‹¤í–‰\n",
    "search_db.invoke(\"ë¦¬ë¹„ì•ˆì€ ì–¸ì œ ì‚¬ì—…ì„ ì‹œì‘í–ˆë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. **Tool Binding** (ëª¨ë¸ì— Tool ì—°ê²°)\n",
    "\n",
    "- **ëª¨ë¸-ë„êµ¬ ì—°ê²°**ë¡œ ì…ë ¥ ìŠ¤í‚¤ë§ˆ ìë™ ì¸ì‹\n",
    "\n",
    "- **ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ê²€ì¦**ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ì…ë ¥ ë³´ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"<think>\\nOkay, the user is asking for the weather in Seoul. Let me check the available tools. There's a function called get_weather that takes a city parameter from the list of major cities. The cities are Seoul, Busan, Daejeon, Jeju, and Gangwon. Since the user specified Seoul, I should use that function with the city set to Seoul. No need to use the search_db function here. I'll format the tool call accordingly.\\n</think>\\n\\n\" additional_kwargs={} response_metadata={'model': 'qwen3:0.6b', 'created_at': '2025-07-02T01:09:33.7100198Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9789990800, 'load_duration': 5392798300, 'prompt_eval_count': 235, 'prompt_eval_duration': 778298900, 'eval_count': 119, 'eval_duration': 3614919800, 'model_name': 'qwen3:0.6b'} id='run--f23fdff3-46fc-4802-a02c-8f4c98c2cdd0-0' tool_calls=[{'name': 'get_weather', 'args': {'city': 'ì„œìš¸'}, 'id': 'e161e60b-d174-430e-a693-b18c824df3bf', 'type': 'tool_call'}] usage_metadata={'input_tokens': 235, 'output_tokens': 119, 'total_tokens': 354}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# model = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-2.0-flash\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     # other params...\n",
    "# )\n",
    "\n",
    "model = ChatOllama(model=\"qwen3:0.6b\")\n",
    "\n",
    "# ëª¨ë¸\n",
    "# model = ChatOpenAI(model=\"gpt-4.1-mini\",temperature=0)\n",
    "\n",
    "# ë„êµ¬ ëª©ë¡\n",
    "tools = [get_weather, search_db]\n",
    "\n",
    "# ë„êµ¬ë¥¼ ëª¨ë¸ì— ë°”ì¸ë”© (bind_tools ë©”ì†Œë“œ ì‚¬ìš©)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ë„êµ¬ë¥¼ í˜¸ì¶œ\n",
    "result = model_with_tools.invoke(\"ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': 'ì„œìš¸'},\n",
       "  'id': 'e161e60b-d174-430e-a693-b18c824df3bf',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"ì•ˆë…•\" which translates to \"Hello\" in Korean. I need to respond appropriately. Since they\\'re greeting me, I should acknowledge their greeting. Let me check if there\\'s any specific function they need, but looking at the tools provided, there\\'s get_weather and search_db. Neither of these functions are related to a greeting. So I should just respond politely. No tool calls needed here.\\n</think>\\n\\nì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ë¬¸ì œë‚˜ ë„ì›€ì„ ìš”ì²­í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š', additional_kwargs={}, response_metadata={'model': 'qwen3:0.6b', 'created_at': '2025-07-02T01:10:05.0872739Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8740248000, 'load_duration': 30448100, 'prompt_eval_count': 229, 'prompt_eval_duration': 45395200, 'eval_count': 112, 'eval_duration': 8663959400, 'model_name': 'qwen3:0.6b'}, id='run--d90b1c6e-4309-46f6-837b-45b18e935791-0', usage_metadata={'input_tokens': 229, 'output_tokens': 112, 'total_tokens': 341})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(\"ì•ˆë…•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. **Tool Calling** (ëª¨ë¸ì´ Toolì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°)\n",
    "\n",
    "- **ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ì‘ë‹µ** ìƒì„±ìœ¼ë¡œ ì •í™•í•œ ì…ë ¥ í˜•ì‹ ì¤€ìˆ˜\n",
    "\n",
    "- **ìë™ ìœ íš¨ì„± ê²€ì¦**ìœ¼ë¡œ ì˜¤ë¥˜ ë°©ì§€\n",
    "\n",
    "- **êµ¬ì¡°í™”ëœ ì¶œë ¥** ìƒì„±ìœ¼ë¡œ ì‹œìŠ¤í…œ í˜¸í™˜ì„± ë³´ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "additional_kwargs: \n",
      "{'tool_calls': [{'id': 'call_A9zwGeae9GDTMRRiVjgXeoi5', 'function': {'arguments': '{\"city\":\"ì„œìš¸\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "response_metadata: \n",
      "{'token_usage': {'completion_tokens': 14, 'prompt_tokens': 109, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-Bofu4ebKbRL3XMkkRvPiIr5wdc1Wd', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "type: \n",
      "ai\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "id: \n",
      "run--aa3f846e-62c7-4b2b-8383-0d16ce78e9d7-0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "example: \n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_calls: \n",
      "[{'name': 'get_weather', 'args': {'city': 'ì„œìš¸'}, 'id': 'call_A9zwGeae9GDTMRRiVjgXeoi5', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "invalid_tool_calls: \n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage_metadata: \n",
      "{'input_tokens': 109, 'output_tokens': 14, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for k in dict(result).keys():\n",
    "    print(f\"{k}: \")\n",
    "    print(dict(result)[k])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'args': {'city': 'ì„œìš¸'},\n",
      "  'id': 'call_A9zwGeae9GDTMRRiVjgXeoi5',\n",
      "  'name': 'get_weather',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# tool_calls ì¶œë ¥\n",
    "pprint(result.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ìƒ‰ ê²°ê³¼:\n",
      "content: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "additional_kwargs: \n",
      "{'tool_calls': [{'id': 'call_E3ekLKmMfrh7cysvWoqIYGG5', 'function': {'arguments': '{\"query\":\"ë¦¬ë¹„ì•ˆ ì‚¬ì—… ì‹œì‘\"}', 'name': 'search_db'}, 'type': 'function'}], 'refusal': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "response_metadata: \n",
      "{'token_usage': {'completion_tokens': 18, 'prompt_tokens': 114, 'total_tokens': 132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BofwXgzGoBM2LyxLLc0KKlSOmnwXS', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "type: \n",
      "ai\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "id: \n",
      "run--450a4ae1-8fb8-4c57-8e07-4cb6b8bcb7b6-0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "example: \n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_calls: \n",
      "[{'name': 'search_db', 'args': {'query': 'ë¦¬ë¹„ì•ˆ ì‚¬ì—… ì‹œì‘'}, 'id': 'call_E3ekLKmMfrh7cysvWoqIYGG5', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "invalid_tool_calls: \n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage_metadata: \n",
      "{'input_tokens': 114, 'output_tokens': 18, 'total_tokens': 132, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': 'ë¦¬ë¹„ì•ˆ ì‚¬ì—… ì‹œì‘'},\n",
      "  'id': 'call_E3ekLKmMfrh7cysvWoqIYGG5',\n",
      "  'name': 'search_db',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# DB ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ\n",
    "search_result = model_with_tools.invoke(\"ë¦¬ë¹„ì•ˆì€ ì–¸ì œ ì‚¬ì—…ì„ ì‹œì‘í–ˆë‚˜ìš”?\")\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for k in dict(search_result).keys():\n",
    "    print(f\"{k}: \")\n",
    "    print(dict(search_result)[k])\n",
    "    print(\"-\"*100)\n",
    "\n",
    "# tool_calls ì¶œë ¥\n",
    "pprint(search_result.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. **Tool Execution**  (Toolì´ í˜¸ì¶œëœ ê²½ìš° ì‹¤í–‰)\n",
    "\n",
    "- **ì¸ì ê¸°ë°˜ ì‹¤í–‰**ìœ¼ë¡œ ë„êµ¬ ê¸°ëŠ¥ ìˆ˜í–‰\n",
    "\n",
    "- **ëª¨ë¸ ì œê³µ íŒŒë¼ë¯¸í„°**ë¡œ ìë™í™”ëœ ì‹¤í–‰\n",
    "\n",
    "- **ì‹¤í–‰ ê²°ê³¼** ì²˜ë¦¬ ë° ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) í•¨ìˆ˜ì˜ ì¸ìë¥¼ ì§ì ‘ ì „ë‹¬`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'ì„œìš¸'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•¨ìˆ˜ì˜ ì¸ìë¥¼ ì§ì ‘ ì „ë‹¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ -> ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œ\n",
    "result.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ìŒ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather.invoke(result.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'ë¦¬ë¹„ì•ˆ ì‚¬ì—… ì‹œì‘'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e8cc506b-7b09-436c-892f-f5fb6c3a64bb', metadata={'source': 'data\\\\ë¦¬ë¹„ì•ˆ_KR.md', 'language': 'ko', 'company': 'ë¦¬ë¹„ì•ˆ'}, page_content=\"<Document>\\n- **íšŒì‚¬ ìœ í˜•:** ìƒì¥\\n- **ê±°ë˜ì†Œ:** NASDAQ: RIVN\\n- **ì„¤ë¦½:** 2009ë…„ 6ì›”, í”Œë¡œë¦¬ë‹¤ ì£¼ ë¡ledge\\n- **ì„¤ë¦½ì:** R. J. ìŠ¤ìºë¦°ì§€\\n- **ë³¸ì‚¬:** ë¯¸êµ­ ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼ ì–´ë°”ì¸\\n- **ì„œë¹„ìŠ¤ ì§€ì—­:** ë¶ë¯¸\\n- **ì£¼ìš” ì¸ë¬¼:** R. J. ìŠ¤ìºë¦°ì§€ (CEO)\\n- **ì œí’ˆ:** ì „ê¸° ìë™ì°¨, ë°°í„°ë¦¬\\n- **ìƒì‚°ëŸ‰ (2023):** 57,232ëŒ€\\n- **ì„œë¹„ìŠ¤:** ì „ê¸° ìë™ì°¨ ì¶©ì „, ìë™ì°¨ ë³´í—˜\\n- **ìˆ˜ìµ (2023):** 44ì–µ 3ì²œë§Œ ë¯¸êµ­ ë‹¬ëŸ¬\\n- **ìˆœì´ìµ (2023):** -54ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\\n- **ì´ ìì‚° (2023):** 168ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\\n</Document>\\n<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ 'ë¦¬ë¹„ì•ˆ'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source>\"),\n",
       " Document(id='4ba9002a-df79-4498-b120-07b63fc04dc9', metadata={'company': 'ë¦¬ë¹„ì•ˆ', 'source': 'data\\\\ë¦¬ë¹„ì•ˆ_KR.md', 'language': 'ko'}, page_content=\"<Document>\\n**ì—­ì‚¬**\\n\\n**ì´ˆì°½ê¸° (2009â€“15):**\\n\\n- 2009ë…„ R. J. ìŠ¤ìºë¦°ì§€ê°€ Mainstream Motorsë¡œ ì„¤ë¦½.\\n- 2011ë…„ Rivian Automotiveë¡œ ì‚¬ëª… ë³€ê²½.\\n- ì²˜ìŒì—ëŠ” ìŠ¤í¬ì¸ ì¹´ í”„ë¡œí† íƒ€ì…(R1)ì— ì§‘ì¤‘í–ˆì§€ë§Œ ì „ê¸° ë° ììœ¨ ì£¼í–‰ ì°¨ëŸ‰ìœ¼ë¡œ ì „í™˜.\\n\\n**ìƒì‚° ì¤€ë¹„ (2016â€“20):**\\n\\n- 2017ë…„ ì¼ë¦¬ë…¸ì´ ì£¼ ë…¸ë©€ì— ìˆëŠ” ì´ì „ Mitsubishi Motors ì œì¡° ê³µì¥ì„ 1,600ë§Œ ë‹¬ëŸ¬ì— ì¸ìˆ˜.\\n- 2017ë…„ 12ì›”, ì²« ë‘ ì œí’ˆì¸ R1T (í”½ì—… íŠ¸ëŸ­)ì™€ R1S (SUV)ë¥¼ ê³µê°œ.\\n- ìƒì‚°ì€ 2020ë…„ì— ì‹œì‘ë  ì˜ˆì •.\\n\\n**ì²« ëª¨ë¸ ë°°ì†¡; IPO; ê°ì› ë° í™•ì¥ (2021â€“24):**\\n</Document>\\n<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ 'ë¦¬ë¹„ì•ˆ'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source>\")]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_db.invoke(search_result.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ToolCall ê°ì²´ë¥¼ ì „ë‹¬ ì „ë‹¬`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather',\n",
       " 'args': {'city': 'ì„œìš¸'},\n",
       " 'id': 'call_A9zwGeae9GDTMRRiVjgXeoi5',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='ì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ìŒ', name='get_weather', tool_call_id='call_A9zwGeae9GDTMRRiVjgXeoi5')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToolCall ê°ì²´ë¥¼ ì „ë‹¬ ì „ë‹¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ -> ToolMessage ê°ì²´ë¥¼ ë°˜í™˜\n",
    "get_weather.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='[Document(id=\\'e8cc506b-7b09-436c-892f-f5fb6c3a64bb\\', metadata={\\'language\\': \\'ko\\', \\'source\\': \\'data\\\\\\\\ë¦¬ë¹„ì•ˆ_KR.md\\', \\'company\\': \\'ë¦¬ë¹„ì•ˆ\\'}, page_content=\"<Document>\\\\n- **íšŒì‚¬ ìœ í˜•:** ìƒì¥\\\\n- **ê±°ë˜ì†Œ:** NASDAQ: RIVN\\\\n- **ì„¤ë¦½:** 2009ë…„ 6ì›”, í”Œë¡œë¦¬ë‹¤ ì£¼ ë¡ledge\\\\n- **ì„¤ë¦½ì:** R. J. ìŠ¤ìºë¦°ì§€\\\\n- **ë³¸ì‚¬:** ë¯¸êµ­ ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼ ì–´ë°”ì¸\\\\n- **ì„œë¹„ìŠ¤ ì§€ì—­:** ë¶ë¯¸\\\\n- **ì£¼ìš” ì¸ë¬¼:** R. J. ìŠ¤ìºë¦°ì§€ (CEO)\\\\n- **ì œí’ˆ:** ì „ê¸° ìë™ì°¨, ë°°í„°ë¦¬\\\\n- **ìƒì‚°ëŸ‰ (2023):** 57,232ëŒ€\\\\n- **ì„œë¹„ìŠ¤:** ì „ê¸° ìë™ì°¨ ì¶©ì „, ìë™ì°¨ ë³´í—˜\\\\n- **ìˆ˜ìµ (2023):** 44ì–µ 3ì²œë§Œ ë¯¸êµ­ ë‹¬ëŸ¬\\\\n- **ìˆœì´ìµ (2023):** -54ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\\\\n- **ì´ ìì‚° (2023):** 168ì–µ ë¯¸êµ­ ë‹¬ëŸ¬\\\\n</Document>\\\\n<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ \\'ë¦¬ë¹„ì•ˆ\\'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source>\"), Document(id=\\'4ba9002a-df79-4498-b120-07b63fc04dc9\\', metadata={\\'source\\': \\'data\\\\\\\\ë¦¬ë¹„ì•ˆ_KR.md\\', \\'language\\': \\'ko\\', \\'company\\': \\'ë¦¬ë¹„ì•ˆ\\'}, page_content=\"<Document>\\\\n**ì—­ì‚¬**\\\\n\\\\n**ì´ˆì°½ê¸° (2009â€“15):**\\\\n\\\\n- 2009ë…„ R. J. ìŠ¤ìºë¦°ì§€ê°€ Mainstream Motorsë¡œ ì„¤ë¦½.\\\\n- 2011ë…„ Rivian Automotiveë¡œ ì‚¬ëª… ë³€ê²½.\\\\n- ì²˜ìŒì—ëŠ” ìŠ¤í¬ì¸ ì¹´ í”„ë¡œí† íƒ€ì…(R1)ì— ì§‘ì¤‘í–ˆì§€ë§Œ ì „ê¸° ë° ììœ¨ ì£¼í–‰ ì°¨ëŸ‰ìœ¼ë¡œ ì „í™˜.\\\\n\\\\n**ìƒì‚° ì¤€ë¹„ (2016â€“20):**\\\\n\\\\n- 2017ë…„ ì¼ë¦¬ë…¸ì´ ì£¼ ë…¸ë©€ì— ìˆëŠ” ì´ì „ Mitsubishi Motors ì œì¡° ê³µì¥ì„ 1,600ë§Œ ë‹¬ëŸ¬ì— ì¸ìˆ˜.\\\\n- 2017ë…„ 12ì›”, ì²« ë‘ ì œí’ˆì¸ R1T (í”½ì—… íŠ¸ëŸ­)ì™€ R1S (SUV)ë¥¼ ê³µê°œ.\\\\n- ìƒì‚°ì€ 2020ë…„ì— ì‹œì‘ë  ì˜ˆì •.\\\\n\\\\n**ì²« ëª¨ë¸ ë°°ì†¡; IPO; ê°ì› ë° í™•ì¥ (2021â€“24):**\\\\n</Document>\\\\n<Source>ì´ ë¬¸ì„œëŠ” ë¯¸êµ­ ì „ê¸°ì°¨ íšŒì‚¬ì¸ \\'ë¦¬ë¹„ì•ˆ\\'ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.</Source>\")]', name='search_db', tool_call_id='call_E3ekLKmMfrh7cysvWoqIYGG5')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_db.invoke(search_result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Tool Calling ì‚¬ìš© ì‹œ **ê³ ë ¤ì‚¬í•­**\n",
    "\n",
    "- **ëª¨ë¸ í˜¸í™˜ì„±**ì´ Tool Calling ì„±ëŠ¥ì— ì§ì ‘ ì˜í–¥\n",
    "\n",
    "- **ëª…í™•í•œ ë„êµ¬ ì •ì˜**ê°€ ëª¨ë¸ì˜ ì´í•´ë„ì™€ í™œìš©ë„ í–¥ìƒ\n",
    "\n",
    "- **ë‹¨ìˆœí•œ ê¸°ëŠ¥**ì˜ ë„êµ¬ê°€ ë” íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™\n",
    "\n",
    "- **ê³¼ë‹¤í•œ ë„êµ¬**ëŠ” ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ ìœ ë°œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ 10:20ë¶„ê¹Œì§€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Agent**\n",
    "\n",
    "- **LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)** ì„ ì˜ì‚¬ê²°ì • ì—”ì§„ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ\n",
    "\n",
    "- ëª¨ë¸ì€ ì…ë ¥ëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ **ë§¥ë½ì— ë§ëŠ” ì˜ì‚¬ê²°ì •**ì„ ìˆ˜í–‰\n",
    "\n",
    "- ì‹œìŠ¤í…œì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì´í•´í•˜ê³  **ì ì ˆí•œ í•´ê²°ì±…**ì„ ì œì‹œ\n",
    "\n",
    "- ë³µì¡í•œ ì‘ì—…ì„ ìë™í™”í•˜ì—¬ **ì—…ë¬´ íš¨ìœ¨ì„±**ì„ ë†’ì¼ ìˆ˜ ìˆìŒ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **AgentExecutor** \n",
    "\n",
    "- **AgentExecutor**ëŠ” LangChainì˜ ê¸°ë³¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œìŠ¤í…œ\n",
    "\n",
    "- ì—ì´ì „íŠ¸ì˜ **ê³„íš-ì‹¤í–‰-ê´€ì°°** ì‚¬ì´í´ì„ ìë™ìœ¼ë¡œ ê´€ë¦¬\n",
    "\n",
    "- ì—ì´ì „íŠ¸ì˜ í–‰ë™ì„ **ëª¨ë‹ˆí„°ë§**í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ì¶”ê°€ ë„êµ¬ ì •ì˜`\n",
    "\n",
    "- **@tool ë°ì½”ë ˆì´í„°**ë¥¼ ì‚¬ìš©í•´ ê³„ì‚°(íŒŒì´ì¬ ì½”ë“œ ì‹¤í–‰) ê¸°ëŠ¥ì„ ê°€ì§„ **ì»¤ìŠ¤í…€ ë„êµ¬ë¥¼ ì •ì˜**\n",
    "\n",
    "- ë°ì½”ë ˆì´í„°ë¥¼ í†µí•´ í•¨ìˆ˜ê°€ **Tool Calling ì‹œìŠ¤í…œì— ë“±ë¡**ë˜ì–´ LLMì´ í˜¸ì¶œ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return eval(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë„êµ¬ ì‹¤í–‰ \n",
    "calculate.invoke(\"3+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿`\n",
    "\n",
    "- **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**ì€ ì—ì´ì „íŠ¸ì˜ **ê¸°ë³¸ í–‰ë™ê³¼ ì‘ë‹µ ë°©ì‹**ì„ ì •ì˜í•˜ëŠ” ì§€ì¹¨\n",
    "\n",
    "- ì—ì´ì „íŠ¸ì˜ **ì¼ê´€ëœ ì‘ë‹µ**ê³¼ **íš¨ìœ¨ì ì¸ ë„êµ¬ ì‚¬ìš©**ì„ ìœ„í•œ ê¸°ë³¸ í‹€ ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” AI Assistantì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ë¶€ì‚° ë‚ ì”¨ ì–´ë•Œ?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” AI Assistantì…ë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‹¤í–‰\n",
    "response = prompt.invoke({\n",
    "    \"input\": \"ë¶€ì‚° ë‚ ì”¨ ì–´ë•Œ?\",\n",
    "    \"agent_scratchpad\": []  # ì—ì´ì „íŠ¸ ìŠ¤í¬ë˜ì¹˜íŒ¨ë“œ (ë©”ì‹œì§€ ê¸°ë¡)\n",
    "})\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‹¤í–‰ ê²°ê³¼\n",
    "pprint(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) LLM ì§€ì •`\n",
    "\n",
    "- **ChatGPT ëª¨ë¸**ì´ ì—ì´ì „íŠ¸ì˜ **í•µì‹¬ ì¶”ë¡  ì—”ì§„**ìœ¼ë¡œ ì‚¬ìš©ë¨\n",
    "\n",
    "- ëª¨ë¸ì€ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ê³  **ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒ**í•˜ì—¬ ì‘ì—… ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Agent (ì—ì´ì „íŠ¸) ìƒì„±`\n",
    "\n",
    "- **ì—ì´ì „íŠ¸**ëŠ” LLMê³¼ ë„êµ¬ë¥¼ **í†µí•©**í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ\n",
    "\n",
    "- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ê¸°ë°˜ìœ¼ë¡œ **ì‚¬ìš©ì ìš”ì²­ì„ í•´ì„**í•˜ê³  ì ì ˆí•œ ë„êµ¬ ì„ íƒ\n",
    "\n",
    "- ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ **ìµœì¢… ì‘ë‹µì„ ìƒì„±**í•˜ëŠ” ì›Œí¬í”Œë¡œìš° êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# ë„êµ¬ ëª©ë¡ ìƒì„± \n",
    "tools = [get_weather, search_db, calculate]\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„± (ë„êµ¬ í˜¸ì¶œ)\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) AgentExecutor (ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°) ìƒì„±`\n",
    "\n",
    "- **AgentExecutor**ëŠ” ì—ì´ì „íŠ¸ì˜ **ì‘ì—… íë¦„ì„ ê´€ë¦¬**í•˜ê³  ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "- ì‚¬ìš©ì ì…ë ¥ë¶€í„° ìµœì¢… ì¶œë ¥ê¹Œì§€ì˜ **ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ìœ¨**í•˜ê³  ì œì–´\n",
    "\n",
    "- ì—ëŸ¬ ì²˜ë¦¬, ë¡œê¹…, ê²°ê³¼ í¬ë§·íŒ… ë“± **ì‹œìŠ¤í…œ ìš´ì˜ì— í•„ìš”í•œ ê¸°ëŠ¥** ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„±\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,      # ë„êµ¬ í˜¸ì¶œ ì—ì´ì „íŠ¸\n",
    "    tools=tools,      # ë„êµ¬ ëª©ë¡\n",
    "    verbose=True,     # ìƒì„¸ ë¡œê·¸ ì¶œë ¥\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_weather` with `{'city': 'ì„œìš¸'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ìŒ\u001b[0m\u001b[32;1m\u001b[1;3mì„œìš¸ì˜ ë‚ ì”¨ëŠ” ë§‘ìŒì…ë‹ˆë‹¤. ë” ê¶ê¸ˆí•œ ì  ìˆìœ¼ì‹ ê°€ìš”?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": \"ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?', 'output': 'ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ë§‘ìŒì…ë‹ˆë‹¤. ë” ê¶ê¸ˆí•œ ì  ìˆìœ¼ì‹ ê°€ìš”?'}\n"
     ]
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calculate` with `{'expression': '32+18'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m50\u001b[0m\u001b[32;1m\u001b[1;3m32 ë”í•˜ê¸° 18ì€ 50ì…ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„±\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,      # ë„êµ¬ í˜¸ì¶œ ì—ì´ì „íŠ¸\n",
    "    tools=tools,      # ë„êµ¬ ëª©ë¡\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True  # ì¤‘ê°„ ë‹¨ê³„ ë°˜í™˜ (ê¸°ë³¸ê°’ False)\n",
    "    )\n",
    "\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": \"32 ë”í•˜ê¸° 18ì€ ì–¼ë§ˆì¸ê°€ìš”?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '32 ë”í•˜ê¸° 18ì€ ì–¼ë§ˆì¸ê°€ìš”?',\n",
      " 'intermediate_steps': [(ToolAgentAction(tool='calculate', tool_input={'expression': '32+18'}, log=\"\\nInvoking: `calculate` with `{'expression': '32+18'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_jHpne1B1DhKBZMPcIuUzSfxZ', 'function': {'arguments': '{\"expression\":\"32+18\"}', 'name': 'calculate'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'service_tier': 'default'}, id='run--cdb5de1e-c610-4d3b-888c-c25ee3ad9803', tool_calls=[{'name': 'calculate', 'args': {'expression': '32+18'}, 'id': 'call_jHpne1B1DhKBZMPcIuUzSfxZ', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'calculate', 'args': '{\"expression\":\"32+18\"}', 'id': 'call_jHpne1B1DhKBZMPcIuUzSfxZ', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_jHpne1B1DhKBZMPcIuUzSfxZ'),\n",
      "                         50)],\n",
      " 'output': '32 ë”í•˜ê¸° 18ì€ 50ì…ë‹ˆë‹¤.'}\n"
     ]
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. **LangGraph** \n",
    "\n",
    "- **LangGraph**ëŠ” LangChainì˜ í™•ì¥ ë„êµ¬ë¡œ **ê³ ê¸‰ ì—ì´ì „íŠ¸ ê°œë°œ**ì„ ì§€ì›\n",
    "\n",
    "- **ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°**ë¥¼ í†µí•´ ë³µì¡í•œ ì—ì´ì „íŠ¸ ë¡œì§ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŒ \n",
    "\n",
    "- ìƒíƒœ ê´€ë¦¬ì™€ **íƒ€ì… ì•ˆì „ì„±**ì„ í†µí•´ ì•ˆì •ì ì¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ë³´ì¥\n",
    "\n",
    "- AgentExecutorë³´ë‹¤ ë” **ìœ ì—°í•œ ì‚¬ìš©ì ì •ì˜**ê°€ ê°€ëŠ¥í•¨ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ë„êµ¬ ì‹¤í–‰ ì—ì´ì „íŠ¸ ì •ì˜`\n",
    "\n",
    "- LangGraphì˜ **react agent executor**ëŠ” ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ ìƒíƒœë¥¼ ê´€ë¦¬\n",
    "\n",
    "- ì—ì´ì „íŠ¸ì˜ ì¶œë ¥ì— **ë„êµ¬ í˜¸ì¶œ**ì´ ì—†ì„ ë•Œê¹Œì§€ ë©”ì‹œì§€ë¥¼ ê³„ì† ì²˜ë¦¬í•¨\n",
    "\n",
    "- ì‹œì‘ ì‹œ **ì´ˆê¸° ë©”ì‹œì§€ ëª©ë¡**ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "\n",
    "- ì‹¤í–‰ ê²°ê³¼ë¡œ ì „ì²´ **ëŒ€í™” ê¸°ë¡**ì„ í¬í•¨í•œ ê·¸ë˜í”„ ìƒíƒœë¥¼ ë°˜í™˜\n",
    "\n",
    "- **ë©”ì‹œì§€ ê¸°ë°˜ ìƒíƒœ** ê´€ë¦¬ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ì˜ ì‹¤í–‰ íë¦„ì„ ì²´ê³„ì ìœ¼ë¡œ ì œì–´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# ë„êµ¬ ëª©ë¡ ìƒì„± \n",
    "tools = [get_weather, calculate, search_db]\n",
    "\n",
    "# ë„êµ¬ ì‹¤í–‰ ì—ì¸ì „íŠ¸ ìƒì„±\n",
    "langgraph_agent_executor = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ì—ì´ì „íŠ¸ ì‹¤í–‰`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='32 ê³±í•˜ê¸° 18ì€ ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}, id='a450c767-857b-4600-be19-88abd9304a2c'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_b3VU85gMrkCgCf2wFslX8nUr', 'function': {'arguments': '{\"expression\":\"32 * 18\"}', 'name': 'calculate'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 134, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bogd5uFjQRLA2FmT7ivq8uDJ73bL0', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a4a85af4-00ea-40ab-871f-933aa54b928b-0', tool_calls=[{'name': 'calculate', 'args': {'expression': '32 * 18'}, 'id': 'call_b3VU85gMrkCgCf2wFslX8nUr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 134, 'output_tokens': 16, 'total_tokens': 150, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='576', name='calculate', id='c9adebaa-f473-46c3-9aba-2b610dedcced', tool_call_id='call_b3VU85gMrkCgCf2wFslX8nUr'),\n",
      "              AIMessage(content='32 ê³±í•˜ê¸° 18ì€ 576ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 158, 'total_tokens': 170, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bogd6GSskfaitSRqajY3ijn4JDfAC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d48ea82f-eabf-4b2d-b0ff-5232375f0c0a-0', usage_metadata={'input_tokens': 158, 'output_tokens': 12, 'total_tokens': 170, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "messages = langgraph_agent_executor.invoke(\n",
    "    {\"messages\": [(\"human\", \"32 ê³±í•˜ê¸° 18ì€ ì–¼ë§ˆì¸ê°€ìš”?\")]}\n",
    ")\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥\n",
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 ê³±í•˜ê¸° 18ì€ 576ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(messages['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktds-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
