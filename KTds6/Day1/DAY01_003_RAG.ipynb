{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f191d1cf",
   "metadata": {},
   "source": [
    "#  RAG 체인 구성\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ec21",
   "metadata": {},
   "source": [
    "## RAG란 무엇인가?\n",
    "\n",
    "### 🎯 핵심 개념\n",
    "**Retrieval Augmented Generation (RAG)** 는 대규모 언어 모델(LLM)에 외부 지식을 연결하여 더 정확하고 최신의 정보를 제공하는 AI 프레임워크입니다.\n",
    "\n",
    "### 🔍 RAG의 작동 원리\n",
    "```\n",
    "사용자 질문 → 관련 문서 검색 → 컨텍스트와 함께 LLM에 전달 → 답변 생성\n",
    "```\n",
    "\n",
    "### 📊 RAG vs 일반 LLM 비교\n",
    "| 구분 | 일반 LLM | RAG |\n",
    "|------|----------|-----|\n",
    "| 정보 소스 | 사전 훈련 데이터만 | 외부 지식베이스 + 사전 훈련 데이터 |\n",
    "| 최신성 | 훈련 시점까지 | 실시간 업데이트 가능 |\n",
    "| 정확성 | 환각(hallucination) 가능성 | 검증된 문서 기반 답변 |\n",
    "| 사용 사례 | 일반적인 질문 답변 | 특정 도메인의 전문적 답변 |\n",
    "\n",
    "---\n",
    "\n",
    "## 환경 설정\n",
    "\n",
    "### 🛠️ 필수 라이브러리 설치\n",
    "\n",
    "```bash\n",
    "# 기본 LangChain 패키지\n",
    "pip install langchain langchain-community \n",
    "\n",
    "# 임베딩 모델\n",
    "pip install langchain-openai langchain-huggingface\n",
    "\n",
    "# 벡터 저장소\n",
    "pip install langchain-chroma\n",
    "\n",
    "# 문서 처리\n",
    "pip install pypdf \n",
    "\n",
    "# 웹 스크래핑\n",
    "pip install beautifulsoup4\n",
    "\n",
    "# 토크나이저\n",
    "pip install tiktoken transformers sentence-transformers\n",
    "\n",
    "# 실험적 기능 (SemanticChunker)\n",
    "pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be5eb8",
   "metadata": {},
   "source": [
    "### 🔑 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일 생성\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키 설정 (필요시)\n",
    "# OPENAI_API_KEY=your_openai_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5989430",
   "metadata": {},
   "source": [
    "### 📋 기본 라이브러리 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c23a89",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 문서 로더 (Document Loaders)\n",
    "\n",
    "### 🎯 문서 로더란?\n",
    "**Document Loader**는 다양한 소스에서 문서를 로드하여 LangChain의 `Document` 객체로 변환하는 도구입니다.\n",
    "\n",
    "### 📄 Document 객체 구조\n",
    "```python\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Document 객체의 기본 구조\n",
    "document = Document(\n",
    "    page_content=\"문서의 텍스트 내용\",\n",
    "    metadata={\n",
    "        \"source\": \"문서 출처\",\n",
    "        \"page\": 1,\n",
    "        \"title\": \"문서 제목\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### 📄 문서 로더의 종류\n",
    "- PDF 파일 로더\n",
    "- 웹 페이지 로더 \n",
    "- CSV 데이터 로더\n",
    "- 디렉토리 로더\n",
    "- HTML 데이터 로더\n",
    "- JSON 데이터 로더\n",
    "- Markdown 데이터 로더\n",
    "- Microsoft Office 데이터 로더\n",
    "\n",
    "\n",
    "### 1. 🌐 웹 문서 로더 (WebBaseLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "# 기본 웹 문서 로드\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://python.langchain.com/docs/tutorials/rag/\",\n",
    "        \"https://js.langchain.com/docs/tutorials/rag/\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "web_docs = web_loader.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67940f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"첫 번째 문서 내용:\\n{web_docs[0].page_content[:500]}...\")  # 앞부분만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"첫 번째 문서 메타데이터: {web_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239cbc0",
   "metadata": {},
   "source": [
    "### 2. 📊 CSV 파일 로더 (CSVLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 기본 CSV 로드\n",
    "csv_loader = CSVLoader(\"./data/kbo_teams_2023.csv\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(f\"문서 수: {len(csv_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41430baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"첫 번째 문서 내용:\\n{csv_docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"첫 번째 문서 메타데이터: {csv_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소스 컬럼 지정 및 인코딩 설정\n",
    "csv_loader_advanced = CSVLoader(\n",
    "    file_path=\"./data/kbo_teams_2023.csv\",\n",
    "    source_column=\"Team\",      # 이 컬럼이 메타데이터의 source가 됨\n",
    "    content_columns=[\"Team\", \"Introduction\"],  # 이 컬럼이 문서의 내용이 됨\n",
    "    metadata_columns=[\"Founded\", \"City\"],  # 이 컬럼이 메타데이터에 추가됨\n",
    "    encoding=\"utf-8\",          # 인코딩 명시\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",      # 구분자\n",
    "        \"quotechar\": '\"',      # 인용 문자\n",
    "    }\n",
    ")\n",
    "\n",
    "csv_docs_advanced = csv_loader_advanced.load()\n",
    "\n",
    "# 문서 수와 첫 번째 문서 내용 출력\n",
    "print(f\"문서 수: {len(csv_docs_advanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b02841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"마지막 문서 내용:\\n{csv_docs_advanced[-1].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"마지막 문서 메타데이터: {csv_docs_advanced[-1].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e9558",
   "metadata": {},
   "source": [
    "### 3. 📖 PDF 파일 로더 \n",
    "\n",
    "- **PyPDFLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 초기화\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c964d1",
   "metadata": {},
   "source": [
    "- **다른 PDF 로더들**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    PyMuPDFLoader,\n",
    "    PDFMinerLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28116083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMuPDF 로더 (빠른 처리)\n",
    "pymupdf_loader = PyMuPDFLoader(\"./data/labor_law.pdf\")\n",
    "pdf_docs = pymupdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFMiner 로더 (정확한 텍스트 추출)\n",
    "pdfminer_loader = PDFMinerLoader(\"./data/labor_law.pdf\")\n",
    "pdf_docs = pdfminer_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907759c",
   "metadata": {},
   "source": [
    "### 4. 📝 텍스트 파일 로더 (TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e731e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 단일 텍스트 파일 로드\n",
    "text_loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "text_docs = text_loader.load()\n",
    "\n",
    "print(f\"문서 수: {len(text_docs)}\")\n",
    "print(f\"첫 번째 문서 내용:\\n{text_docs[0].page_content[:1000]}\")  # 첫 1000자 출력\n",
    "print(f\"첫 번째 문서 메타데이터: {text_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디렉토리 내 모든 텍스트 파일 로드\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "directory_loader = DirectoryLoader(\n",
    "    \"./data/\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "all_text_docs = directory_loader.load()\n",
    "\n",
    "print(f\"전체 문서 수: {len(all_text_docs)}\")\n",
    "print(f\"첫 번째 문서 내용:\\n{all_text_docs[0].page_content[:1000]}\")  # 첫 1000자 출력\n",
    "print(f\"첫 번째 문서 메타데이터: {all_text_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cb485",
   "metadata": {},
   "source": [
    "### 🎯 실습 1: 웹 문서 로더 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 웹 페이지들을 로드하고 메타데이터를 출력해보세요\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/concepts/\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb33946",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 텍스트 분할 (Text Splitting)\n",
    "\n",
    "### 🎯 텍스트 분할이 필요한 이유\n",
    "1. **토큰 제한**: LLM은 입력 토큰 수에 제한이 있음\n",
    "2. **검색 정확도**: 작은 청크가 더 정확한 검색 결과 제공\n",
    "3. **메모리 효율성**: 대용량 문서의 효율적 처리\n",
    "\n",
    "### 📊 분할 전략 비교\n",
    "| 방법 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|----------|\n",
    "| CharacterTextSplitter | 단순, 빠름 | 문맥 고려 안함 | 간단한 텍스트 |\n",
    "| RecursiveCharacterTextSplitter | 문맥 보존 우수 | 계산 복잡 | 일반적인 문서 |\n",
    "| SemanticChunker | 의미 기반 분할 | 느림, 비용 많음 | 중요한 문서 |\n",
    "| TokenTextSplitter | 정확한 토큰 수 | 토크나이저 의존 | API 비용 최적화 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 로더 초기화\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf', mode='single')  # 'single' 또는 'page' 모드 선택 가능\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa31164",
   "metadata": {},
   "source": [
    "### 1. CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = pdf_docs[0].page_content\n",
    "print(f'첫 번째 문서의 텍스트 길이: {len(long_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 기본 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",        # 구분자\n",
    "    chunk_size=1000,         # 청크 크기\n",
    "    chunk_overlap=200,       # 중복 크기\n",
    "    length_function=len,     # 길이 측정 함수\n",
    "    is_separator_regex=False # 정규식 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "print(f\"분할된 청크 수: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 기본 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",        # 구분자\n",
    "    chunk_size=1000,         # 청크 크기\n",
    "    chunk_overlap=200,       # 중복 크기\n",
    "    length_function=len,     # 길이 측정 함수\n",
    "    is_separator_regex=False # 정규식 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "print(f\"분할된 청크 수: {len(chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:10]):\n",
    "    print(f\"청크 {i+1} 길이: {len(chunk)} 문자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3dedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "# 법률 문서와 공문서에 적합한 문장 분할 정규식 패턴\n",
    "# 문장 끝 후 공백이 있고, 특정 패턴이 따라오지 않는 경우만 분할 (목록 번호나 조항 번호 앞, 괄호로 된 항목 표시 앞, 기타 구두점 앞)\n",
    "sentence_pattern = r'(?<=[.!?])\\s+(?!\\s*(?:\\d+|호|조|항|]|\\)|[가-힣]{1,2}\\s*\\)|[A-Za-z]\\s*\\)|[,;:]))'\n",
    "\n",
    "# 정규식을 사용한 문장 단위 분할기 생성\n",
    "sentence_splitter = CharacterTextSplitter(\n",
    "    separator=sentence_pattern,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    is_separator_regex=True,\n",
    "    keep_separator=True\n",
    ")\n",
    "\n",
    "# 문장 단위로 분할\n",
    "sentence_chunks = sentence_splitter.split_text(long_text)\n",
    "print(f\"문장 단위로 분할된 청크 수: {len(sentence_chunks)}\")\n",
    "for i, chunk in enumerate(sentence_chunks[:10]):\n",
    "    print(f\"청크 {i+1} 길이: {len(chunk)} 문자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac488bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"첫 번째 문서 청크 내용: {sentence_chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"두 번째 문서 청크 내용: {sentence_chunks[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"세 번째 문서 청크 내용: {sentence_chunks[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824d6d1",
   "metadata": {},
   "source": [
    "### 2. RecursiveCharacterTextSplitter\n",
    "\n",
    "- 재귀적으로 텍스트를 분할하여 문맥을 최대한 보존하는 분할 도구\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 기본 재귀 분할기\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 우선순위 순서 (큰 구분자부터 작은 구분자 순서로 재귀적 분할)\n",
    ")\n",
    "\n",
    "# Document 객체 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "\n",
    "# 각 청크의 길이 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"청크 {i+1}: {len(chunk.page_content)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe18e1",
   "metadata": {},
   "source": [
    "### 3. 토큰 기반 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34cd7a",
   "metadata": {},
   "source": [
    "#### 🔧 TikToken 토크나이저 기반 분할\n",
    "- OpenAI 임베딩 모델이 사용하는 토크나이저를 사용하여 정확한 토큰 수로 텍스트를 분할하는 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 토크나이저 사용\n",
    "token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # GPT-4 인코딩\n",
    "    chunk_size=500,              # 토큰 수 기준\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = token_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "# 토큰 수 확인\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer.encode(chunk.page_content))\n",
    "    print(f\"청크 {i+1}: {token_count} 토큰, {len(chunk.page_content)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ba7a0",
   "metadata": {},
   "source": [
    "#### 🤗 Hugging Face 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50854e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# BGE-M3 토크나이저 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "hf_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = hf_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "# 토큰 수 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer(chunk.page_content)[\"input_ids\"])\n",
    "    print(f\"청크 {i+1}: {token_count} 토큰, {len(chunk.page_content)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bbc2e",
   "metadata": {},
   "source": [
    "### 4. **Semantic Chunking**\n",
    "\n",
    "- **SemanticChunker**는 텍스트를 의미 단위로 **분할**하는 특수한 텍스트 분할도구 \n",
    "\n",
    "- 단순 길이 기반이 아닌 **의미 기반**으로 텍스트를 청크화하는데 효과적\n",
    "\n",
    "- **breakpoint_threshold_type**: Text Splitting의 다양한 임계값(Threshold) 설정 방식 (통계적 기법) \n",
    "\n",
    "    - **Gradient** 방식: 임베딩 벡터 간의 **기울기 변화**를 기준으로 텍스트를 분할\n",
    "    - **Percentile** 방식: 임베딩 거리의 **백분위수**를 기준으로 분할 지점을 결정 (기본값: 95%)\n",
    "    - **Standard Deviation** 방식: 임베딩 거리의 **표준편차**를 활용하여 유의미한 변화점을 찾아서 분할\n",
    "    - **Interquartile** 방식: 임베딩 거리의 **사분위수 범위**를 기준으로 이상치를 감지하여 분할\n",
    "\n",
    "- 설치: pip install langchain_experimental 또는 uv add langchain_experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker \n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델을 사용하여 SemanticChunker를 초기화 \n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),         # OpenAI 임베딩 사용\n",
    "    breakpoint_threshold_type=\"gradient\",  # 임계값 타입 설정 (gradient, percentile, standard_deviation, interquartile)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956587ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568bc61e",
   "metadata": {},
   "source": [
    "### 🎯 실습 2: 텍스트 분할 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 텍스트를 다양한 방법으로 분할하고 결과를 비교해보세요\n",
    "sample_text = \"\"\"\n",
    "인공지능은 현대 기술의 핵심입니다. \n",
    "머신러닝을 통해 컴퓨터는 학습할 수 있습니다.\n",
    "\n",
    "딥러닝은 신경망을 기반으로 합니다.\n",
    "자연어 처리는 텍스트를 이해하는 기술입니다.\n",
    "\n",
    "컴퓨터 비전은 이미지를 분석합니다.\n",
    "강화학습은 행동을 통해 학습합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec29fae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 문서 임베딩 (Document Embedding)\n",
    "\n",
    "### 🎯 임베딩이란?\n",
    "텍스트를 고차원 벡터 공간의 숫자 배열로 변환하여 의미적 유사도를 계산할 수 있게 하는 기술입니다.\n",
    "\n",
    "### 📊 임베딩 모델 비교\n",
    "| 모델 | 차원 | 언어 지원 | 비용 | 성능 | 사용 사례 |\n",
    "|------|------|----------|------|------|----------|\n",
    "| OpenAI text-embedding-3-small | 1536 | 다국어 | 유료 | 높음 | 프로덕션 |\n",
    "| OpenAI text-embedding-3-large | 3072 | 다국어 | 유료 | 최고 | 고성능 요구 |\n",
    "| BAAI/bge-m3 | 1024 | 다국어 | 무료 | 높음 | 한국어 특화 |\n",
    "| sentence-transformers/all-MiniLM-L6-v2 | 384 | 영어 | 무료 | 중간 | 로컬 개발 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d3272",
   "metadata": {},
   "source": [
    "### 1. OpenAI 임베딩\n",
    "\n",
    "#### 🔧 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 기본 임베딩 모델\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536,           # 차원 수 (기본값)\n",
    "    show_progress_bar=True,    # 진행률 표시\n",
    "    max_retries=3             # 재시도 횟수\n",
    ")\n",
    "\n",
    "print(f\"임베딩 차원: {embeddings_model.dimensions}\")\n",
    "print(f\"컨텍스트 길이: {embeddings_model.embedding_ctx_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9801824",
   "metadata": {},
   "source": [
    "#### 📝 문서 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19286db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 컬렉션 임베딩\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 이미지를 분석하는 기술입니다.\"\n",
    "]\n",
    "\n",
    "# 배치 임베딩 (효율적)\n",
    "doc_embeddings = embeddings_model.embed_documents(documents)\n",
    "print(f\"임베딩 벡터 수: {len(doc_embeddings)}\")\n",
    "print(f\"각 벡터 차원: {len(doc_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 임베딩\n",
    "query = \"AI 기술에 대해 알려주세요\"\n",
    "query_embedding = embeddings_model.embed_query(query)\n",
    "print(f\"쿼리 임베딩 차원: {len(query_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67317e58",
   "metadata": {},
   "source": [
    "#### 💡 차원 축소 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab31808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 절약을 위한 차원 축소\n",
    "compact_embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    "    dimensions=512  # 원래 1536에서 512로 축소\n",
    ")\n",
    "\n",
    "# 성능과 비용의 균형점 찾는 것이 중요!!!\n",
    "compact_doc_embeddings = compact_embeddings.embed_documents(documents)\n",
    "print(f\"축소된 임베딩 벡터 수: {len(compact_doc_embeddings)}\")\n",
    "print(f\"축소된 각 벡터 차원: {len(compact_doc_embeddings[0])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137bbef1",
   "metadata": {},
   "source": [
    "### 2. Hugging Face 임베딩\n",
    "\n",
    "#### 🤗 BGE-M3 모델 (한국어 우수)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83222ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# BGE-M3 모델 (다국어, 한국어 성능 우수)\n",
    "embeddings_bge = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={'device': 'cpu'},        # 'cuda' for GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}  # L2 정규화 - 벡터의 각 차원을 벡터의 L2 노름(크기)으로 나누어 단위 벡터로 변환 (벡터 크기 1로 정규화)\n",
    ")\n",
    "\n",
    "# BGE-M3 모델로 문서 임베딩\n",
    "bge_hf_embeddings = embeddings_bge.embed_documents(documents)\n",
    "print(f\"한국어 임베딩 차원: {len(bge_hf_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a79ffb",
   "metadata": {},
   "source": [
    "#### 📱 경량 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빠른 처리를 위한 경량 모델\n",
    "embedding_gte = HuggingFaceEmbeddings(\n",
    "    model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "    model_kwargs={'device': 'cpu', 'trust_remote_code': True},  # trust_remote_code 필요 \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "    \n",
    "# 경량 모델로 문서 임베딩\n",
    "alibaba_hf_embeddings = embedding_gte.embed_documents(documents)\n",
    "print(f\"경량 모델 한국어 임베딩 차원: {len(alibaba_hf_embeddings[0])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc083cd",
   "metadata": {},
   "source": [
    "### 3. Ollama 임베딩 (로컬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Ollama 서버가 실행 중이어야 함\n",
    "embeddings_ollama = OllamaEmbeddings(\n",
    "    model=\"bge-m3\",                    # 사용할 모델\n",
    "    # base_url=\"http://localhost:11434\"  # Ollama 서버 주소\n",
    ")\n",
    "\n",
    "# 로컬 임베딩\n",
    "local_embeddings = embeddings_ollama.embed_documents(documents)\n",
    "\n",
    "print(f\"로컬 임베딩 벡터 수: {len(local_embeddings)}\")\n",
    "print(f\"각 벡터 차원: {len(local_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441df2cb",
   "metadata": {},
   "source": [
    "### 4. 유사도 계산 및 검색\n",
    "\n",
    "#### 📏 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_most_similar(query, doc_embeddings, documents, embeddings_model):\n",
    "    \"\"\"가장 유사한 문서 찾기\"\"\"\n",
    "    # 쿼리 임베딩\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    \n",
    "    # 가장 유사한 문서 인덱스\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    \n",
    "    return {\n",
    "        \"document\": documents[most_similar_idx],\n",
    "        \"similarity\": similarities[most_similar_idx],\n",
    "        \"index\": most_similar_idx\n",
    "    }\n",
    "\n",
    "# 쿼리와 문서 임베딩을 사용하여 가장 유사한 문서 찾기 (OpenAI)\n",
    "query = \"딥러닝에 대해 알려주세요\"\n",
    "result = find_most_similar(query, doc_embeddings, documents, embeddings_model)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d78393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFaceEmbeddings를 사용한 유사도 검색 (BGE-M3)\n",
    "result = find_most_similar(query, bge_hf_embeddings, documents, embeddings_bge)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alibaba-NLP/gte-multilingual-base 모델로 유사도 검색\n",
    "result = find_most_similar(query, alibaba_hf_embeddings, documents, embedding_gte)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157eced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama 모델로 유사도 검색 (bge-m3)\n",
    "result = find_most_similar(query, local_embeddings, documents, embeddings_ollama)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d40c4",
   "metadata": {},
   "source": [
    "### 🎯 실습 3: 임베딩 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 질문들에 대해 다른 임베딩 모델들의 검색 성능을 비교해보세요\n",
    "queries = [\n",
    "    \"기계학습이란 무엇인가요?\",\n",
    "    \"이미지 인식 기술에 대해 설명해주세요\",\n",
    "    \"언어 모델의 작동 원리는?\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ffa75",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 벡터 저장소 (Vector Store)\n",
    "\n",
    "### 🎯 벡터 저장소란?\n",
    "임베딩된 벡터를 효율적으로 저장하고 유사도 기반 검색을 수행하는 특수 데이터베이스\n",
    "\n",
    "### 📊 벡터 저장소 비교\n",
    "| 종류 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|----------|\n",
    "| Chroma | 설치 간단, 로컬 친화적 | 대용량 처리 한계 | 개발, 프로토타입 |\n",
    "| FAISS | 매우 빠름, 확장성 우수 | 설정 복잡 | 대용량 검색 |\n",
    "| Pinecone | 완전 관리형, 고성능 | 유료, 클라우드 의존 | 프로덕션 |\n",
    "| Weaviate | GraphQL 지원, 하이브리드 검색 | 학습 곡선 | 복합 검색 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bd40b",
   "metadata": {},
   "source": [
    "### 🚀 Chroma 설치 및 설정\n",
    "```bash\n",
    "pip install langchain-chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb5d82",
   "metadata": {},
   "source": [
    "#### 📚 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서 준비\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf', mode='single')\n",
    "pdf_docs = pdf_loader.load()\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "\n",
    "# 임베딩 모델\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma 벡터 저장소 생성\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"labor_law\",\n",
    "    persist_directory=\"./local_chroma_db\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}  # 유사도 메트릭\n",
    ")\n",
    "\n",
    "print(f\"저장된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d65858",
   "metadata": {},
   "source": [
    "#### 💾 벡터 저장소 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d62249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 벡터 저장소 로드\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./local_chroma_db\"\n",
    ")\n",
    "\n",
    "print(f\"로드된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581bc215",
   "metadata": {},
   "source": [
    "#### 🔍 기본 검색 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 유사도 검색\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "similar_docs = chroma_db.similarity_search(\n",
    "    query=query,\n",
    "    k=5,  # 상위 5개 결과\n",
    "    filter={\"source\": \"./data/labor_law.pdf\"}  # 메타데이터 필터\n",
    ")\n",
    "\n",
    "print(f\"검색 결과 수: {len(similar_docs)}\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 점수와 함께 검색 (유사도 점수 포함)\n",
    "docs_with_scores = chroma_db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for doc, score in docs_with_scores:\n",
    "    print(f\"점수: {score:.4f}\")\n",
    "    print(f\"내용: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e9d91",
   "metadata": {},
   "source": [
    "#### 🎛️ 메타데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합 필터 조건\n",
    "filter_criteria = {\n",
    "    \"$and\": [\n",
    "        {\"source\": {\"$eq\": \"./data/labor_law.pdf\"}},\n",
    "        {\"page\": {\"$gte\": 10}}  # 10페이지 이상\n",
    "    ]\n",
    "}\n",
    "\n",
    "filtered_results = chroma_db.similarity_search(\n",
    "    query=query,\n",
    "    k=5,\n",
    "    filter=filter_criteria, \n",
    ")\n",
    "\n",
    "print(f\"필터링된 검색 결과 수: {len(filtered_results)}\")\n",
    "for i, doc in enumerate(filtered_results):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366f2ff",
   "metadata": {},
   "source": [
    "#### 🔄 문서 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9dab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 문서 추가\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "new_docs = [Document(page_content=\"새로운 내용\", metadata={\"source\": \"new\"})]\n",
    "chroma_db.add_documents(new_docs, ids=[\"new_doc_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ab92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 삭제 (ID 기반)\n",
    "chroma_db.delete(ids=[\"new_doc_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 컬렉션 삭제\n",
    "# chroma_db.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64df58",
   "metadata": {},
   "source": [
    "### 🎯 실습 4: 벡터 저장소 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 단계로 나만의 벡터 저장소를 구축해보세요:\n",
    "# 1. 웹에서 문서 로드\n",
    "# 2. 적절한 크기로 분할\n",
    "# 3. 임베딩 및 저장\n",
    "# 4. 검색 테스트\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528dd45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 검색기 (Retriever)\n",
    "\n",
    "### 🎯 Retriever란?\n",
    "벡터 저장소를 기반으로 사용자 질의에 가장 관련성 높은 문서를 검색하는 인터페이스입니다.\n",
    "\n",
    "### 📊 검색 전략 비교\n",
    "| 전략 | 설명 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|------|----------|\n",
    "| similarity | 단순 유사도 검색 | 빠름, 직관적 | 다양성 부족 | 일반적인 검색 |\n",
    "| similarity_score_threshold | 임계값 기반 검색 | 품질 보장 | 결과 수 불안정 | 고품질 결과 필요 |\n",
    "| mmr | 최대 한계 관련성 | 다양성 우수 | 느림 | 포괄적 정보 필요 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e572d",
   "metadata": {},
   "source": [
    "### 1. 기본 유사도 검색\n",
    "\n",
    "#### 🔍 Top-K 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소를 Retriever로 변환\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # 상위 5개 결과\n",
    ")\n",
    "\n",
    "# 검색 실행\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"문서 {i+1}:\")\n",
    "    print(f\"내용: {doc.page_content[:200]}...\")\n",
    "    print(f\"출처: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d1339",
   "metadata": {},
   "source": [
    "### 2. 임계값 기반 검색\n",
    "\n",
    "#### 📏 점수 임계값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 점수 임계값 기반 검색\n",
    "threshold_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.3,  # 0.3 이상의 유사도만\n",
    "        \"k\": 10                  # 최대 10개까지\n",
    "    }\n",
    ")\n",
    "\n",
    "retrieved_docs = threshold_retriever.invoke(query)\n",
    "\n",
    "# 실제 유사도 점수 확인\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    # 실제 유사도 계산\n",
    "    doc_embedding = embeddings.embed_query(doc.page_content)\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "    \n",
    "    print(f\"문서 {i+1} (유사도: {similarity:.4f}):\")\n",
    "    print(f\"{doc.page_content[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f5a0c",
   "metadata": {},
   "source": [
    "### 3. MMR (Maximal Marginal Relevance) 검색\n",
    "\n",
    "#### 🎯 다양성을 고려한 검색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR 검색 - 관련성과 다양성의 균형\n",
    "mmr_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # 최종 반환할 문서 수\n",
    "        \"fetch_k\": 20,         # 초기 후보 문서 수\n",
    "        \"lambda_mult\": 0.5     # 관련성 vs 다양성 (0=최대 다양성, 1=최대 관련성)\n",
    "    }\n",
    ")\n",
    "\n",
    "mmr_docs = mmr_retriever.invoke(query)\n",
    "\n",
    "print(\"MMR 검색 결과:\")\n",
    "for i, doc in enumerate(mmr_docs):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d898f7d",
   "metadata": {},
   "source": [
    "#### 🔧 lambda_mult 파라미터 실험\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 lambda_mult 값으로 실험\n",
    "lambda_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    retriever = chroma_db.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"fetch_k\": 10,\n",
    "            \"lambda_mult\": lambda_val\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    docs = retriever.invoke(query)\n",
    "    print(f\"\\nLambda {lambda_val} 결과:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"  {i+1}. {doc.page_content[:100]}...\")\n",
    "    \n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40825374",
   "metadata": {},
   "source": [
    "#### 🎛️ 메타데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e00bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터 기반 필터링 retriever\n",
    "filtered_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"filter\": {\n",
    "            \"source\": \"./data/labor_law.pdf\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "filtered_results = filtered_retriever.invoke(query)\n",
    "\n",
    "print(\"메타데이터 기반 필터링 결과:\")\n",
    "for i, doc in enumerate(filtered_results):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656541aa",
   "metadata": {},
   "source": [
    "#### 🔄 동적 검색 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739cbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicRetriever:\n",
    "    def __init__(self, vectorstore, embeddings):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.embeddings = embeddings\n",
    "    \n",
    "    def retrieve(self, query, search_type=\"auto\", k=5):\n",
    "        \"\"\"쿼리 특성에 따라 동적으로 검색 전략 선택\"\"\"\n",
    "        \n",
    "        # 쿼리 복잡도 분석\n",
    "        query_length = len(query.split())\n",
    "        \n",
    "        if query_length <= 3:\n",
    "            # 짧은 쿼리: 높은 임계값\n",
    "            search_type = \"similarity_score_threshold\"\n",
    "            search_kwargs = {\"score_threshold\": 0.25, \"k\": k}\n",
    "        elif query_length > 10:\n",
    "            # 긴 쿼리: MMR로 다양성 확보\n",
    "            search_type = \"mmr\"\n",
    "            search_kwargs = {\"k\": k, \"fetch_k\": k*3, \"lambda_mult\": 0.3}\n",
    "        else:\n",
    "            # 중간 길이: 기본 유사도 검색\n",
    "            search_type = \"similarity\"\n",
    "            search_kwargs = {\"k\": k}\n",
    "        \n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_type=search_type,\n",
    "            search_kwargs=search_kwargs\n",
    "        )\n",
    "        \n",
    "        return retriever.invoke(query)\n",
    "\n",
    "# 사용 예시\n",
    "dynamic_retriever = DynamicRetriever(chroma_db, embeddings)\n",
    "\n",
    "queries = [\n",
    "    \"탄력근로\",  # 짧은 쿼리\n",
    "    \"탄력 근로에 대해 설명해주세요\",  # 중간 쿼리\n",
    "    \"탄력 근로 제도의 장점과 단점, 그리고 실제 적용 사례를 포함하여 자세히 설명해주세요\"  # 긴 쿼리\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n쿼리: {query}\")\n",
    "    print(f\"길이: {len(query.split())} 단어\")\n",
    "    docs = dynamic_retriever.retrieve(query)\n",
    "    print(f\"검색 결과: {len(docs)}개 문서\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e667b",
   "metadata": {},
   "source": [
    "### 🎯 실습 5: 검색 전략 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 질문에 대해 다른 검색 전략들의 결과를 비교해보세요\n",
    "test_query = \"근로시간 단축에 대한 규정은 무엇인가요?\"\n",
    "\n",
    "strategies = {\n",
    "    \"similarity\": {\"k\": 5},\n",
    "    \"similarity_score_threshold\": {\"score_threshold\": 0.3, \"k\": 10},\n",
    "    \"mmr\": {\"k\": 5, \"fetch_k\": 15, \"lambda_mult\": 0.5}\n",
    "}\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5231bd3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RAG 체인 구현\n",
    "\n",
    "### 🎯 RAG 체인이란?\n",
    "검색(Retrieval)과 생성(Generation)을 연결하여 외부 지식을 기반으로 답변을 생성하는 파이프라인\n",
    "\n",
    "### 🔄 RAG 워크플로우\n",
    "`\n",
    "사용자 질문 → 관련 문서 검색 → 컨텍스트 구성 → LLM 프롬프트 → 답변 생성\n",
    "`\n",
    "\n",
    "### 1. 프롬프트 템플릿 설계\n",
    "\n",
    "#### 📝 기본 RAG 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 기본 RAG 프롬프트 템플릿\n",
    "basic_template = \"\"\"주어진 컨텍스트를 기반으로 질문에 답변하세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "basic_prompt = ChatPromptTemplate.from_template(basic_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b3127",
   "metadata": {},
   "source": [
    "#### 🎨 고급 RAG 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c836c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_template = \"\"\"당신은 전문적인 문서 분석 AI입니다. 주어진 컨텍스트를 바탕으로 정확하고 유용한 답변을 제공하세요.\n",
    "\n",
    "## 답변 지침\n",
    "- 컨텍스트에 있는 정보만을 사용하여 답변하세요\n",
    "- 확실하지 않은 정보는 \"명확하지 않습니다\"라고 명시하세요\n",
    "- 답변은 논리적이고 구조화된 형태로 제공하세요\n",
    "- 가능한 경우 구체적인 예시나 수치를 포함하세요\n",
    "- 답변에 참조한 문서의 출처가 있다면 포함하세요 (문서명, 페이지, URL 등)\n",
    "\n",
    "## 컨텍스트\n",
    "{context}\n",
    "\n",
    "## 질문\n",
    "{question}\n",
    "\n",
    "## 답변 형식\n",
    "**핵심 답변:** (질문에 대한 직접적인 답변)\n",
    "\n",
    "**세부 설명:** (추가적인 설명이나 배경 정보)\n",
    "\n",
    "**관련 정보:** (컨텍스트에서 발견된 연관 정보)\n",
    "\n",
    "**답변:**\"\"\"\n",
    "\n",
    "advanced_prompt = ChatPromptTemplate.from_template(advanced_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cdf3ac",
   "metadata": {},
   "source": [
    "#### 🌟 도메인별 특화 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_template = \"\"\"당신은 법률 문서 전문 AI입니다. 법률 조항을 정확히 해석하고 설명해주세요.\n",
    "\n",
    "## 법률 해석 원칙\n",
    "- 조문의 정확한 인용을 포함하세요\n",
    "- 법적 용어는 일반인이 이해할 수 있도록 설명하세요\n",
    "- 예외 조항이나 단서가 있다면 반드시 언급하세요\n",
    "- 관련 법령이나 시행령도 함께 언급하세요\n",
    "\n",
    "## 관련 법률 조항\n",
    "{context}\n",
    "\n",
    "## 법률 질의\n",
    "{question}\n",
    "\n",
    "## 법률 답변\n",
    "**해당 조항:** (관련 법률 조항 인용)\n",
    "\n",
    "**조항 해석:** (조항의 의미와 적용 범위)\n",
    "\n",
    "**주의사항:** (예외 조항이나 제한 사항)\n",
    "\n",
    "**답변:**\"\"\"\n",
    "\n",
    "legal_prompt = ChatPromptTemplate.from_template(legal_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2074b",
   "metadata": {},
   "source": [
    "### 2. LLM 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.1,                   # 일관성 있는 답변\n",
    "    max_completion_tokens=1000,        # 답변 길이 제한\n",
    "    top_p=0.9,              # 다양성 제어\n",
    "    frequency_penalty=0.1,  # 반복 방지\n",
    "    presence_penalty=0.1    # 새로운 단어 장려\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54638f88",
   "metadata": {},
   "source": [
    "### 3. RAG 체인 구성\n",
    "\n",
    "#### 🔗 기본 LCEL 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"문서 리스트를 문자열로 포맷\"\"\"\n",
    "    return \"\\n\\n\".join([\n",
    "        f\"{doc.page_content}\" for doc in docs\n",
    "    ])\n",
    "\n",
    "# 기본 RAG 체인\n",
    "basic_rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | basic_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "result = basic_rag_chain.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c118a3b",
   "metadata": {},
   "source": [
    "#### 🎯 고급 RAG 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_with_metadata(docs):\n",
    "    \"\"\"메타데이터를 포함한 문서 포맷팅\"\"\"\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        \n",
    "        formatted_doc = f\"\"\"\n",
    "출처: {source}\n",
    "페이지: {page}\n",
    "내용: {doc.page_content}\n",
    "---\n",
    "\"\"\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    \n",
    "    return \"\\n\".join(formatted_docs)\n",
    "\n",
    "\n",
    "# 고급 RAG 체인\n",
    "advanced_rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": retriever | format_docs_with_metadata,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | advanced_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "result = advanced_rag_chain.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc6522",
   "metadata": {},
   "source": [
    "### 🎯 실습 6: 완전한 RAG 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 요구사항을 만족하는 RAG 시스템을 구축해보세요:\n",
    "# 1. 여러 문서 형식 지원 (PDF, 웹, 텍스트)\n",
    "# 2. 동적 검색 전략 선택\n",
    "# 3. 도메인별 프롬프트 템플릿\n",
    "# 4. 응답 품질 평가\n",
    "\n",
    "class ComprehensiveRAGSystem:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_documents(self, sources):\n",
    "        \"\"\"다양한 소스에서 문서 로드\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "    \n",
    "    def setup_vector_store(self, documents):\n",
    "        \"\"\"벡터 저장소 구성\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "    \n",
    "    def query(self, question, domain=\"general\"):\n",
    "        \"\"\"도메인별 질의응답\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "\n",
    "# 여기에 구현 코드를 작성하세요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kt-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
