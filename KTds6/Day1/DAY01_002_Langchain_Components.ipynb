{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChain의 개념과 주요 컴포넌트 이해\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LangChain 소개\n",
    "\n",
    "### 1.1 LangChain이란?\n",
    "**LangChain**은 대화형 AI 애플리케이션을 쉽게 개발할 수 있도록 도와주는 프레임워크입니다.\n",
    "\n",
    "#### 📦 핵심 가치\n",
    "- **모듈화**: 독립적인 컴포넌트를 조합하여 복잡한 AI 시스템 구축\n",
    "- **상호운용성**: 다양한 AI 모델과 데이터 소스를 하나의 인터페이스로 통합\n",
    "- **확장성**: 간단한 챗봇부터 복잡한 AI 에이전트까지 확장 가능\n",
    "- **관찰성**: LangSmith를 통한 실시간 모니터링 및 디버깅\n",
    "\n",
    "#### 📦 핵심 아키텍처\n",
    "```markdown\n",
    "**LangChain 생태계**\n",
    "├── langchain-core     # 기본 추상화 및 인터페이스\n",
    "├── langchain         # 체인, 에이전트, 검색 전략\n",
    "├── langchain-openai  # OpenAI 통합\n",
    "├── langchain-anthropic # Anthropic 통합\n",
    "├── LangGraph        # 복잡한 에이전트 워크플로우\n",
    "└── LangSmith        # 모니터링 및 디버깅\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://python.langchain.com/svg/langchain_stack_112024_dark.svg\" \n",
    "        alt=\"langchain_stack\" \n",
    "        width=\"600\" \n",
    "        style=\"border: 0;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 환경 설정\n",
    "\n",
    "### 2.1 설치\n",
    "\n",
    "```bash\n",
    "# pip 설치\n",
    "pip install langchain langchain-openai langchain-google-genai\n",
    "\n",
    "# uv 설치 \n",
    "uv add langchain langchain-openai langchain-google-genai\n",
    "\n",
    "# 추가 도구 pip 설치 (선택사항)\n",
    "pip install langchain-ollama langsmith\n",
    "\n",
    "# 추가 도구 uv 설치 (선택사항)\n",
    "uv add langchain-ollama langsmith\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 API 키 설정\n",
    "```python\n",
    "# .env 파일 생성\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "GOOGLE_API_KEY=your_google_api_key_here\n",
    "\n",
    "# LangSmith 설정 (선택사항)\n",
    "LANGSMITH_API_KEY=your_langsmith_api_key\n",
    "LANGSMITH_TRACING=true\n",
    "LANGSMITH_PROJECT=your_project_name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적 확인\n",
    "import os\n",
    "print(f\"LangSmith 추적: {os.getenv('LANGSMITH_TRACING')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 핵심 컴포넌트\n",
    "\n",
    "### 3.1 Chat Models (채팅 모델)\n",
    "\n",
    "- OpenAI, Anthropic, Google 등 다양한 모델을 지원\n",
    "- 텍스트 생성, 대화, 요약 등의 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\", \n",
    "    temperature=0.3,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "# 간단한 대화\n",
    "response = model.invoke(\"탄소의 원자 번호는 무엇인가요?\")\n",
    "print(f\"답변: {response.content}\")\n",
    "print(f\"메타데이터: {response.response_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Messages (메시지)\n",
    "\n",
    "- 메시지는 AI와의 대화에서 역할을 구분하는 기본 단위입니다.\n",
    "- 메시지는 사용자, AI, 시스템 등 다양한 역할을 가질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 시스템 메시지: AI의 역할 정의\n",
    "system_msg = SystemMessage(content=\"당신은 친절한 화학 선생님입니다.\")\n",
    "\n",
    "# 사용자 메시지\n",
    "human_msg = HumanMessage(content=\"탄소의 원자 번호는 몇 번인가요?\")\n",
    "\n",
    "# 대화 실행\n",
    "messages = [system_msg, human_msg]\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Prompt Templates (프롬프트 템플릿)\n",
    "\n",
    "- 템플릿을 사용하여 일관된 프롬프트를 생성할 수 있습니다.\n",
    "- 변수 치환을 통해 동적인 프롬프트를 적용하는 데 유용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📦 기본 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 전문가 템플릿\n",
    "template = \"\"\"\n",
    "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\n",
    "질문: {question}\n",
    "답변: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿 입력 변수 확인\n",
    "print(f\"필수 변수: {prompt.input_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿 확인\n",
    "print(f\"템플릿: {prompt.template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿 사용\n",
    "formatted_prompt = prompt.format(\n",
    "    topic=\"화학\",\n",
    "    question=\"탄소의 원자 번호는 무엇인가요?\"\n",
    ")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📦 채팅 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 채팅용 템플릿\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 전문 {subject} 상담사입니다.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = chat_template.invoke({\n",
    "    \"subject\": \"진로\",\n",
    "    \"question\": \"데이터 사이언티스트가 되려면 어떤 공부를 해야 하나요?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿 확인\n",
    "pprint(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지 속성 확인\n",
    "pprint(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. LCEL (LangChain Expression Language)\n",
    "\n",
    "### 4.1 LCEL이란?\n",
    "**LCEL**은 `|` 연산자를 사용하여 컴포넌트들을 순차적으로 연결하는 선언적 체이닝을 지원합니다.\n",
    "\n",
    "#### 📦 핵심 특징\n",
    "- **재사용성**: 정의된 체인을 다른 체인의 컴포넌트로 활용\n",
    "- **다양한 실행 방식**: `.invoke()`, `.batch()`, `.stream()`, `.astream()`\n",
    "- **자동 최적화**: 배치 처리 시 효율적인 작업 수행\n",
    "- **스키마 지원**: 입력/출력 스키마 자동 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 기본 체인 구성\n",
    "\n",
    "#### 📦 Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\\n\"\n",
    "    \"질문: {question}\\n답변: \"\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | llm\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"화학\",\n",
    "    \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
    "})\n",
    "\n",
    "print(f\"답변: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📦 Prompt + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 파서 추가\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 완전한 체인 구성\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 체인 실행 (문자열 반환)\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"화학\",\n",
    "    \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
    "})\n",
    "\n",
    "print(f\"답변: {response}\")  # 이제 문자열로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. LangSmith 모니터링\n",
    "\n",
    "### 5.1 LangSmith란?\n",
    "**LangSmith**는 LLM 애플리케이션의 관찰성(Observability)을 제공하는 도구입니다.\n",
    "\n",
    "#### 📦 주요 기능\n",
    "- **체인 실행 로깅 및 추적**\n",
    "- **프롬프트 디버깅**\n",
    "- **성능 측정 및 분석**\n",
    "- **실시간 모니터링**\n",
    "\n",
    "### 5.2 LangSmith 설정\n",
    "\n",
    "#### 📦 계정 가입 및 설정\n",
    "```python\n",
    "# 1. LangSmith 계정 가입: https://www.langchain.com/langsmith\n",
    "# 2. .env 파일 설정\n",
    "LANGSMITH_API_KEY=your_langsmith_api_key\n",
    "LANGSMITH_TRACING=true\n",
    "LANGSMITH_PROJECT=your_project_name\n",
    "\n",
    "# 3. 환경 확인\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(f\"LangSmith 추적 상태: {os.getenv('LANGSMITH_TRACING')}\")\n",
    "print(f\"프로젝트명: {os.getenv('LANGSMITH_PROJECT')}\")\n",
    "```\n",
    "\n",
    "### 5.3 자동 추적\n",
    "\n",
    "LangSmith가 설정되면 모든 체인 실행이 자동으로 추적됩니다:\n",
    "\n",
    "```python\n",
    "# 체인 실행 시 자동으로 LangSmith에 로그 전송\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"인공지능\",\n",
    "    \"question\": \"머신러닝과 딥러닝의 차이점은?\"\n",
    "})\n",
    "\n",
    "# LangSmith 대시보드에서 실행 과정 확인 가능:\n",
    "# - 각 단계별 실행 시간\n",
    "# - 입력/출력 데이터\n",
    "# - 토큰 사용량\n",
    "# - 에러 추적\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Runnable 인터페이스\n",
    "\n",
    "### 6.1 Runnable 개념\n",
    "모든 LangChain 컴포넌트는 **Runnable 인터페이스**를 구현하여 일관된 방식으로 실행됩니다.\n",
    "\n",
    "#### 📦 주요 Runnable 유형\n",
    "- `RunnableSequence`: 순차적 실행\n",
    "- `RunnableParallel`: 병렬 실행\n",
    "- `RunnablePassthrough`: 입력 전달\n",
    "- `RunnableLambda`: 함수 래핑\n",
    "\n",
    "### 6.2 RunnableSequence (순차 실행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 전용 체인 (파이프 연산자 사용)\n",
    "translation_prompt = PromptTemplate.from_template(\n",
    "    \"'{text}'를 영어로 번역해주세요. 번역된 문장만을 출력해주세요.\"\n",
    ")\n",
    "\n",
    "translation_chain = translation_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 번역 실행\n",
    "result = translation_chain.invoke({\"text\": \"좋은 하루 되세요!\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# 명시적 RunnableSequence 생성\n",
    "translation_chain = RunnableSequence(\n",
    "    first=translation_prompt, \n",
    "    middle=[llm],\n",
    "    last=StrOutputParser()\n",
    ")\n",
    "\n",
    "# 파이프 연산자와 동일한 결과\n",
    "# translation_chain = translation_prompt | llm | StrOutputParser()\n",
    "\n",
    "result = translation_chain.invoke({\"text\": \"좋은 하루 되세요!\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 RunnableParallel (병렬 실행)\n",
    "\n",
    "#### 📦 질문 분석 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1. 주제 분류 체인\n",
    "topic_template = \"\"\"\n",
    "다음 카테고리 중 하나로 분류하세요:\n",
    "- 화학(Chemistry)\n",
    "- 물리(Physics)  \n",
    "- 생물(Biology)\n",
    "\n",
    "위 3가지 카테고리만 사용하세요.\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "topic_prompt = PromptTemplate.from_template(topic_template)\n",
    "topic_chain = topic_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 실행\n",
    "result = topic_chain.invoke({\n",
    "    \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
    "})\n",
    "print(f\"주제 분류: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 언어 감지 체인\n",
    "language_template = \"\"\"\n",
    "입력된 텍스트의 언어를 분류하세요:\n",
    "- 한국어(Korean)\n",
    "- 영어(English)\n",
    "- 기타(Others)\n",
    "\n",
    "위 3가지 카테고리만 사용하세요.\n",
    "\n",
    "입력: {question}\n",
    "\"\"\"\n",
    "\n",
    "language_prompt = PromptTemplate.from_template(language_template)\n",
    "language_chain = language_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 실행\n",
    "result = language_chain.invoke({\n",
    "    \"question\": \"What is the atomic number of Carbon?\"\n",
    "})\n",
    "print(f\"언어 분류: {result}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 답변 생성 체인\n",
    "answer_template = \"\"\"\n",
    "당신은 {topic} 분야의 전문가입니다. \n",
    "{language}로 다음 질문에 답변해주세요.\n",
    "\n",
    "질문: {question}\n",
    "답변: \"\"\"\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(answer_template)\n",
    "\n",
    "# 4. 병렬 처리 체인 구성\n",
    "analysis_chain = RunnableParallel({\n",
    "    \"topic\": topic_chain,\n",
    "    \"language\": language_chain,\n",
    "    \"question\": itemgetter(\"question\")\n",
    "})\n",
    "\n",
    "# 5. 전체 체인 연결\n",
    "complete_chain = analysis_chain | answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 실행\n",
    "result = complete_chain.invoke({\n",
    "    \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
    "})\n",
    "print(f\"최종 답변: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 감정 분석 파이프라인 (예제)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "# 요약 프롬프트\n",
    "summarize_prompt = PromptTemplate.from_template(\n",
    "    \"다음 텍스트를 한 문장으로 요약해주세요: {text}\"\n",
    ")\n",
    "\n",
    "# 감정 분석 프롬프트\n",
    "sentiment_prompt = PromptTemplate.from_template(\"\"\"\n",
    "다음 텍스트의 감정을 분석해주세요.\n",
    "\n",
    "텍스트: {summary}\n",
    "\n",
    "규칙:\n",
    "1. 반드시 '긍정', '부정', '중립' 중 하나의 단어로만 답변하세요\n",
    "2. 다른 설명이나 부가 정보는 포함하지 마세요\n",
    "\n",
    "답변:\n",
    "\"\"\")\n",
    "\n",
    "# 체인 구성\n",
    "summarize_chain = summarize_prompt | llm\n",
    "sentiment_chain = sentiment_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 전체 파이프라인\n",
    "analysis_pipeline = (\n",
    "    summarize_chain \n",
    "    | RunnableParallel(\n",
    "        summary=lambda x: x.content,\n",
    "        sentiment=lambda x: sentiment_chain.invoke({\"summary\": x.content}),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 테스트 텍스트\n",
    "text = \"\"\"오늘 시험을 봤는데 정말 잘 본 것 같아요. \n",
    "몇 주 동안 열심히 공부한 보람이 있네요. \n",
    "결과가 나오면 좋은 점수를 받을 수 있을 것 같아서 기대됩니다.\"\"\"\n",
    "\n",
    "result = analysis_pipeline.invoke({\"text\": text})\n",
    "print(f\"요약: {result['summary']}\")\n",
    "print(f\"감정 분석: {result['sentiment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. 실습 문제\n",
    "\n",
    "#### 🌟 문제 1: LCEL 기본 체인 만들기\n",
    "- 사용자가 입력한 주제에 대해 3줄 요약 제공\n",
    "- 온도는 0.5로 설정\n",
    "- 문자열 출력 파서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🌟 문제 2: RunnableParallel 활용\n",
    "- 하나의 입력에 대해 번역과 요약을 동시에 수행하는 체인을 만드세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "from langchain_core.runnables import RunnableParallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 🔗 유용한 링크\n",
    "\n",
    "- [LangChain 공식 문서](https://python.langchain.com/docs/introduction/)\n",
    "- [LangSmith 가이드](https://docs.smith.langchain.com/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kt-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
