{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   LangGraph 활용 - 메모리 타입\n",
    "\n",
    "- **Short-term Memory (단기 메모리)**: 단일 대화 세션 내에서 상호작용을 추적\n",
    "- **Long-term Memory (장기 메모리)**: 세션 간에 사용자별 또는 애플리케이션 수준의 데이터를 저장\n",
    "\n",
    "![Memory Types](https://langchain-ai.github.io/langgraph/concepts/img/memory/short-vs-long.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추적 활성화, false: langsmith 추적 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 레스토랑 메뉴 도구 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma 인덱스 로드 \n",
    "menu_db = Chroma(\n",
    "    embedding_function=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "wine_db = Chroma(\n",
    "    embedding_function=embeddings_model,   \n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_menu(query: str, k: int = 2) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=k)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "@tool\n",
    "def search_wine(query: str, k: int = 2) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant wine menu information from the encrypted database.\n",
    "    Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = wine_db.similarity_search(query, k=k)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **장기 메모리 (Long-term Memory)**\n",
    "\n",
    "- **LangGraph Store** 시스템은 다중 세션에서 정보를 유지하는 장기 메모리 기능을 제공\n",
    "\n",
    "- 세션이 끝나도 유지되는 영구적인 메모리로, 사용자별 정보, 학습된 지식, 경험 등을 저장\n",
    "\n",
    "- 정보는 **JSON 문서** 형태로 저장되며, 사용자가 정의한 **네임스페이스**와 고유 키로 구성\n",
    "\n",
    "- 메모리 저장소는 **InMemoryStore** 또는 **DB 기반** 시스템을 선택하여 구현 가능\n",
    "\n",
    "- **콘텐츠 필터**를 통해 여러 네임스페이스 간의 효율적인 검색 가능\n",
    "\n",
    "\n",
    "- **Store vs Checkpointer 비교:**\n",
    "\n",
    "    | 구분 | Store (장기 메모리) | Checkpointer (단기 메모리) |\n",
    "    |------|-------------------|------------------------|\n",
    "    | **범위** | 모든 세션/스레드 공유 | 단일 스레드 내 |\n",
    "    | **생명주기** | 영구적 | 세션 종료시 소멸 |\n",
    "    | **용도** | 사용자 프로필, 지식 베이스 | 대화 히스토리, 상태 |\n",
    "    | **접근 방식** | 키-값 저장소 | 체크포인트 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **InMemoryStore** 이해와 구현\n",
    "\n",
    "- LangGraph에서 **스레드(대화) 간에 정보를 공유**하고 저장하기 위한 인터페이스\n",
    "\n",
    "- **namespace 기반 저장**: 메모리는 계층적 데이터 구조 namespace로 구분되어 저장 (예: (user_id, \"memories\"))\n",
    "\n",
    "- **key-value 저장**: 각 메모리는 고유한 key와 dictionary 형태의 value로 저장\n",
    "\n",
    "- **시맨틱 검색 지원**: 임베딩 모델을 사용하여 의미 기반 검색이 가능\n",
    "\n",
    "- **체크포인터와 연동**: 그래프의 체크포인터와 함께 동작하여 스레드 간 정보 공유 가능\n",
    "\n",
    "    ```python\n",
    "    # Store의 기본 개념\n",
    "    namespace = (\"user_123\", \"preferences\")  # 계층적 네임스페이스\n",
    "    key = \"theme_settings\"                   # 고유 키\n",
    "    value = {\"theme\": \"dark\", \"lang\": \"ko\"}  # 저장할 데이터\n",
    "\n",
    "    # 저장 구조: namespace + key = unique identifier\n",
    "    # (\"user_123\", \"preferences\") + \"theme_settings\" → 유일한 저장 위치\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 기본 사용법`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "import uuid\n",
    "\n",
    "# 기본 Store (영구 저장만)\n",
    "store = InMemoryStore()\n",
    "\n",
    "# namespace 정의 \n",
    "user_id = \"user_1\"\n",
    "namespace = (user_id, \"memories\")\n",
    "\n",
    "# 데이터 저장 (PUT)\n",
    "memory_id = str(uuid.uuid4())\n",
    "memory = {\n",
    "    \"food_preference\": \"김치찌개를 좋아합니다\",\n",
    "    \"hobby\": \"등산\"\n",
    "}\n",
    "store.put(\n",
    "    namespace=namespace, \n",
    "    key=memory_id, \n",
    "    value=memory\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 조회 (GET)\n",
    "\n",
    "# 단일 조회\n",
    "item = store.get(\n",
    "    namespace=(\"user_1\", \"memories\"),\n",
    "    key=memory_id\n",
    ")\n",
    "if item:\n",
    "    print(f\"Value: {item.value}\")\n",
    "    print(f\"Created: {item.created_at}\")\n",
    "    print(f\"Updated: {item.updated_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 (SEARCH)\n",
    "memories = store.search(\n",
    "    namespace,\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "# 검색된 메모리 출력\n",
    "for memory in memories:\n",
    "    pprint(memory.dict())\n",
    "    print(\"-\" * 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 시맨틱 검색 구현`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 함수 정의\n",
    "def embed(texts):\n",
    "    embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    return embeddings_model.embed_documents(texts)\n",
    "\n",
    "# 임베딩 모델을 사용하는 store 생성\n",
    "semantic_store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embed,  # 임베딩 함수 지정\n",
    "        \"dims\": 1536,    # 임베딩 차원 지정\n",
    "        \"fields\": [\"food_preference\", \"hobby\"]  # 임베딩할 필드 지정\n",
    "    }  #type:ignore\n",
    ")  \n",
    "\n",
    "# 여러 메모리 저장\n",
    "memories_to_store = [\n",
    "    {\n",
    "        \"food_preference\": \"매운 음식을 좋아합니다\",\n",
    "        \"hobby\": \"영화 감상\",\n",
    "        \"confidence\": 0.9\n",
    "    },\n",
    "    {\n",
    "        \"food_preference\": \"한식을 선호합니다\",\n",
    "        \"hobby\": \"등산과 캠핑\",\n",
    "        \"confidence\": 0.8\n",
    "    },\n",
    "    {\n",
    "        \"food_preference\": \"양식을 좋아합니다\",\n",
    "        \"hobby\": \"요리\",\n",
    "        \"confidence\": 0.7\n",
    "    }\n",
    "]\n",
    "\n",
    "for memory in memories_to_store:\n",
    "\n",
    "    memory_id = str(uuid.uuid4())\n",
    "\n",
    "    semantic_store.put(\n",
    "        namespace=namespace,\n",
    "        key=memory_id,\n",
    "        value=memory\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 검색 (시맨틱)\n",
    "search_results = semantic_store.search(\n",
    "    namespace,\n",
    "    query=\"캠핑에 어울리는 영화\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for item in search_results:\n",
    "    print(f\"Key: {item.key}\")\n",
    "    print(f\"Score: {item.score}\")  # 벡터 검색시 유사도\n",
    "    print(f\"Value: {item.value}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터 검색\n",
    "search_results = semantic_store.search(\n",
    "    namespace,\n",
    "    query=\"캠핑에 어울리는 영화\",  # 시맨틱 검색 쿼리\n",
    "    filter={\"hobby\": \"등산과 캠핑\"},  # 필터 조건\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for item in search_results:\n",
    "    print(f\"Key: {item.key}\")\n",
    "    print(f\"Score: {item.score}\")  # 벡터 검색시 유사도\n",
    "    print(f\"Value: {item.value}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합 검색 (벡터 + 필터)\n",
    "search_results = semantic_store.search(\n",
    "    namespace,\n",
    "    query=\"캠핑에 어울리는 영화\",  # 시맨틱 검색 쿼리\n",
    "    filter={\"confidence\": {\"$gt\": 0.8, \"$lt\": 1.0}},  # 필터 조건\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for item in search_results:\n",
    "    print(f\"Key: {item.key}\")\n",
    "    print(f\"Score: {item.score}\")  # 벡터 검색시 유사도\n",
    "    print(f\"Value: {item.value}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. **체크포인트 연동**\n",
    "\n",
    "- **체크포인터와 연동**: 그래프의 체크포인터와 함께 동작하여 스레드 간 정보 공유 가능\n",
    "\n",
    "- **이중 메모리 전략**\n",
    "\n",
    "    1. **단기 메모리 (Thread-scoped)**\n",
    "        - 현재 대화의 최근 4-10개 메시지만 유지\n",
    "        - 나머지는 요약으로 압축\n",
    "        - `RemoveMessage`로 오래된 메시지 삭제\n",
    "\n",
    "    2. **장기 메모리 (Cross-thread)**\n",
    "        - 모든 Q&A를 Store에 영구 저장\n",
    "        - 시맨틱 검색으로 필요시 참조\n",
    "        - 다른 스레드에서도 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any, List\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# ============= State 정의 =============\n",
    "class GraphState(MessagesState):\n",
    "    \"\"\"그래프 상태\"\"\"\n",
    "    summary: str  # 대화 요약\n",
    "    context: str  # 검색된 메모리 컨텍스트\n",
    "\n",
    "\n",
    "# ============= 노드 함수 =============\n",
    "def agent_with_memory(state: GraphState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"\n",
    "    메모리 검색 + 메시지 관리 + LLM 호출을 통합한 에이전트\n",
    "    \"\"\"\n",
    "    try:\n",
    "        user_id = config.get(\"configurable\", {}).get(\"user_id\", \"default\")\n",
    "        namespace = (user_id, \"conversation\")\n",
    "        \n",
    "        messages = state[\"messages\"]\n",
    "        summary = state.get(\"summary\", \"\")\n",
    "        \n",
    "        # ========== 메시지 관리 (10개 초과시 요약 후 삭제) ==========\n",
    "        delete_messages = []\n",
    "        if len(messages) > 10:\n",
    "            # 요약 생성/업데이트\n",
    "            messages_to_summarize = messages[:-4]  # 마지막 4개 제외\n",
    "\n",
    "            if messages_to_summarize:\n",
    "                # 기존 요약이 있으면 확장, 없으면 새로 생성\n",
    "                summary_prompt = (\n",
    "                    f\"{'Previous summary: ' + summary + chr(10) if summary else ''}\"\n",
    "                    f\"Summarize the conversation:\\n\"\n",
    "                    + \"\\n\".join([f\"{type(m).__name__}: {m.content}\" for m in messages_to_summarize])\n",
    "                )\n",
    "                \n",
    "                llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
    "                summary = llm.invoke(f\"Provide a concise summary:\\n{summary_prompt}\").content\n",
    "                \n",
    "                # 오래된 메시지 삭제 마크\n",
    "                delete_messages = [RemoveMessage(id=m.id) for m in messages[:-4]]\n",
    "                messages = messages[-4:]  # 최근 4개만 유지\n",
    "\n",
    "        # ========== 장기 메모리에서 관련 대화 검색 ==========\n",
    "        context = \"\"\n",
    "        if messages:\n",
    "            last_msg = messages[-1]\n",
    "            memories = store.search(namespace, query=last_msg.content, limit=3)\n",
    "            \n",
    "            if memories:\n",
    "                context = \"\\n\".join([\n",
    "                    f\"[{m.value['timestamp']}] Q: {m.value['query']} A: {m.value['response']}...\"\n",
    "                    for m in memories\n",
    "                ])\n",
    "        \n",
    "        # ========== 시스템 프롬프트 구성 ==========\n",
    "        system_content = (\n",
    "            \"You are a helpful assistant with access to conversation history.\\n\"\n",
    "            f\"{f'Previous conversation summary: {summary}' if summary else ''}\\n\"\n",
    "            f\"{f'Related past conversations:{chr(10)}{context}' if context else ''}\"\n",
    "        ).strip()\n",
    "        \n",
    "        system_msg = SystemMessage(system_content)\n",
    "        \n",
    "        # ========== LLM 호출 ==========\n",
    "        llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "        llm_with_tools = llm.bind_tools([search_menu, search_wine])\n",
    "        \n",
    "        model_messages = [system_msg] + messages\n",
    "        response = llm_with_tools.invoke(model_messages)\n",
    "        \n",
    "        # ========== 상태 업데이트 반환 ==========\n",
    "        return {\n",
    "            \"messages\": delete_messages + [response],  # 삭제 메시지 + 새 응답\n",
    "            \"summary\": summary,\n",
    "            \"context\": context\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in agent: {e}\")\n",
    "        return {\"messages\": [AIMessage(f\"Error: {str(e)}\")]}\n",
    "\n",
    "\n",
    "def save_to_memory(state: GraphState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"\n",
    "    현재 대화를 장기 메모리에 저장\n",
    "    \"\"\"\n",
    "    try:\n",
    "        user_id = config.get(\"configurable\", {}).get(\"user_id\", \"default\")\n",
    "        namespace = (user_id, \"conversation\")\n",
    "        \n",
    "        messages = state[\"messages\"]\n",
    "        \n",
    "        # 가장 최근의 연속된 Human-AI 메시지 쌍 찾기\n",
    "        user_msg = None\n",
    "        ai_msg = None\n",
    "        \n",
    "        # 마지막 메시지부터 확인\n",
    "        for i in range(len(messages) - 1, -1, -1):\n",
    "            msg = messages[i]\n",
    "            \n",
    "            # AI 메시지를 먼저 찾음\n",
    "            if isinstance(msg, AIMessage) and not ai_msg:\n",
    "                # Tool 관련 메시지는 스킵\n",
    "                if not hasattr(msg, 'tool_calls') or not msg.tool_calls:\n",
    "                    ai_msg = msg\n",
    "                    ai_msg_idx = i\n",
    "            \n",
    "            # AI 메시지를 찾은 후, 바로 앞의 Human 메시지 찾기\n",
    "            elif ai_msg and isinstance(msg, HumanMessage):\n",
    "                # 연속된 메시지인지 확인 (중간에 다른 메시지 없음)\n",
    "                is_consecutive = True\n",
    "                for j in range(i + 1, ai_msg_idx):\n",
    "                    if isinstance(messages[j], HumanMessage):\n",
    "                        is_consecutive = False\n",
    "                        break\n",
    "                \n",
    "                if is_consecutive:\n",
    "                    user_msg = msg\n",
    "                    break\n",
    "        \n",
    "        # 메모리 저장\n",
    "        if user_msg and ai_msg:\n",
    "            memory = {\n",
    "                \"query\": user_msg.content,\n",
    "                \"response\": ai_msg.content,\n",
    "                \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"summary\": state.get(\"summary\", \"\"),\n",
    "                \"thread_id\": config.get(\"configurable\", {}).get(\"thread_id\"),\n",
    "                \"message_count\": len(messages)  # 디버깅용\n",
    "            }\n",
    "            \n",
    "            memory_id = f\"{datetime.now().timestamp()}_{uuid.uuid4().hex[:8]}\"\n",
    "            store.put(namespace, memory_id, memory)\n",
    "            print(f\"💾 Saved memory: {memory_id[:30]}...\")\n",
    "            print(f\"   Q: {user_msg.content[:50]}...\")\n",
    "            print(f\"   A: {ai_msg.content[:50]}...\")\n",
    "            print(f\"   Num: {memory['message_count']}\")\n",
    "        else:\n",
    "            print(\"⚠️  No valid Q&A pair found to save\")\n",
    "\n",
    "        return state\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving memory: {e}\")\n",
    "        return state\n",
    "\n",
    "\n",
    "\n",
    "# 임베딩 함수 정의\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    return embeddings_model.embed_documents(texts)\n",
    "\n",
    "# 임베딩 모델을 사용하는 메모리 스토어 설정\n",
    "conversation_store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embed,  # 임베딩 함수 지정\n",
    "        \"dims\": 1536,    # 임베딩 차원 지정\n",
    "        \"fields\": [\"query\", \"response\", \"summary\"]  # 임베딩할 필드 지정\n",
    "    }  #type:ignore\n",
    ")  \n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"agent\", agent_with_memory)\n",
    "builder.add_node(\"tools\", ToolNode([search_menu, search_wine]))\n",
    "builder.add_node(\"memory\", save_to_memory)\n",
    "\n",
    "# 엣지 구성\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"tools\", \n",
    "        \"__end__\": \"memory\"\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "builder.add_edge(\"memory\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph_with_store = builder.compile(\n",
    "    checkpointer=InMemorySaver(),\n",
    "    store=conversation_store  \n",
    ")\n",
    "\n",
    "# 그래프 시각화\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph_with_store.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자별 설정\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"thread_001\",\n",
    "        \"user_id\": \"user_123\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# 초기 메시지 설정\n",
    "messages = [HumanMessage(content=\"안녕하세요! 시그니처 메뉴를 추천해주세요.\")]\n",
    "\n",
    "# 그래프 실행 및 결과 출력 (초기 메시지 사용)\n",
    "messages = graph_with_store.invoke({\"messages\": messages}, config=config) \n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 번째 메시지 설정\n",
    "messages = [HumanMessage(content=\"파스타 메뉴도 알려주세요.\")]\n",
    "\n",
    "# 그래프 실행 및 결과 출력\n",
    "messages = graph_with_store.invoke(input={\"messages\": messages}, config=config) \n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 장기 메모리 확인\n",
    "\n",
    "user_id = \"user_123\"\n",
    "namespace = (user_id, \"conversation\")\n",
    "memories = conversation_store.search(namespace)\n",
    "\n",
    "# 검색된 메모리 출력\n",
    "for memory in memories:\n",
    "    pprint(memory.dict())\n",
    "    print(\"-\" * 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 번째 메시지 설정\n",
    "messages = [HumanMessage(content=\"와인 페어링 추천도 부탁드려요.\")]\n",
    "\n",
    "# 그래프 실행 및 결과 출력\n",
    "messages = graph_with_store.invoke(input={\"messages\": messages}, config=config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토어 검색 수행\n",
    "\n",
    "user_id = \"user_123\"\n",
    "namespace = (user_id, \"conversation\")\n",
    "memories = conversation_store.search(\n",
    "    namespace,\n",
    "    query=\"지금까지 소개한 파스타 메뉴에는 무엇이 있나요?\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "# 검색된 메모리 출력\n",
    "for memory in memories:\n",
    "    pprint(memory.dict())\n",
    "    print(\"-\" * 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 스레드 ID로 그래프 실행\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"thread_2\",\n",
    "        \"user_id\": \"user_123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 초기 메시지 설정\n",
    "messages = [HumanMessage(content=\"지금까지 소개한 파스타 메뉴에는 무엇이 있나요?\")]\n",
    "\n",
    "# 그래프 실행 및 결과 출력 \n",
    "messages = graph_with_store.invoke({\"messages\": messages}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. **Persistent Store 구현 (SQLite 기반)**\n",
    "\n",
    "- **프로덕션 환경**에서는 메모리가 아닌 영구 저장소가 필요\n",
    "- SQLite를 사용한 구현 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import uuid\n",
    "from langgraph.store.sqlite import SqliteStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 직접 연결 생성 \n",
    "conn = sqlite3.connect(\n",
    "    \"memory.db\",\n",
    "    isolation_level=None,  # autocommit 모드 설정\n",
    "    check_same_thread=False\n",
    ")\n",
    "\n",
    "# Store 생성\n",
    "store = SqliteStore(\n",
    "    conn,\n",
    "    index={\n",
    "        \"embed\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        \"fields\": [\"food_preference\", \"hobby\"],  # 임베딩할 필드 지정\n",
    "        \"dims\": 1536\n",
    "    }\n",
    ")\n",
    "\n",
    "# Setup 호출 \n",
    "store.setup()\n",
    "\n",
    "# 메모리 저장\n",
    "memories_to_store = [\n",
    "    {\n",
    "        \"food_preference\": \"매운 음식을 좋아합니다\",\n",
    "        \"hobby\": \"영화 감상\",\n",
    "        \"confidence\": 0.9\n",
    "    },\n",
    "    {\n",
    "        \"food_preference\": \"한식을 선호합니다\",\n",
    "        \"hobby\": \"등산과 캠핑\",\n",
    "        \"confidence\": 0.8\n",
    "    },\n",
    "    {\n",
    "        \"food_preference\": \"양식을 좋아합니다\",\n",
    "        \"hobby\": \"요리\",\n",
    "        \"confidence\": 0.7\n",
    "    }\n",
    "]\n",
    "\n",
    "namespace = (\"user_1\", \"preferences\")\n",
    "\n",
    "for memory in memories_to_store:\n",
    "    memory_id = str(uuid.uuid4())\n",
    "    store.put(namespace, memory_id, memory)\n",
    "    print(f\"Saved: {memory_id}\")\n",
    "\n",
    "# 벡터 검색\n",
    "print(\"\\n=== 벡터 검색 결과 ===\")\n",
    "search_results = store.search(\n",
    "    namespace,\n",
    "    query=\"캠핑에 어울리는 영화\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for item in search_results:\n",
    "    print(f\"Key: {item.key}\")\n",
    "    print(f\"Score: {item.score:.4f}\")\n",
    "    print(f\"Value: {item.value}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 개인화된 서비스 구현 예제\n",
    "\n",
    "- **두 가지 메모리 시스템**\n",
    "    - **단기 메모리 (Checkpointer)**: 현재 대화 세션의 히스토리 관리\n",
    "    - **장기 메모리 (Store)**: 사용자 프로필, 선호도, 상호작용 기록 영구 저장\n",
    "\n",
    "    ```python\n",
    "    # 네임스페이스 구조\n",
    "    (\"user_id\", \"profile\")        # 사용자 프로필 (1개)\n",
    "    (\"user_id\", \"preferences\")    # 선호도 목록 (N개)\n",
    "    (\"user_id\", \"interactions\")   # 대화 요약 (N개)\n",
    "    (\"user_id\", \"facts\")          # 중요 사실 (N개)\n",
    "    ```\n",
    "\n",
    "- **핵심 컴포넌트**\n",
    "    1. **ProfileAnalyzer**: 사용자 행동 패턴 분석 → 성격/관심사 추출\n",
    "    2. **ConversationSummarizer**: 대화 내용 → 구조화된 요약\n",
    "    3. **SqliteStore + 벡터 검색**: 시맨틱 검색으로 관련 기억 찾기\n",
    "    4. **PersonalizedAgent**: 개인화된 응답 생성\n",
    "\n",
    "- **단계별 처리**\n",
    "\n",
    "    1. **프로필 분석** \n",
    "        - 최근 10개 상호작용 분석\n",
    "        - 성격, 관심사, 대화 스타일 파악\n",
    "        - 3개 이상 대화 시 자동 업데이트\n",
    "\n",
    "    2. **컨텍스트 로드**\n",
    "        - 사용자 프로필 불러오기\n",
    "        - 관련 선호도 검색 (벡터 유사도)\n",
    "        - 최근 대화 주제 확인\n",
    "\n",
    "    3. **개인화 응답**\n",
    "        - 프로필 기반 말투 조정\n",
    "        - 선호도 반영한 추천\n",
    "        - 과거 대화 참조\n",
    "\n",
    "    4. **자동 학습**\n",
    "        - 대화 요약 → 주제/의도 추출\n",
    "        - 중요 사실 → facts 테이블\n",
    "        - 선호 표현 → preferences 테이블\n",
    "\n",
    "- **시맨틱 메모리 (사실/개념)**\n",
    "  - 사용자별 맞춤형 정보 제공: 각 사용자에 대한 프로필과 사실 정보를 체계적으로 관리하여 개인화된 응답 가능\n",
    "  - 효율적인 정보 검색: 관련 사실들을 빠르게 검색하여 사용자 질문에 대한 정확한 답변 제공\n",
    "  - 지속적인 학습: 새로운 정보를 지속적으로 학습하여 메모리를 업데이트하고 개선함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.store.sqlite import SqliteStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import sqlite3\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "# ============= Pydantic 모델 정의 =============\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"사용자 프로필 분석 결과\"\"\"\n",
    "    personality_traits: List[str] = Field(description=\"성격 특성\")\n",
    "    interests: List[str] = Field(description=\"관심사\")\n",
    "    communication_style: str = Field(description=\"선호하는 대화 스타일\")\n",
    "    key_preferences: List[str] = Field(description=\"주요 선호도 리스트\")\n",
    "    sentiment_tendency: str = Field(description=\"감정 성향: positive/neutral/negative\")\n",
    "\n",
    "class ConversationSummary(BaseModel):\n",
    "    \"\"\"대화 요약 결과\"\"\"\n",
    "    main_topic: str = Field(description=\"주요 주제\")\n",
    "    user_intent: str = Field(description=\"사용자 의도\")\n",
    "    key_points: List[str] = Field(description=\"핵심 포인트들\")\n",
    "    action_items: List[str] = Field(description=\"액션 아이템\")\n",
    "    sentiment: str = Field(description=\"대화 감정\")\n",
    "    important_facts: List[str] = Field(description=\"중요 사실\")\n",
    "\n",
    "# ============= State 정의 =============\n",
    "class GraphState(MessagesState):\n",
    "    user_context: dict     # 사용자 컨텍스트 정보\n",
    "    profile_analysis: dict  # 프로필 분석 결과\n",
    "    conversation_summary: dict  # 대화 요약 결과\n",
    "    should_update_profile: bool  # 프로필 업데이트 여부\n",
    "\n",
    "# ============= LLM 체인들 =============\n",
    "class ProfileAnalyzer:\n",
    "    \"\"\"사용자 프로필 분석 체인\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
    "        self.structured_llm = self.llm.with_structured_output(UserProfile)\n",
    "    \n",
    "    def analyze_profile(self, interactions: List[dict], current_messages: List = None, existing_profile: dict = None) -> UserProfile:\n",
    "        \"\"\"상호작용 기록과 현재 대화를 분석하여 프로필 생성\"\"\"\n",
    "        \n",
    "        # 기존 상호작용 내용 정리\n",
    "        interaction_texts = []\n",
    "        for inter in interactions[:10]:\n",
    "            if inter:\n",
    "                # 요약뿐만 아니라 다른 정보도 포함\n",
    "                text_parts = []\n",
    "                if inter.get('main_topic'):\n",
    "                    text_parts.append(f\"주제: {inter['main_topic']}\")\n",
    "                if inter.get('user_intent'):\n",
    "                    text_parts.append(f\"의도: {inter['user_intent']}\")\n",
    "                if inter.get('key_points'):\n",
    "                    text_parts.append(f\"포인트: {', '.join(inter['key_points'][:3])}\")\n",
    "                if inter.get('important_facts'):\n",
    "                    text_parts.append(f\"중요사실: {', '.join(inter['important_facts'][:2])}\")\n",
    "                \n",
    "                if text_parts:\n",
    "                    interaction_texts.append(\" | \".join(text_parts))\n",
    "        \n",
    "        interaction_text = \"\\n\".join([f\"- {text}\" for text in interaction_texts if text])\n",
    "        \n",
    "        # 현재 대화 내용 추가 \n",
    "        current_conversation = \"\"\n",
    "        if current_messages:\n",
    "            try:\n",
    "                # 리스트인지 확인\n",
    "                if not isinstance(current_messages, (list, tuple)):\n",
    "                    print(f\"경고: current_messages의 타입이 {type(current_messages)}입니다. 리스트가 예상됩니다.\")\n",
    "                    current_messages = []\n",
    "                \n",
    "                conv_parts = []\n",
    "                # 최근 메시지만 처리\n",
    "                messages_to_process = list(current_messages)[-5:] if len(current_messages) > 0 else []\n",
    "                \n",
    "                for msg in messages_to_process:\n",
    "                    if isinstance(msg, HumanMessage):\n",
    "                        conv_parts.append(f\"User: {msg.content}\")\n",
    "                    elif isinstance(msg, AIMessage):\n",
    "                        conv_parts.append(f\"Assistant: {msg.content}\")\n",
    "                    elif isinstance(msg, SystemMessage):\n",
    "                        conv_parts.append(f\"System: {msg.content}\")\n",
    "                    elif isinstance(msg, dict):\n",
    "                        conv_parts.append(f\"{msg.get('role', '알수없음')}: {msg.get('content', '')}\")\n",
    "                \n",
    "                current_conversation = \"\\n\".join(conv_parts)\n",
    "            except Exception as e:\n",
    "                print(f\"current_messages 처리 중 오류: {e}\")\n",
    "                current_conversation = \"\"\n",
    "        \n",
    "        # 디버깅 로그\n",
    "        print(f\"\\n=== 프로필 분석 디버그 ===\")\n",
    "        print(f\"이전 상호작용 수: {len(interactions)}\")\n",
    "        print(f\"상호작용 텍스트 길이: {len(interaction_text)}\")\n",
    "        print(f\"현재 대화 길이: {len(current_conversation)}\")\n",
    "        print(f\"기존 프로필 존재: {bool(existing_profile)}\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        사용자의 상호작용 기록과 현재 대화를 분석하여 상세한 프로필을 생성하세요.\n",
    "        \n",
    "        ## 중요: 대화에서 구체적인 정보를 추출하세요. 빈 리스트를 반환하지 마세요.\n",
    "        \n",
    "        ## 이전 상호작용 요약:\n",
    "        {interaction_text if interaction_text else \"아직 이전 상호작용이 없습니다\"}\n",
    "        \n",
    "        ## 현재 대화:\n",
    "        {current_conversation if current_conversation else \"현재 대화가 없습니다\"}\n",
    "\n",
    "        ## 업데이트할 기존 프로필:\n",
    "        {json.dumps(existing_profile, indent=2, ensure_ascii=False) if existing_profile else \"기존 프로필이 없습니다\"}\n",
    "\n",
    "        ## 위의 모든 정보를 바탕으로 다음을 추출하여 반환하세요:\n",
    "        1. 성격 특성 - 최소 2-3개의 특성 (예: 호기심 많은, 분석적인, 친근한, 사려깊은)\n",
    "        2. 주요 관심사 - 논의하거나 관심을 보인 구체적인 주제들\n",
    "        3. 소통 스타일 - 선호하는 의사소통 방식\n",
    "        4. 주요 선호도 - 언급된 선호사항들 (음식, 활동, 도구 등)\n",
    "        5. 전반적인 감정 성향 - 일반적인 감정 톤\n",
    "        \n",
    "        정보가 제한적이더라도 사용 가능한 데이터를 기반으로 합리적인 추론을 하세요.\n",
    "        사용자의 소통 방식을 바탕으로 항상 최소한의 특성과 관심사를 반환하세요.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 메시지 형태로 전달\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        result = self.structured_llm.invoke(messages)\n",
    "        \n",
    "        # 결과 검증 및 로그\n",
    "        print(f\"\\n=== 프로필 분석 결과 ===\")\n",
    "        print(f\"성격 특성: {result.personality_traits}\")\n",
    "        print(f\"관심사: {result.interests}\")\n",
    "        print(f\"소통 스타일: {result.communication_style}\")\n",
    "        print(\"================================\\n\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "class ConversationSummarizer:\n",
    "    \"\"\"대화 요약 체인\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
    "        self.structured_llm = self.llm.with_structured_output(ConversationSummary)\n",
    "    \n",
    "    def summarize_conversation(self, messages: List) -> ConversationSummary:\n",
    "        \"\"\"대화를 구조화된 요약으로 변환\"\"\"\n",
    "        \n",
    "        # 메시지 포맷팅 (Message 객체 처리)\n",
    "        conversation_parts = []\n",
    "        for msg in messages[-10:]:  # 최근 10개 메시지\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                conversation_parts.append(f\"User: {msg.content}\")\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                conversation_parts.append(f\"Assistant: {msg.content}\")\n",
    "            elif isinstance(msg, SystemMessage):\n",
    "                conversation_parts.append(f\"System: {msg.content}\")\n",
    "            else:\n",
    "                # 딕셔너리 형태인 경우\n",
    "                if isinstance(msg, dict):\n",
    "                    conversation_parts.append(f\"{msg.get('role', '알수없음')}: {msg.get('content', '')}\")\n",
    "        \n",
    "        conversation = \"\\n\".join(conversation_parts)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        이 대화를 분석하여 상세한 구조화된 요약을 생성하세요.\n",
    "        \n",
    "        ## 중요: 구체적인 정보를 추출하세요. 빈 필드를 남기지 마세요.\n",
    "\n",
    "        ## 대화:\n",
    "        {conversation}\n",
    "        \n",
    "        ## 다음을 추출하여 반환하세요:\n",
    "        1. 논의된 주요 주제 - 구체적으로 명시\n",
    "        2. 사용자의 주요 의도 - 달성하고자 했던 목표\n",
    "        3. 다룬 핵심 포인트들 - 3-5개의 구체적인 포인트들\n",
    "        4. 언급된 액션 아이템이나 할 일들\n",
    "        5. 대화의 전반적인 감정 분위기\n",
    "        6. 사용자에 대한 중요 사실들 - 언급된 개인 정보, 선호도, 세부사항\n",
    "        \n",
    "        각 필드에 대해 대화 내용을 바탕으로 의미있는 내용을 제공하세요.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 메시지 형태로 전달\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        result = self.structured_llm.invoke(messages)\n",
    "        \n",
    "        # 결과 로그\n",
    "        print(f\"\\n=== 대화 요약 ===\")\n",
    "        print(f\"주제: {result.main_topic}\")\n",
    "        print(f\"핵심 포인트: {len(result.key_points)}개 항목\")\n",
    "        print(f\"중요 사실: {len(result.important_facts)}개 항목\")\n",
    "        print(\"============================\\n\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ============= 노드 함수들 =============\n",
    "def check_and_save_interaction(state, config, *, store):\n",
    "    \"\"\"대화를 먼저 저장하고 프로필 업데이트 필요 여부 확인\"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    \n",
    "    # messages 타입 체크 및 변환\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not isinstance(messages, (list, tuple)):\n",
    "        print(f\"경고: messages의 타입이 {type(messages)}입니다. 리스트가 아닙니다.\")\n",
    "        return {\"should_update_profile\": False}\n",
    "    \n",
    "    if len(messages) < 2:\n",
    "        return {\"should_update_profile\": False}\n",
    "    \n",
    "    # 요약 시스템 초기화\n",
    "    summarizer = ConversationSummarizer()\n",
    "    \n",
    "    try:\n",
    "        # 대화 요약 생성\n",
    "        summary = summarizer.summarize_conversation(messages)  # 이미 검증된 messages 사용\n",
    "        summary_dict = summary.model_dump()\n",
    "        \n",
    "        # 상호작용 저장\n",
    "        interaction_id = str(uuid.uuid4())\n",
    "        store.put(\n",
    "            (\"users\", user_id, \"interactions\"),\n",
    "            interaction_id,\n",
    "            {\n",
    "                **summary_dict,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"message_count\": len(messages)  # 검증된 messages 사용\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 중요한 사실들을 별도로 저장\n",
    "        for fact in summary.important_facts:\n",
    "            if fact:\n",
    "                store.put(\n",
    "                    (\"users\", user_id, \"facts\"),\n",
    "                    str(uuid.uuid4()),\n",
    "                    {\n",
    "                        \"fact\": fact,\n",
    "                        \"source\": \"conversation\",\n",
    "                        \"conversation_id\": interaction_id,\n",
    "                        \"timestamp\": datetime.now().isoformat()\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        # 선호도 추출 및 저장\n",
    "        all_text = \"\"\n",
    "        for msg in messages:  # 검증된 messages 사용\n",
    "            if hasattr(msg, 'content'):\n",
    "                all_text += \" \" + msg.content\n",
    "            elif isinstance(msg, dict):\n",
    "                all_text += \" \" + msg.get(\"content\", \"\")\n",
    "        \n",
    "        preference_keywords = [\"prefer\", \"like\", \"love\", \"enjoy\", \"favorite\", \"좋아\", \"선호\", \"좋습니다\", \"좋네요\", \"맘에 든다\"]\n",
    "        if any(word in all_text.lower() for word in preference_keywords):\n",
    "            for point in summary.key_points:\n",
    "                if any(word in point.lower() for word in preference_keywords):\n",
    "                    store.put(\n",
    "                        (\"users\", user_id, \"preferences\"),\n",
    "                        str(uuid.uuid4()),\n",
    "                        {\n",
    "                            \"preference\": point,\n",
    "                            \"conversation_id\": interaction_id,\n",
    "                            \"timestamp\": datetime.now().isoformat()\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        # 상호작용 개수 확인\n",
    "        interactions = store.search(\n",
    "            (\"users\", user_id, \"interactions\"),\n",
    "            limit=10\n",
    "        ) or []\n",
    "        \n",
    "        # 3개 이상이거나 3의 배수일 때 프로필 업데이트\n",
    "        should_update = len(interactions) >= 3 and (len(interactions) % 3 == 0 or len(interactions) == 3)\n",
    "        \n",
    "        return {\n",
    "            \"conversation_summary\": summary_dict,\n",
    "            \"should_update_profile\": should_update\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"요약 오류: {e}\")\n",
    "        return {\"should_update_profile\": False}\n",
    "\n",
    "def update_user_profile(state, config, *, store):\n",
    "    \"\"\"조건부로 사용자 프로필 업데이트\"\"\"\n",
    "    if not state.get(\"should_update_profile\", False):\n",
    "        # 기존 프로필만 로드\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        existing_profile = store.get((\"users\", user_id), \"profile\")\n",
    "        return {\"profile_analysis\": existing_profile.value if existing_profile else {}}\n",
    "    \n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    \n",
    "    # 프로필 분석기 초기화\n",
    "    analyzer = ProfileAnalyzer()\n",
    "    \n",
    "    # 기존 프로필 조회\n",
    "    existing_profile = store.get((\"users\", user_id), \"profile\")\n",
    "    \n",
    "    # 최근 상호작용 조회 (현재 대화도 포함됨)\n",
    "    interactions = store.search(\n",
    "        (\"users\", user_id, \"interactions\"),\n",
    "        limit=10\n",
    "    ) or []\n",
    "    \n",
    "    try:\n",
    "        # 현재 메시지도 함께 전달 \n",
    "        messages = state.get(\"messages\", [])\n",
    "        \n",
    "        # messages가 올바른 타입인지 확인\n",
    "        if messages and not isinstance(messages, (list, tuple)):\n",
    "            print(f\"경고: state['messages']의 타입이 {type(messages)}입니다. 리스트로 변환합니다.\")\n",
    "            messages = []\n",
    "        \n",
    "        profile_analysis = analyzer.analyze_profile(\n",
    "            [inter.value for inter in interactions if inter and inter.value],\n",
    "            current_messages=messages,\n",
    "            existing_profile=existing_profile.value if existing_profile else {}\n",
    "        )\n",
    "        \n",
    "        # 프로필 저장/업데이트\n",
    "        store.put(\n",
    "            (\"users\", user_id),\n",
    "            \"profile\",\n",
    "            {\n",
    "                **profile_analysis.model_dump(),\n",
    "                \"last_updated\": datetime.now().isoformat(),\n",
    "                \"update_count\": (existing_profile.value.get(\"update_count\", 0) + 1) if existing_profile else 1\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 사용자 {user_id}의 프로필이 성공적으로 업데이트되었습니다.\")\n",
    "        return {\"profile_analysis\": profile_analysis.model_dump()}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 프로필 분석 오류: {e}\")\n",
    "        return {\"profile_analysis\": existing_profile.value if existing_profile else {}}\n",
    "\n",
    "def load_user_context(state, config, *, store):\n",
    "    \"\"\"사용자 컨텍스트 로드\"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    \n",
    "    # 프로필 조회 (이미 업데이트된 상태)\n",
    "    profile = state.get(\"profile_analysis\") or {}\n",
    "    if not profile:\n",
    "        stored_profile = store.get((\"users\", user_id), \"profile\")\n",
    "        profile = stored_profile.value if stored_profile else {}\n",
    "    \n",
    "    # 최근 선호도 조회\n",
    "    preferences = store.search(\n",
    "        (\"users\", user_id, \"preferences\"),\n",
    "        limit=3\n",
    "    ) or []\n",
    "    \n",
    "    # 최근 상호작용 조회\n",
    "    query = \"\"\n",
    "    if state.get(\"messages\"):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if isinstance(last_message, (HumanMessage, AIMessage, SystemMessage)):\n",
    "            query = last_message.content\n",
    "        elif isinstance(last_message, dict):\n",
    "            query = last_message.get(\"content\", \"\")\n",
    "    \n",
    "    recent_interactions = store.search(\n",
    "        (\"users\", user_id, \"interactions\"),\n",
    "        query=query if query else None,\n",
    "        limit=3\n",
    "    ) or []\n",
    "    \n",
    "    context = {\n",
    "        \"user_context\": {\n",
    "            \"profile\": profile,\n",
    "            \"preferences\": [p.value for p in preferences if p and p.value],\n",
    "            \"recent_interactions\": [i.value for i in recent_interactions if i and i.value]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 디버깅 정보\n",
    "    print(f\"\\n=== 로드된 컨텍스트 ===\")\n",
    "    print(f\"프로필 로드됨: {bool(profile)}\")\n",
    "    print(f\"선호도 개수: {len(context['user_context']['preferences'])}\")\n",
    "    print(f\"최근 상호작용: {len(context['user_context']['recent_interactions'])}\")\n",
    "    print(\"======================\\n\")\n",
    "    \n",
    "    return context\n",
    "\n",
    "def personalized_agent(state, config, *, store):\n",
    "    \"\"\"개인화된 응답 생성\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)\n",
    "    \n",
    "    # 컨텍스트 활용\n",
    "    context = state.get(\"user_context\", {})\n",
    "    profile = context.get(\"profile\", {}) or state.get(\"profile_analysis\", {})\n",
    "    \n",
    "    # 개인화된 시스템 프롬프트 구성\n",
    "    system_parts = [\"당신은 친절한 AI 어시스턴트입니다.\"]\n",
    "    \n",
    "    if profile:\n",
    "        personality = profile.get('personality_traits', [])\n",
    "        interests = profile.get('interests', [])\n",
    "        comm_style = profile.get('communication_style', '친근한')\n",
    "        sentiment = profile.get('sentiment_tendency', '중립적')\n",
    "        \n",
    "        if personality or interests:\n",
    "            system_parts.append(f\"\"\"\n",
    "사용자 프로필:\n",
    "- 성격: {', '.join(personality) if personality else '아직 파악되지 않음'}\n",
    "- 관심사: {', '.join(interests) if interests else '아직 파악되지 않음'}\n",
    "- 소통 스타일: {comm_style}\n",
    "- 감정 성향: {sentiment}\n",
    "\"\"\")\n",
    "    \n",
    "    if context.get('preferences'):\n",
    "        pref_text = \"\\n\".join([f\"- {p['preference']}\" if isinstance(p, dict) else f\"- {p}\" for p in context['preferences'][:3]])\n",
    "        system_parts.append(f\"사용자 선호도:\\n{pref_text}\")\n",
    "    \n",
    "    if context.get('recent_interactions'):\n",
    "        recent_text = \"\\n\".join([\n",
    "            f\"- {inter.get('main_topic', '정보 없음')}: {inter.get('user_intent', '정보 없음')}\"\n",
    "            for inter in context['recent_interactions'][:3]\n",
    "        ])\n",
    "        system_parts.append(f\"최근 대화 내용:\\n{recent_text}\")\n",
    "    \n",
    "    system_parts.append(\"알려진 사용자의 성격과 선호도에 맞는 응답을 제공하세요.\")\n",
    "    \n",
    "    system_prompt = \"\\n\\n\".join(system_parts)\n",
    "    \n",
    "    # 메시지 리스트 구성\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    if state.get(\"messages\"):\n",
    "        messages.extend(state[\"messages\"])\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ============= 그래프 구성 =============\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# 노드 추가 \n",
    "builder.add_node(\"check_and_save\", check_and_save_interaction)  # 먼저 저장\n",
    "builder.add_node(\"update_profile\", update_user_profile)  # 조건부 프로필 업데이트\n",
    "builder.add_node(\"load_context\", load_user_context)\n",
    "builder.add_node(\"agent\", personalized_agent)\n",
    "\n",
    "# 플로우 정의 \n",
    "builder.add_edge(START, \"check_and_save\")  # 먼저 현재 대화 저장\n",
    "builder.add_edge(\"check_and_save\", \"update_profile\")  # 필요시 프로필 업데이트\n",
    "builder.add_edge(\"update_profile\", \"load_context\")\n",
    "builder.add_edge(\"load_context\", \"agent\")\n",
    "builder.add_edge(\"agent\", END)\n",
    "\n",
    "# Store 연결\n",
    "store_conn = sqlite3.connect(\n",
    "    \"profile_memory.db\",\n",
    "    isolation_level=None,\n",
    "    check_same_thread=False\n",
    ")\n",
    "\n",
    "store = SqliteStore(\n",
    "    store_conn,\n",
    "    index={\n",
    "        \"embed\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        \"fields\": [\"content\", \"summary\", \"fact\", \"preference\", \"main_topic\", \"key_points\"],\n",
    "        \"dims\": 1536\n",
    "    }\n",
    ")\n",
    "store.setup()\n",
    "\n",
    "# Checkpointer 연결\n",
    "checkpoint_conn = sqlite3.connect(\n",
    "    \"profile_checkpoints.db\",\n",
    "    check_same_thread=False\n",
    ")\n",
    "\n",
    "checkpointer = SqliteSaver(checkpoint_conn)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=store\n",
    ")\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 사용자 설정\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\", \"user_id\": \"user123\"}}\n",
    "\n",
    "# 첫 번째 대화\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"안녕하세요! 저는 이탈리안 음식을 좋아하고 주말에는 등산을 즐깁니다.\")]},\n",
    "    config\n",
    ")\n",
    "print(\"Bot:\", result[\"messages\"][-1].content)\n",
    "print(\"Summary:\", result.get(\"conversation_summary\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 대화\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"제 이름은 스티브라고 합니다. 소프트웨어 개발자로 일하고 있어요.\")]},\n",
    "    config\n",
    ")\n",
    "print(\"Bot:\", result[\"messages\"][-1].content)\n",
    "print(\"Summary:\", result.get(\"conversation_summary\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 선호도\n",
    "store.search((\"users\", \"user123\", \"preferences\"), limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 사실\n",
    "store.search((\"users\", \"user123\", \"facts\"), limit=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 번째 대화\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"내년에는 새로운 프로그래밍 언어를 배우고 싶고, 이탈리아 여행도 가고 싶어요.\")]},\n",
    "    config\n",
    ")\n",
    "print(\"Bot:\", result[\"messages\"][-1].content)\n",
    "print(\"Summary:\", result.get(\"conversation_summary\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네 번째 대화 \n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"운동은 주로 테니스를 치고, 여가시간에는 독서를 즐겨해요. 성격은 꼼꼼하고 계획적인 편이에요.\")]},\n",
    "    config\n",
    ")\n",
    "print(\"Bot:\", result[\"messages\"][-1].content)\n",
    "print(\"Summary:\", result.get(\"conversation_summary\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 상호 작용 확인\n",
    "store.search((\"users\", \"user123\", \"interactions\"), limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 선호도\n",
    "store.search((\"users\", \"user123\", \"preferences\"), limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 사실\n",
    "store.search((\"users\", \"user123\", \"facts\"), limit=5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 사용자 프로필 조회\n",
    "profile = store.get((\"users\", \"user123\"), \"profile\")\n",
    "if profile:\n",
    "    print(\"=== User Profile ===\")\n",
    "    print(f\"Created: {profile.created_at}\")\n",
    "    print(f\"Updated: {profile.updated_at}\")\n",
    "    print(f\"Data: {profile.value}\")\n",
    "else:\n",
    "    print(\"프로필이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다섯 번째 대화 \n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"오늘 저녁에 가족모임에서 먹을 요리를 추천해주세요.\")]},\n",
    "    config\n",
    ")\n",
    "print(\"Bot:\", result[\"messages\"][-1].content)\n",
    "print(\"Summary:\", result.get(\"conversation_summary\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skt-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
