{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   LangGraph 활용 - 메시지 그래프 + 리듀서 구현 + 병렬 실행\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 \n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Reducer (리듀서)**\n",
    "\n",
    "- **State Reducer**는 LangGraph의 **상태 관리 핵심 메커니즘**\n",
    "\n",
    "- 각 노드의 출력을 **전체 그래프 상태에 통합**하는 방식을 정의\n",
    "\n",
    "- **Reducer의 필요성**:\n",
    "\n",
    "    - **상태 덮어쓰기 문제**: 기본적으로 각 노드의 반환값은 해당 상태 키의 이전 값을 덮어쓰는 방식으로 동작 (override)\n",
    "    \n",
    "    - **누적 업데이트 필요**: 특히 메시지 리스트와 같은 경우, 이전 상태에 새로운 값을 추가하고 싶을 때가 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Reducer를 별도로 지정하지 않은 경우 `\n",
    "\n",
    "- **기본 Reducer**는 이전 값을 **자동으로 덮어쓰는** 방식으로 작동\n",
    "- Reducer 설정이 없는 경우 **자동으로 기본값**이 적용\n",
    "- 이는 단순한 상태 업데이트에는 적합하나 **데이터 누적이 필요한 경우 부적절**\n",
    "- 기본 Reducer는 **간단한 상태 관리**에 적합하지만 복잡한 데이터 처리에는 한계가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 상태 정의 \n",
    "class DocumentState(TypedDict):\n",
    "    query: str\n",
    "    documents: List[str]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(DocumentState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"문서를 검색해주세요.\"}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"-\"*100)\n",
    "print(\"최종 상태:\")\n",
    "print(\"쿼리:\", final_state['query'])\n",
    "print(\"검색된 문서:\", final_state['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) Reducer를 별도로 지정하는 경우 `\n",
    "\n",
    "- **Annotated**를 통해 **사용자 정의 Reducer**를 지정할 수 있음 \n",
    "- **operator.add**를 사용하면 리스트 형태의 데이터를 **누적 관리**할 수 있음 \n",
    "- 여기서는 기존 리스트에 새로운 메시지를 추가하는 방식으로 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "class ReducerState(TypedDict):\n",
    "    query: str\n",
    "    documents: Annotated[List[str], add]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(ReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"문서를 누적해서 검색해주세요.\"}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"-\"*100)\n",
    "print(\"최종 상태:\")\n",
    "print(\"쿼리:\", final_state['query'])\n",
    "print(\"검색된 문서:\", final_state['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Custom Reducer 사용 `\n",
    "\n",
    "- **Custom Reducer**는 **복잡한 상태 관리**가 필요할 때 사용됨 \n",
    "- **중복 제거**나 **최대/최소값 유지**와 같은 특수한 로직을 구현할 수 있음 \n",
    "- 비즈니스 요구사항에 맞는 **맞춤형 상태 관리**가 가능\n",
    "- 상황에 따라 **조건부 병합**과 같은 고급 기능을 구현할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "\n",
    "# Custom reducer: 중복된 문서를 제거하며 리스트 병합\n",
    "def reduce_unique_documents(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Combine two lists of documents, removing duplicates.\"\"\"\n",
    "    if not left:\n",
    "        left = []\n",
    "    if not right:\n",
    "        right = []\n",
    "    # 중복 제거: set을 사용하여 중복된 문서를 제거하고 다시 list로 변환\n",
    "    return list(set(left + right))\n",
    "\n",
    "# 상태 정의 (documents 필드 포함)\n",
    "class CustomReducerState(TypedDict):\n",
    "    query: str\n",
    "    documents: Annotated[List[str], reduce_unique_documents]  # Custom Reducer 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: query 업데이트\n",
    "def node_1(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(CustomReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"문서를 누적해서 검색해주세요.\"}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"-\"*100)\n",
    "print(\"최종 상태:\")\n",
    "print(\"쿼리:\", final_state['query'])\n",
    "print(\"검색된 문서:\", final_state['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Message 사용**\n",
    "\n",
    "- **LangGraph**는 **메시지 목록** 기반의 채팅 모델 인터페이스를 활용\n",
    "\n",
    "- `HumanMessage`와 `AIMessage` 등 다양한 메시지 타입을 지원\n",
    "\n",
    "- 그래프 상태에서 대화 기록은 **메시지 객체 리스트**로 저장되며, 이를 통해 효율적인 대화 관리를 가능\n",
    "\n",
    "- **reducer 함수**를 통해 상태 업데이트 시 메시지 목록이 어떻게 갱신될지 정의할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) add_messages`\n",
    "\n",
    "- 메시지 ID를 기반으로 기존 메시지를 업데이트하거나 새 메시지를 추가하는 고급 관리 기능을 제공\n",
    "    - 새 메시지는 기존 목록에 추가\n",
    "    - 기존 메시지 업데이트도 올바르게 처리 (메시지 ID를 추적)\n",
    "\n",
    "- 기존 메시지의 중복 추가를 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# add_messages 사용 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# chatbot 노드 함수 정의\n",
    "def chatbot(state: GraphState) -> GraphState:\n",
    "    # LLM을 사용하여 챗봇 메시지 생성\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Workflow Graph\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 초기 상태\n",
    "initial_state = {\"messages\": [(\"user\", \"안녕하세요!\")]}\n",
    "\n",
    "# 그래프 실행\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    pprint(event['messages'])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) MessagesState`\n",
    "\n",
    "- **`MessagesState`** 는 메시지 관리를 위해 미리 정의된 상태 타입\n",
    "\n",
    "- 이 상태는 **`add_messages` reducer**를 기본으로 사용하여 메시지 업데이트를 자동으로 처리\n",
    "\n",
    "- `AnyMessage` 객체 리스트를 포함하는 **단일 `messages` 키**로 구성되어 있어 구조가 단순함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# messages 키를 가진 상태 생성 (messages 키는 기본 제공)\n",
    "class GraphState(MessagesState):  # MessagesState 상속\n",
    "    ... \n",
    "    # 추가적인 필드 정의 가능\n",
    "    # custom_field: str\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# chatbot 노드 함수 정의\n",
    "def chatbot(state: GraphState) -> GraphState:\n",
    "    # LLM을 사용하여 챗봇 메시지 생성\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Workflow Graph\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 초기 상태\n",
    "initial_state = {\"messages\": [(\"user\", \"안녕하세요!\")]}\n",
    "\n",
    "# 그래프 실행\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    pprint(event['messages'])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) MessagesState 커스텀 필드 추가`\n",
    "\n",
    "- **MessagesState**를 상속받아 추가 필드를 포함하는 새로운 상태 타입을 정의할 수 있음 \n",
    "\n",
    "- 기존 `messages` 키의 **`add_messages` reducer** 기능을 그대로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# MessagesState를 상속하여 커스텀 필드 추가\n",
    "class GraphState(MessagesState):\n",
    "    # 사용자의 감정 상태를 추적하는 필드 추가\n",
    "    emotion: Optional[str] \n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# 감정 분석을 위한 프롬프트 템플릿\n",
    "EMOTION_PROMPT = \"\"\"\n",
    "사용자의 메시지를 분석하여 감정 상태를 파악해주세요.\n",
    "가능한 감정 상태: 행복, 슬픔, 화남, 중립\n",
    "\n",
    "사용자 메시지: {message}\n",
    "\n",
    "감정 상태만 한 단어로 답변해주세요.\n",
    "\"\"\"\n",
    "\n",
    "# 감정 분석 노드\n",
    "def analyze_emotion(state: GraphState) -> GraphState:\n",
    "    # 가장 최근 사용자 메시지 가져오기\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 감정 분석 실행\n",
    "    emotion_analysis = llm.invoke(EMOTION_PROMPT.format(message=last_message))\n",
    "    \n",
    "    # 상태 업데이트\n",
    "    return {\n",
    "        \"emotion\": emotion_analysis.content.strip()\n",
    "    }\n",
    "\n",
    "# 챗봇 응답 노드\n",
    "def chatbot(state: GraphState) -> GraphState:\n",
    "    # 현재 감정 상태를 고려한 시스템 메시지 생성\n",
    "    system_message = f\"\"\"\n",
    "    사용자의 현재 감정 상태는 {state['emotion']}입니다.\n",
    "    이를 고려하여 공감적이고 적절한 응답을 해주세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 기존 메시지에 시스템 메시지 추가\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + state[\"messages\"]\n",
    "    \n",
    "    # LLM 응답 생성\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Workflow Graph 구성\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"analyze_emotion\", analyze_emotion)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 엣지 추가\n",
    "builder.add_edge(START, \"analyze_emotion\")\n",
    "builder.add_edge(\"analyze_emotion\", \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"오늘 정말 힘든 하루였어요...\"}]\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    if \"emotion\" in event:\n",
    "        print(f\"감정 상태: {event['emotion']}\")\n",
    "    if \"messages\" in event:\n",
    "        print(\"메시지:\")\n",
    "        for msg in event[\"messages\"]:\n",
    "            print(f\"{msg.type}: {msg.content}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **병렬 처리**\n",
    "\n",
    "- **분기(branching)** 기능을 통해 LangGraph에서 노드의 병렬 실행이 가능\n",
    "\n",
    "- 병렬 처리는 **독립적인 작업**들을 동시에 실행함으로써 전체 처리 시간을 단축\n",
    "\n",
    "- 다양한 데이터 소스에서 **정보 수집 및 처리**가 필요한 경우 병렬 실행이 특히 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 표준 엣지를 사용한 분기 (Fan-out/Fan-in)`\n",
    "\n",
    "- **Fan-out** 구조는 하나의 노드에서 여러 병렬 노드로 데이터를 분산시키는 방식을 구현\n",
    "\n",
    "- **Fan-in** 구조는 병렬로 처리된 여러 노드의 결과를 단일 노드에서 취합하는 역할\n",
    "\n",
    "- 가장 기본적이고 직관적인 병렬 처리 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 검색 엔진에서 정보 가져오기\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Any, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 상태 정의: 검색 결과를 누적할 리스트를 포함\n",
    "class SearchState(TypedDict):\n",
    "    search_results: Annotated[list, operator.add]\n",
    "\n",
    "# 각 검색 엔진에 대한 노드 정의\n",
    "def search_engine_a(state: SearchState):\n",
    "    print(\"Searching with Engine A...\")\n",
    "    return {\"search_results\": [\"Result A1\", \"Result A2\"]}\n",
    "\n",
    "def search_engine_b(state: SearchState):\n",
    "    print(\"Searching with Engine B...\")\n",
    "    return {\"search_results\": [\"Result B1\"]}\n",
    "\n",
    "def combine_results(state: SearchState):\n",
    "    print(\"Combining search results...\")\n",
    "    return {\"search_results\": [\"Combined Result\"]}\n",
    "\n",
    "# 그래프 구성\n",
    "search_builder = StateGraph(SearchState)\n",
    "search_builder.add_node(\"engine_a\", search_engine_a)\n",
    "search_builder.add_node(\"engine_b\", search_engine_b)\n",
    "search_builder.add_node(\"combine\", combine_results)\n",
    "\n",
    "# 엣지 연결: START -> engine_a, engine_b (병렬 실행) -> combine -> END\n",
    "search_builder.add_edge(START, \"engine_a\")\n",
    "search_builder.add_edge(START, \"engine_b\")\n",
    "search_builder.add_edge(\"engine_a\", \"combine\")\n",
    "search_builder.add_edge(\"engine_b\", \"combine\")\n",
    "# search_builder.add_edge([\"engine_a\", \"engine_b\"], \"combine\") # 병렬 실행 후 결과 결합\n",
    "search_builder.add_edge(\"combine\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "search_graph = search_builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(search_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "search_graph.invoke({\"search_results\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 조건부 엣지를 사용한 분기 (Conditional Branching)`\n",
    "\n",
    "- **Fan-out** 구조는 하나의 노드에서 여러 병렬 노드로 데이터를 분산시키는 방식을 구현\n",
    "\n",
    "- **Fan-in** 구조는 병렬로 처리된 여러 노드의 결과를 단일 노드에서 취합하는 역할\n",
    "\n",
    "- 가장 기본적이고 직관적인 병렬 처리 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**구현 예시**\n",
    "\n",
    "- 초기 그리팅 후 조건부로 서비스를 실행\n",
    "- 선택된 서비스들을 병렬로 실행\n",
    "- 모든 서비스 실행 후 최종 처리를 수행\n",
    "- 전체 과정의 상태를 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 상태 정의: aggregate 리스트와 라우팅을 위한 user_intent 필드 포함\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list, operator.add]  # aggregate 대신 messages 사용\n",
    "    user_intent: str  # 라우팅 조건\n",
    "\n",
    "# 서비스 노드 정의\n",
    "def greet_service(state: ChatState):\n",
    "    print(f'Adding \"greet\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"Hello!\"]} \n",
    "\n",
    "def weather_service(state: ChatState):\n",
    "    print(f'Adding \"weather\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"The weather is sunny.\"]}\n",
    "\n",
    "def news_service(state: ChatState):\n",
    "    print(f'Adding \"news\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"Here's the latest news.\"]}\n",
    "\n",
    "def help_service(state: ChatState):\n",
    "    print(f'Adding \"help\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"How can I help you?\"]}\n",
    "\n",
    "def process_response(state: ChatState):\n",
    "    print(f'Adding \"process\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"Processing complete.\"]}\n",
    "\n",
    "# 라우팅 함수: user_intent 값에 따라 서비스 노드 결정\n",
    "def route_services(state: ChatState) -> Sequence[str]:\n",
    "    if state[\"user_intent\"] == \"weather_news\":\n",
    "        # 날씨와 뉴스 서비스를 병렬 실행\n",
    "        return [\"weather_service\", \"news_service\"]\n",
    "    \n",
    "    # 기본적으로 인사와 뉴스 서비스를 병렬 실행\n",
    "    return [\"help_service\", \"news_service\"]\n",
    "\n",
    "# 그래프 구성\n",
    "chat_builder = StateGraph(ChatState)\n",
    "\n",
    "# 노드 추가\n",
    "chat_builder.add_node(\"greet\", greet_service)\n",
    "chat_builder.add_node(\"weather_service\", weather_service)\n",
    "chat_builder.add_node(\"news_service\", news_service)\n",
    "chat_builder.add_node(\"help_service\", help_service)\n",
    "chat_builder.add_node(\"process\", process_response)\n",
    "\n",
    "# 엣지 추가\n",
    "chat_builder.add_edge(START, \"greet\")\n",
    "\n",
    "# 중간 노드 정의\n",
    "intermediates = [\"weather_service\", \"news_service\", \"help_service\"]\n",
    "\n",
    "# greet 노드에서 조건부 엣지 추가\n",
    "chat_builder.add_conditional_edges(\n",
    "    \"greet\",\n",
    "    route_services,\n",
    "    intermediates,\n",
    ")\n",
    "\n",
    "# 중간 노드들을 process 노드에 연결\n",
    "for node in intermediates:\n",
    "    chat_builder.add_edge(node, \"process\")\n",
    "\n",
    "chat_builder.add_edge(\"process\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "chat_graph = chat_builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(chat_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"weather_news\" 의도를 가지고 실행\n",
    "chat_graph.invoke({\"messages\": [], \"user_intent\": \"weather_news\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 의도를 가지고 실행\n",
    "chat_graph.invoke({\"messages\": [], \"user_intent\": \"news\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 다단계 분기 (Multi-step Parallel Paths)`\n",
    "\n",
    "- **다단계 분기**는 각각의 병렬 경로에서 여러 단계의 독립적인 처리를 지원 \n",
    "\n",
    "- 각 분기는 **서로 다른 데이터 처리 파이프라인**을 포함할 수 있어, 복잡한 워크플로우 구현이 가능\n",
    "\n",
    "- 최종적으로 각 분기의 결과는 하나의 노드에서 **통합되어 처리**될 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리와 모델 예측을 병렬로 수행하기\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class ModelState(TypedDict):\n",
    "    data: Annotated[list, operator.add]\n",
    "\n",
    "def fetch_data_a(state: ModelState):\n",
    "    return {\"data\": [\"Data A1\"]}\n",
    "\n",
    "def preprocess_data_a(state: ModelState):\n",
    "    return {\"data\": [\"Preprocessed A1\"]}\n",
    "\n",
    "def fetch_data_b(state: ModelState):\n",
    "    return {\"data\": [\"Data B1\"]}\n",
    "\n",
    "def make_prediction(state: ModelState):\n",
    "    return {\"data\": [\"Prediction from A and B\"]}\n",
    "\n",
    "model_builder = StateGraph(ModelState)\n",
    "model_builder.add_node(\"fetch_a\", fetch_data_a)\n",
    "model_builder.add_node(\"preprocess_a\", preprocess_data_a)\n",
    "model_builder.add_node(\"fetch_b\", fetch_data_b)\n",
    "model_builder.add_node(\"predict\", make_prediction)\n",
    "\n",
    "model_builder.add_edge(START, \"fetch_a\")\n",
    "model_builder.add_edge(START, \"fetch_b\")\n",
    "model_builder.add_edge(\"fetch_a\", \"preprocess_a\")\n",
    "model_builder.add_edge([\"preprocess_a\", \"fetch_b\"], \"predict\")\n",
    "model_builder.add_edge(\"predict\", END)\n",
    "\n",
    "model_graph = model_builder.compile()\n",
    "\n",
    "display(Image(model_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "model_graph.invoke({\"data\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 동적 엣지 생성 및 개별 상태 전달하기 (Map-Reduce 패턴)`\n",
    "\n",
    "- **기본 동작의 한계**\n",
    "\n",
    "    - 기본적으로 LangGraph의 노드와 엣지는 미리 정의되며, 모든 노드는 동일한 공유 상태(shared state)를 사용함. 하지만 다음과 같은 경우에는 문제가 발생할 수 있음. \n",
    "\n",
    "    -  **동적 엣지:** 실행 시점에 따라 연결해야 할 노드의 수가 달라지는 경우 (예: 입력 데이터에 따라 다른 개수의 하위 작업을 생성해야 하는 경우)\n",
    "    -  **개별 상태:** 각 노드가 독립적인 상태를 가지고 작업해야 하는 경우 (예: 각 하위 작업이 서로 다른 데이터를 처리해야 하는 경우)\n",
    "\n",
    "- **Map-Reduce 패턴**\n",
    "\n",
    "    1.  **Map:**  하나의 노드(mapper)가 여러 개의 객체(또는 작업)를 생성\n",
    "    2.  **Reduce:** 다른 노드(reducer)가 mapper가 생성한 객체들을 처리하고 결과를 결합\n",
    "\n",
    "-  **`Send` 객체**\n",
    "\n",
    "    - LangGraph에서는 `Send` 객체를 사용하여 map 단계를 구현할 수 있음 \n",
    "    - `Send` 객체는 조건부 엣지(`add_conditional_edges`)의 `condition_function`에서 반환될 수 있으며, 다음과 같은 두 가지 인수를 받아서 구현\n",
    "\n",
    "        1.  **`node_name` (str):**  실행할 노드의 이름\n",
    "        2.  **`state` (dict):** 해당 노드에 전달할 개별 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 글로벌 상태 정의\n",
    "class WebScrapingState(TypedDict):\n",
    "    urls: List[str]  # 스크래핑할 URL 목록 (글로벌)\n",
    "    scraped_data: Annotated[List[dict], operator.add]  # 스크래핑된 데이터 (글로벌, 누적)\n",
    "\n",
    "# 로컬 상태 정의\n",
    "class PrivateSate(TypedDict):\n",
    "    url: str  # 스크래핑할 URL (로컬 상태)\n",
    "\n",
    "# 노드 정의\n",
    "def define_urls(state: WebScrapingState):\n",
    "    \"\"\"URL 목록을 정의합니다. (글로벌 상태 사용)\"\"\"\n",
    "    print(\"Using provided URLs...\")\n",
    "    return {\"urls\": state[\"urls\"]}  # 글로벌 상태(urls) 사용\n",
    "\n",
    "def scrape_website(state: PrivateSate):  # 로컬 상태를 받음\n",
    "    \"\"\"각 웹사이트를 스크래핑합니다. (로컬 상태 사용)\"\"\"\n",
    "    print(f\"Scraping {state['url']}...\")  # 로컬 상태(url) 사용\n",
    "    # 실제 스크래핑 로직 (여기서는 시뮬레이션)\n",
    "    return {\"scraped_data\": [f\"Data from {state['url']}\"]} # 글로벌 상태(scraped_data) 사용\n",
    "\n",
    "def route_to_scraping(state: WebScrapingState):\n",
    "    \"\"\"스크래핑 노드로 라우팅합니다. (글로벌 상태 사용, 로컬 상태 생성)\"\"\"\n",
    "    # 글로벌 상태(urls)를 사용하여 로컬 상태({\"url\": url})를 생성하고 Send로 전달\n",
    "    return [Send(\"scrape_website\", {\"url\": url}) for url in state[\"urls\"]]\n",
    "\n",
    "\n",
    "# 그래프 구성\n",
    "graph = StateGraph(WebScrapingState)  \n",
    "graph.add_node(\"define_urls\", define_urls)\n",
    "graph.add_node(\"scrape_website\", scrape_website)\n",
    "\n",
    "graph.set_entry_point(\"define_urls\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"define_urls\",\n",
    "    route_to_scraping,\n",
    "    [\"scrape_website\"],  # 스크래핑 노드로 라우팅\n",
    ")\n",
    "\n",
    "graph.add_edge(\"scrape_website\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "compiled_graph = graph.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(compiled_graph.get_graph().draw_mermaid_png()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행 (외부에서 URL 목록 입력)\n",
    "initial_state = {\"urls\": [\"https://example.com\", \"https://example.net\", \"https://example.org\"]}\n",
    "result = compiled_graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    define_urls[define_urls]\n",
    "    scrape_website[scrape_website]\n",
    "    _start((START)) --> define_urls\n",
    "    define_urls --\"Send(scrape_website)\"--> scrape_website\n",
    "    scrape_website --> _end((END))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`Send` 객체의 사용 예시**\n",
    "\n",
    "- 문서 요약 시스템 (대용량 텍스트 처리)\n",
    "- 긴 문서를 여러 부분으로 나누어 병렬로 요약한 후 통합하는 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Dict, Tuple, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langchain_openai import ChatOpenAI  \n",
    "from IPython.display import Image, display\n",
    "\n",
    "# LLM 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "class SummarizationState(TypedDict):\n",
    "    contents: List[Document]  # 초기 Document 객체 리스트\n",
    "    chunks: List[Dict[str, Any]]  # 청크 리스트 (인덱스, 내용, 메타데이터 포함)\n",
    "    summaries: Annotated[List[Tuple[int, str]], operator.add]  # (인덱스, 요약) 튜플 리스트\n",
    "    final_summary: str\n",
    "\n",
    "class DocumentState(TypedDict):\n",
    "    content: str\n",
    "    index: int  # 청크의 순서를 나타내는 인덱스\n",
    "\n",
    "def split_documents(state: SummarizationState):\n",
    "    \"\"\"각 Document를 순서를 유지하며 청크로 분할\"\"\"\n",
    "    chunks = []\n",
    "    chunk_size = 1000\n",
    "    global_chunk_index = 0\n",
    "    \n",
    "    # 각 Document를 순차적으로 처리\n",
    "    for doc_index, document in enumerate(state[\"contents\"]):\n",
    "        content = document.page_content\n",
    "        \n",
    "        # 해당 문서를 청크로 분할\n",
    "        for i in range(0, len(content), chunk_size):\n",
    "            chunk_content = content[i:i + chunk_size]\n",
    "            \n",
    "            # 빈 청크는 스킵\n",
    "            if chunk_content.strip():\n",
    "                chunks.append({\n",
    "                    \"index\": global_chunk_index,\n",
    "                    \"content\": chunk_content,\n",
    "                    \"source_document\": doc_index,\n",
    "                    \"source_metadata\": document.metadata\n",
    "                })\n",
    "                global_chunk_index += 1\n",
    "    \n",
    "    return {\"chunks\": chunks}\n",
    "\n",
    "def summarize_document(state: DocumentState):\n",
    "    \"\"\"개별 문서 청크를 요약\"\"\"\n",
    "    prompt = f\"\"\"다음 텍스트를 2-3문장으로 간결하게 요약해주세요:\n",
    "    \n",
    "    {state['content']}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.invoke(prompt)\n",
    "        summary = response.content\n",
    "    except Exception as e:\n",
    "        summary = f\"요약 생성 중 오류 발생: {str(e)}\"\n",
    "    \n",
    "    # 순서 정보와 함께 요약 반환\n",
    "    return {\"summaries\": [(state[\"index\"], summary)]}\n",
    "\n",
    "def continue_to_summarization(state: SummarizationState):\n",
    "    \"\"\"각 청크를 병렬로 요약하도록 Send 작업 생성\"\"\"\n",
    "    return [\n",
    "        Send(\"summarize_document\", {\n",
    "            \"content\": chunk[\"content\"],\n",
    "            \"index\": chunk[\"index\"]\n",
    "        }) \n",
    "        for chunk in state[\"chunks\"]\n",
    "    ]\n",
    "\n",
    "def create_final_summary(state: SummarizationState):\n",
    "    \"\"\"순서를 유지하며 최종 요약 생성\"\"\"\n",
    "    # 인덱스별로 요약을 정렬\n",
    "    sorted_summaries = sorted(state[\"summaries\"], key=lambda x: x[0])\n",
    "    \n",
    "    # 순서대로 요약들을 결합\n",
    "    ordered_summaries = [summary for _, summary in sorted_summaries]\n",
    "    combined_summaries = \"\\n\\n\".join(ordered_summaries)\n",
    "    \n",
    "    prompt = f\"\"\"다음은 문서를 청크별로 요약한 내용들입니다. \n",
    "    이들을 종합하여 하나의 포괄적이고 일관성 있는 최종 요약을 작성해주세요.\n",
    "    원본 문서의 순서와 흐름을 유지하면서 핵심 내용을 간결하게 정리해주세요:\n",
    "    \n",
    "    {combined_summaries}\n",
    "    \n",
    "    최종 요약:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.invoke(prompt)\n",
    "        final_summary = response.content\n",
    "    except Exception as e:\n",
    "        final_summary = f\"최종 요약 생성 중 오류 발생: {str(e)}\"\n",
    "    \n",
    "    return {\"final_summary\": final_summary}\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(SummarizationState)\n",
    "builder.add_node(\"split_documents\", split_documents)\n",
    "builder.add_node(\"summarize_document\", summarize_document)\n",
    "builder.add_node(\"create_final_summary\", create_final_summary)\n",
    "\n",
    "# 엣지 연결\n",
    "builder.add_edge(START, \"split_documents\")\n",
    "builder.add_conditional_edges(\"split_documents\", continue_to_summarization, [\"summarize_document\"])\n",
    "builder.add_edge(\"summarize_document\", \"create_final_summary\")\n",
    "builder.add_edge(\"create_final_summary\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/labor_law.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"로드된 페이지 수: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 문서 요약 실행\n",
    "initial_state = {\n",
    "    \"contents\": documents,\n",
    "}\n",
    "    \n",
    "for step in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    if \"chunks\" in step:\n",
    "        print(f\"처리 중인 청크 수: {len(step['chunks'])}\")\n",
    "    if \"summaries\" in step:\n",
    "        print(f\"현재까지 생성된 요약 수: {len(step['summaries'])}\")\n",
    "    if \"final_summary\" in step:\n",
    "        print(\"최종 요약 생성 중...\")\n",
    "        print(step[\"final_summary\"])  # 최종 요약 출력\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 상태 출려\n",
    "print(\"최종 상태:\")\n",
    "print(\"최종 요약:\", step.get(\"final_summary\", \"요약이 생성되지 않았습니다.\"))\n",
    "print(\"전체 청크 수:\", len(step.get(\"chunks\", [])))\n",
    "print(\"전체 요약 수:\", len(step.get(\"summaries\", [])))\n",
    "print(\"전체 문서 수:\", len(step.get(\"contents\", [])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kt-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
