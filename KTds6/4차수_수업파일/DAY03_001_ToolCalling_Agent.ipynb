{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Tool Calling (Function Calling) + 에이전트(Agent) 개념\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Tool Calling**\n",
    "\n",
    "- **Tool Calling**은 LLM이 외부 시스템과 상호작용하기 위한 **함수 호출 메커니즘**\n",
    "\n",
    "- LLM은 정의된 도구나 함수를 통해 **외부 시스템과 통신**하고 작업을 수행\n",
    "\n",
    "- **Tool calling**은 모델이 시스템과 직접 상호작용할 수 있게 하는 기능\n",
    "\n",
    "- **구조화된 출력**을 통해 API나 데이터베이스와 같은 시스템 요구사항 충족\n",
    "\n",
    "- **스키마 기반 응답**으로 시스템 간 효율적 통신 가능\n",
    "\n",
    "\n",
    "![Tool Calling Concept](https://python.langchain.com/assets/images/tool_calling_concept-552a73031228ff9144c7d59f26dedbbf.png)\n",
    "\n",
    "\n",
    "[참조] https://python.langchain.com/docs/concepts/tool_calling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **Tool Creation** (`@tool` 데코레이터 사용)\n",
    "\n",
    "- **@tool 데코레이터**로 함수에 스키마 정보 추가\n",
    "\n",
    "- **함수와 스키마** 간 자동 연결로 도구 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 간단한 날씨 예제`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"서울\", \"부산\", \"대구\", \"인천\", \"광주\"]):\n",
    "    \"\"\"한국 주요 도시의 날씨 정보를 가져옵니다.\"\"\"\n",
    "    weather_data = {\n",
    "        \"서울\": \"맑음\",\n",
    "        \"부산\": \"흐림\",\n",
    "        \"대구\": \"맑음\",\n",
    "        \"인천\": \"비\",\n",
    "        \"광주\": \"구름많음\"\n",
    "    }\n",
    "    \n",
    "    if city in weather_data:\n",
    "        return f\"{city} 날씨는 {weather_data[city]}\"\n",
    "    else:\n",
    "        raise AssertionError(\"지원하지 않는 도시입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for get_weather\ncity\n  Input should be '서울', '부산', '대구', '인천' or '광주' [type=literal_error, input_value='대전', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 도구 실행\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mget_weather\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m대전\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\myproject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:599\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    596\u001b[39m     **kwargs: Any,\n\u001b[32m    597\u001b[39m ) -> Any:\n\u001b[32m    598\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\myproject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:883\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    882\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    884\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    885\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\myproject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:845\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    843\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    849\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\myproject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:760\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    753\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    754\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    757\u001b[39m ):\n\u001b[32m    758\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    759\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    762\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\myproject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:641\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    639\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    643\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\myproject\\.venv\\Lib\\site-packages\\pydantic\\main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for get_weather\ncity\n  Input should be '서울', '부산', '대구', '인천' or '광주' [type=literal_error, input_value='대전', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/literal_error"
     ]
    }
   ],
   "source": [
    "# 도구 실행\n",
    "get_weather.invoke(\"대전\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) DB 검색 예제`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소 로드 \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"db_korean_cosine_metadata\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- <Document>\n",
      "- **회사 유형:** 상장\n",
      "- **거래소:** NASDAQ: RIVN\n",
      "- **설립:** 2009년 6월, 플로리다 주 록ledge\n",
      "- **설립자:** R. J. 스캐린지\n",
      "- **본사:** 미국 캘리포니아 주 어바인\n",
      "- **서비스 지역:** 북미\n",
      "- **주요 인물:** R. J. 스캐린지 (CEO)\n",
      "- **제품:** 전기 자동차, 배터리\n",
      "- **생산량 (2023):** 57,232대\n",
      "- **서비스:** 전기 자동차 충전, 자동차 보험\n",
      "- **수익 (2023):** 44억 3천만 미국 달러\n",
      "- **순이익 (2023):** -54억 미국 달러\n",
      "- **총 자산 (2023):** 168억 미국 달러\n",
      "</Document>\n",
      "<Source>이 문서는 미국 전기차 회사인 '리비안'에 대한 문서입니다.</Source> [출처: data\\리비안_KR.md]\n",
      "- <Document>\n",
      "Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차 제조업체, 자동차 기술 및 야외 레크리에이션 회사입니다.\n",
      "\n",
      "**주요 정보:**\n",
      "</Document>\n",
      "<Source>이 문서는 미국 전기차 회사인 '리비안'에 대한 문서입니다.</Source> [출처: data\\리비안_KR.md]\n"
     ]
    }
   ],
   "source": [
    "# 검색기 지정하여 테스트 \n",
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9ec57bda-78dd-4253-9983-c2148fe8fa3c', metadata={'language': 'ko', 'company': '리비안', 'source': 'data\\\\리비안_KR.md'}, page_content=\"<Document>\\n- **회사 유형:** 상장\\n- **거래소:** NASDAQ: RIVN\\n- **설립:** 2009년 6월, 플로리다 주 록ledge\\n- **설립자:** R. J. 스캐린지\\n- **본사:** 미국 캘리포니아 주 어바인\\n- **서비스 지역:** 북미\\n- **주요 인물:** R. J. 스캐린지 (CEO)\\n- **제품:** 전기 자동차, 배터리\\n- **생산량 (2023):** 57,232대\\n- **서비스:** 전기 자동차 충전, 자동차 보험\\n- **수익 (2023):** 44억 3천만 미국 달러\\n- **순이익 (2023):** -54억 미국 달러\\n- **총 자산 (2023):** 168억 미국 달러\\n</Document>\\n<Source>이 문서는 미국 전기차 회사인 '리비안'에 대한 문서입니다.</Source>\"),\n",
       " Document(id='8ba04923-8dbd-4848-90dc-39ad1b087ba0', metadata={'language': 'ko', 'source': 'data\\\\리비안_KR.md', 'company': '리비안'}, page_content=\"<Document>\\nRivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차 제조업체, 자동차 기술 및 야외 레크리에이션 회사입니다.\\n\\n**주요 정보:**\\n</Document>\\n<Source>이 문서는 미국 전기차 회사인 '리비안'에 대한 문서입니다.</Source>\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DB 검색하는 사용자 정의 도구 생성\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_db(query: str):\n",
    "    \"\"\"리비안, 테슬라 회사에 대한 정보를 관련 데이터베이스에서 검색합니다.\"\"\"\n",
    "    return chroma_k_retriever.invoke(query)\n",
    "\n",
    "# 도구 실행\n",
    "search_db.invoke(\"리비안은 언제 사업을 시작했나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. **Tool Binding** (모델에 Tool 연결)\n",
    "\n",
    "- **모델-도구 연결**로 입력 스키마 자동 인식\n",
    "\n",
    "- **스키마 기반 검증**으로 올바른 입력 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_o99X1xnYsqRbA5yjrTp7DKkb', 'function': {'arguments': '{\"city\":\"서울\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 109, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BwJHJwbJ5E2nyOvI4A4snB9SL3CNC', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--53bc4156-fde3-44af-a9dd-a62568c035c7-0' tool_calls=[{'name': 'get_weather', 'args': {'city': '서울'}, 'id': 'call_o99X1xnYsqRbA5yjrTp7DKkb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 109, 'output_tokens': 14, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 모델\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\",temperature=0)\n",
    "# model= ChatOllama(model=\"qwen3:0.6b\",temperature=0)\n",
    "\n",
    "# 도구 목록\n",
    "tools = [get_weather, search_db]\n",
    "\n",
    "# 도구를 모델에 바인딩 (bind_tools 메소드 사용)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# 사용자 쿼리를 모델에 전달하여 도구를 호출\n",
    "result = model_with_tools.invoke(\"서울 날씨 어때?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': '서울'},\n",
       "  'id': '78a5dcdd-8d9e-4e16-a1fa-7d5dc66493a3',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. **Tool Calling** (모델이 Tool을 사용하는 경우)\n",
    "\n",
    "- **스키마 기반 응답** 생성으로 정확한 입력 형식 준수\n",
    "\n",
    "- **자동 유효성 검증**으로 오류 방지\n",
    "\n",
    "- **구조화된 출력** 생성으로 시스템 호환성 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "additional_kwargs: \n",
      "{'tool_calls': [{'id': 'call_Wsp3fBDjc8dL4rCdFPKCeKnR', 'function': {'arguments': '{\"city\":\"서울\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "response_metadata: \n",
      "{'token_usage': {'completion_tokens': 14, 'prompt_tokens': 109, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BwJAqwVa5FwHiRM1I1pN18GpRWyza', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "type: \n",
      "ai\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "id: \n",
      "run--c00562ee-b9c9-4a87-8a24-3027744f918d-0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "example: \n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_calls: \n",
      "[{'name': 'get_weather', 'args': {'city': '서울'}, 'id': 'call_Wsp3fBDjc8dL4rCdFPKCeKnR', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "invalid_tool_calls: \n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage_metadata: \n",
      "{'input_tokens': 109, 'output_tokens': 14, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for k in dict(result).keys():\n",
    "    print(f\"{k}: \")\n",
    "    print(dict(result)[k])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'args': {'city': '서울'},\n",
      "  'id': 'call_Wsp3fBDjc8dL4rCdFPKCeKnR',\n",
      "  'name': 'get_weather',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# tool_calls 출력\n",
    "pprint(result.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과:\n",
      "content: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "additional_kwargs: \n",
      "{'tool_calls': [{'id': 'call_hcIweZcn3p0H4sdLej6t0ZdV', 'function': {'arguments': '{\"query\":\"리비안 사업 시작\"}', 'name': 'search_db'}, 'type': 'function'}], 'refusal': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "response_metadata: \n",
      "{'token_usage': {'completion_tokens': 18, 'prompt_tokens': 114, 'total_tokens': 132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BwJClSCZArTGXAsUUFpHCkKetWC5J', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "type: \n",
      "ai\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "id: \n",
      "run--f87c977c-9573-45ed-a647-f09f2abcea17-0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "example: \n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_calls: \n",
      "[{'name': 'search_db', 'args': {'query': '리비안 사업 시작'}, 'id': 'call_hcIweZcn3p0H4sdLej6t0ZdV', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "invalid_tool_calls: \n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage_metadata: \n",
      "{'input_tokens': 114, 'output_tokens': 18, 'total_tokens': 132, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '리비안 사업 시작'},\n",
      "  'id': 'call_hcIweZcn3p0H4sdLej6t0ZdV',\n",
      "  'name': 'search_db',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# DB 검색 도구 호출\n",
    "search_result = model_with_tools.invoke(\"리비안은 언제 사업을 시작했나요?\")\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"검색 결과:\")\n",
    "for k in dict(search_result).keys():\n",
    "    print(f\"{k}: \")\n",
    "    print(dict(search_result)[k])\n",
    "    print(\"-\"*100)\n",
    "\n",
    "# tool_calls 출력\n",
    "pprint(search_result.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. **Tool Execution**  (Tool이 호출된 경우 실행)\n",
    "\n",
    "- **인자 기반 실행**으로 도구 기능 수행\n",
    "\n",
    "- **모델 제공 파라미터**로 자동화된 실행\n",
    "\n",
    "- **실행 결과** 처리 및 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 함수의 인자를 직접 전달`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': '서울'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수의 인자를 직접 전달하는 방식으로 실행 -> 도구를 직접 호출\n",
    "result.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울 날씨는 맑음'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather.invoke(result.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '리비안 사업 시작'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9ec57bda-78dd-4253-9983-c2148fe8fa3c', metadata={'company': '리비안', 'source': 'data\\\\리비안_KR.md', 'language': 'ko'}, page_content=\"<Document>\\n- **회사 유형:** 상장\\n- **거래소:** NASDAQ: RIVN\\n- **설립:** 2009년 6월, 플로리다 주 록ledge\\n- **설립자:** R. J. 스캐린지\\n- **본사:** 미국 캘리포니아 주 어바인\\n- **서비스 지역:** 북미\\n- **주요 인물:** R. J. 스캐린지 (CEO)\\n- **제품:** 전기 자동차, 배터리\\n- **생산량 (2023):** 57,232대\\n- **서비스:** 전기 자동차 충전, 자동차 보험\\n- **수익 (2023):** 44억 3천만 미국 달러\\n- **순이익 (2023):** -54억 미국 달러\\n- **총 자산 (2023):** 168억 미국 달러\\n</Document>\\n<Source>이 문서는 미국 전기차 회사인 '리비안'에 대한 문서입니다.</Source>\"),\n",
       " Document(id='ee612575-7bd5-4e2e-aa61-7523a4e9a6ea', metadata={'language': 'ko', 'company': '리비안', 'source': 'data\\\\리비안_KR.md'}, page_content=\"<Document>\\n**역사**\\n\\n**초창기 (2009–15):**\\n\\n- 2009년 R. J. 스캐린지가 Mainstream Motors로 설립.\\n- 2011년 Rivian Automotive로 사명 변경.\\n- 처음에는 스포츠카 프로토타입(R1)에 집중했지만 전기 및 자율 주행 차량으로 전환.\\n\\n**생산 준비 (2016–20):**\\n\\n- 2017년 일리노이 주 노멀에 있는 이전 Mitsubishi Motors 제조 공장을 1,600만 달러에 인수.\\n- 2017년 12월, 첫 두 제품인 R1T (픽업 트럭)와 R1S (SUV)를 공개.\\n- 생산은 2020년에 시작될 예정.\\n\\n**첫 모델 배송; IPO; 감원 및 확장 (2021–24):**\\n</Document>\\n<Source>이 문서는 미국 전기차 회사인 '리비안'에 대한 문서입니다.</Source>\")]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_db.invoke(search_result.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ToolCall 객체를 전달 전달`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather',\n",
       " 'args': {'city': '서울'},\n",
       " 'id': 'call_Wsp3fBDjc8dL4rCdFPKCeKnR',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='서울 날씨는 맑음', name='get_weather', tool_call_id='call_Wsp3fBDjc8dL4rCdFPKCeKnR')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToolCall 객체를 전달 전달하는 방식으로 실행 -> ToolMessage 객체를 반환\n",
    "get_weather.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='[Document(id=\\'9ec57bda-78dd-4253-9983-c2148fe8fa3c\\', metadata={\\'source\\': \\'data\\\\\\\\리비안_KR.md\\', \\'company\\': \\'리비안\\', \\'language\\': \\'ko\\'}, page_content=\"<Document>\\\\n- **회사 유형:** 상장\\\\n- **거래소:** NASDAQ: RIVN\\\\n- **설립:** 2009년 6월, 플로리다 주 록ledge\\\\n- **설립자:** R. J. 스캐린지\\\\n- **본사:** 미국 캘리포니아 주 어바인\\\\n- **서비스 지역:** 북미\\\\n- **주요 인물:** R. J. 스캐린지 (CEO)\\\\n- **제품:** 전기 자동차, 배터리\\\\n- **생산량 (2023):** 57,232대\\\\n- **서비스:** 전기 자동차 충전, 자동차 보험\\\\n- **수익 (2023):** 44억 3천만 미국 달러\\\\n- **순이익 (2023):** -54억 미국 달러\\\\n- **총 자산 (2023):** 168억 미국 달러\\\\n</Document>\\\\n<Source>이 문서는 미국 전기차 회사인 \\'리비안\\'에 대한 문서입니다.</Source>\"), Document(id=\\'ee612575-7bd5-4e2e-aa61-7523a4e9a6ea\\', metadata={\\'company\\': \\'리비안\\', \\'source\\': \\'data\\\\\\\\리비안_KR.md\\', \\'language\\': \\'ko\\'}, page_content=\"<Document>\\\\n**역사**\\\\n\\\\n**초창기 (2009–15):**\\\\n\\\\n- 2009년 R. J. 스캐린지가 Mainstream Motors로 설립.\\\\n- 2011년 Rivian Automotive로 사명 변경.\\\\n- 처음에는 스포츠카 프로토타입(R1)에 집중했지만 전기 및 자율 주행 차량으로 전환.\\\\n\\\\n**생산 준비 (2016–20):**\\\\n\\\\n- 2017년 일리노이 주 노멀에 있는 이전 Mitsubishi Motors 제조 공장을 1,600만 달러에 인수.\\\\n- 2017년 12월, 첫 두 제품인 R1T (픽업 트럭)와 R1S (SUV)를 공개.\\\\n- 생산은 2020년에 시작될 예정.\\\\n\\\\n**첫 모델 배송; IPO; 감원 및 확장 (2021–24):**\\\\n</Document>\\\\n<Source>이 문서는 미국 전기차 회사인 \\'리비안\\'에 대한 문서입니다.</Source>\")]', name='search_db', tool_call_id='call_hcIweZcn3p0H4sdLej6t0ZdV')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_db.invoke(search_result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Tool Calling 사용 시 **고려사항**\n",
    "\n",
    "- **모델 호환성**이 Tool Calling 성능에 직접 영향\n",
    "\n",
    "- **명확한 도구 정의**가 모델의 이해도와 활용도 향상\n",
    "\n",
    "- **단순한 기능**의 도구가 더 효과적으로 작동\n",
    "\n",
    "- **과다한 도구**는 모델 성능 저하 유발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Agent**\n",
    "\n",
    "- **LLM(대규모 언어 모델)** 을 의사결정 엔진으로 사용하여 작업을 수행하는 시스템\n",
    "\n",
    "- 모델은 입력된 데이터를 분석하여 **맥락에 맞는 의사결정**을 수행\n",
    "\n",
    "- 시스템은 사용자의 요청을 이해하고 **적절한 해결책**을 제시\n",
    "\n",
    "- 복잡한 작업을 자동화하여 **업무 효율성**을 높일 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **AgentExecutor** \n",
    "\n",
    "- **AgentExecutor**는 LangChain의 기본 에이전트 실행 시스템\n",
    "\n",
    "- 에이전트의 **계획-실행-관찰** 사이클을 자동으로 관리\n",
    "\n",
    "- 에이전트의 행동을 **모니터링**하고 결과를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 추가 도구 정의`\n",
    "\n",
    "- **@tool 데코레이터**를 사용해 계산(파이썬 코드 실행) 기능을 가진 **커스텀 도구를 정의**\n",
    "\n",
    "- 데코레이터를 통해 함수가 **Tool Calling 시스템에 등록**되어 LLM이 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"수학 계산을 수행합니다.\"\"\"\n",
    "    return eval(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도구 실행 \n",
    "calculate.invoke(\"3+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 프롬프트 템플릿`\n",
    "\n",
    "- **프롬프트 템플릿**은 에이전트의 **기본 행동과 응답 방식**을 정의하는 지침\n",
    "\n",
    "- 에이전트의 **일관된 응답**과 **효율적인 도구 사용**을 위한 기본 틀 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 사용자의 요청을 처리하는 AI Assistant입니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='부산 날씨 어때?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 사용자의 요청을 처리하는 AI Assistant입니다.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "# 프롬프트 템플릿 실행\n",
    "response = prompt.invoke({\n",
    "    \"input\": \"부산 날씨 어때?\",\n",
    "    \"agent_scratchpad\": []  # 에이전트 스크래치패드 (메시지 기록)\n",
    "})\n",
    "\n",
    "# 프롬프트 템플릿 실행 결과\n",
    "pprint(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) LLM 지정`\n",
    "\n",
    "- **ChatGPT 모델**이 에이전트의 **핵심 추론 엔진**으로 사용됨\n",
    "\n",
    "- 모델은 사용자 입력을 분석하고 **적절한 도구를 선택**하여 작업 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Agent (에이전트) 생성`\n",
    "\n",
    "- **에이전트**는 LLM과 도구를 **통합**하여 복잡한 작업을 수행하는 시스템\n",
    "\n",
    "- 프롬프트 템플릿을 기반으로 **사용자 요청을 해석**하고 적절한 도구 선택\n",
    "\n",
    "- 도구 실행 결과를 분석하여 **최종 응답을 생성**하는 워크플로우 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# 도구 목록 생성 \n",
    "tools = [get_weather, search_db, calculate]\n",
    "\n",
    "# 에이전트 생성 (도구 호출)\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) AgentExecutor (에이전트 실행기) 생성`\n",
    "\n",
    "- **AgentExecutor**는 에이전트의 **작업 흐름을 관리**하고 결과를 처리하는 컴포넌트\n",
    "\n",
    "- 사용자 입력부터 최종 출력까지의 **전체 프로세스를 조율**하고 제어\n",
    "\n",
    "- 에러 처리, 로깅, 결과 포맷팅 등 **시스템 운영에 필요한 기능** 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# 에이전트 실행기 생성\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,      # 도구 호출 에이전트\n",
    "    tools=tools,      # 도구 목록\n",
    "    verbose=True,     # 상세 로그 출력\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_weather` with `{'city': '서울'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m서울 날씨는 맑음\u001b[0m\u001b[32;1m\u001b[1;3m서울의 날씨는 맑음입니다. 더 궁금한 점 있으신가요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": \"서울의 날씨는 어떤가요?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '서울의 날씨는 어떤가요?', 'output': '서울의 날씨는 맑음입니다. 더 궁금한 점 있으신가요?'}\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행 결과 출력\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 실행기 생성\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,      # 도구 호출 에이전트\n",
    "    tools=tools,      # 도구 목록\n",
    "    return_intermediate_steps=True  # 중간 단계 반환 (기본값 False)\n",
    "    )\n",
    "\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": \"32 더하기 18은 얼마인가요?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '32 더하기 18은 얼마인가요?',\n",
      " 'intermediate_steps': [(ToolAgentAction(tool='calculate', tool_input={'expression': '32+18'}, log=\"\\nInvoking: `calculate` with `{'expression': '32+18'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_WtXMbpfN85n23rB7FrB2lVK0', 'function': {'arguments': '{\"expression\":\"32+18\"}', 'name': 'calculate'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4.1-mini-2025-04-14', 'service_tier': 'default'}, id='run--d3fd038a-5dae-44a7-a643-6994d7c620c1', tool_calls=[{'name': 'calculate', 'args': {'expression': '32+18'}, 'id': 'call_WtXMbpfN85n23rB7FrB2lVK0', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'calculate', 'args': '{\"expression\":\"32+18\"}', 'id': 'call_WtXMbpfN85n23rB7FrB2lVK0', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_WtXMbpfN85n23rB7FrB2lVK0'),\n",
      "                         50)],\n",
      " 'output': '32 더하기 18은 50입니다.'}\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행 결과 출력\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. **LangGraph** \n",
    "\n",
    "- **LangGraph**는 LangChain의 확장 도구로 **고급 에이전트 개발**을 지원\n",
    "\n",
    "- **그래프 기반 워크플로우**를 통해 복잡한 에이전트 로직을 구현할 수 있음 \n",
    "\n",
    "- 상태 관리와 **타입 안전성**을 통해 안정적인 에이전트 실행을 보장\n",
    "\n",
    "- AgentExecutor보다 더 **유연한 사용자 정의**가 가능함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 도구 실행 에이전트 정의`\n",
    "\n",
    "- LangGraph의 **react agent executor**는 메시지 목록으로 상태를 관리\n",
    "\n",
    "- 에이전트의 출력에 **도구 호출**이 없을 때까지 메시지를 계속 처리함\n",
    "\n",
    "- 시작 시 **초기 메시지 목록**을 입력으로 사용\n",
    "\n",
    "- 실행 결과로 전체 **대화 기록**을 포함한 그래프 상태를 반환\n",
    "\n",
    "- **메시지 기반 상태** 관리를 통해 에이전트의 실행 흐름을 체계적으로 제어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 도구 목록 생성 \n",
    "tools = [get_weather, calculate]\n",
    "\n",
    "# 도구 실행 에인전트 생성\n",
    "langgraph_agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 에이전트 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='32 곱하기 18은 얼마인가요?', additional_kwargs={}, response_metadata={}, id='96843d76-2657-46f5-bb1f-fcdbf4d62da5'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_oiFcR7f5MJEyMZ9GXWfpQENM', 'function': {'arguments': '{\"expression\":\"32 * 18\"}', 'name': 'calculate'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 101, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BwJLTwRfcfQjvAEwykillXy4A0afK', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--084a03a9-3911-4303-8d14-5ab081a2d4be-0', tool_calls=[{'name': 'calculate', 'args': {'expression': '32 * 18'}, 'id': 'call_oiFcR7f5MJEyMZ9GXWfpQENM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 101, 'output_tokens': 16, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='576', name='calculate', id='c315762c-2737-44bb-b476-1f37ba0a28a5', tool_call_id='call_oiFcR7f5MJEyMZ9GXWfpQENM'),\n",
      "              AIMessage(content='32 곱하기 18은 576입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 125, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BwJLUyTL6xFAYT5e5VNKXiduYnVWg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--df546436-1106-4650-a9c0-4cc0ab6f0ed6-0', usage_metadata={'input_tokens': 125, 'output_tokens': 12, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행\n",
    "messages = langgraph_agent_executor.invoke(\n",
    "    {\"messages\": [(\"human\", \"32 곱하기 18은 얼마인가요?\")]}\n",
    ")\n",
    "\n",
    "# 에이전트 실행 결과 출력\n",
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
