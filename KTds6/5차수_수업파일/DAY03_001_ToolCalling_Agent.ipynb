{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling & Agent\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tool Calling 개념\n",
    "\n",
    "- **Tool Calling**은 LLM이 외부 시스템과 상호작용하기 위한 핵심 메커니즘\n",
    "- **구조화된 출력**: LLM이 정의된 스키마에 따라 함수 호출 정보를 생성\n",
    "- **외부 시스템 연동**: API, 데이터베이스, 파일 시스템 등과 연결\n",
    "- **자동 검증**: 스키마 기반으로 입력 파라미터 자동 검증\n",
    "- **유연한 확장**: 새로운 도구를 쉽게 추가하고 제거 가능\n",
    "\n",
    "\n",
    "![Tool Calling Concept](https://python.langchain.com/assets/images/tool_calling_concept-552a73031228ff9144c7d59f26dedbbf.png)\n",
    "\n",
    "\n",
    "[참조] https://python.langchain.com/docs/concepts/tool_calling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. 기본적인 Tool 생성\n",
    "\n",
    "#### 1.1 @tool 데코레이터 사용법\n",
    "\n",
    "- **@tool 데코레이터**로 함수에 스키마 정보 추가\n",
    "\n",
    "- **함수와 스키마** 간 자동 연결로 도구 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"두 정수를 더합니다.\n",
    "    \n",
    "    Args:\n",
    "        a: 첫 번째 정수\n",
    "        b: 두 번째 정수\n",
    "    \n",
    "    Returns:\n",
    "        두 수의 합\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"두 정수를 곱합니다.\n",
    "    \n",
    "    Args:\n",
    "        a: 첫 번째 정수\n",
    "        b: 두 번째 정수\n",
    "    \n",
    "    Returns:\n",
    "        두 수의 곱\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# 도구 실행 테스트\n",
    "print(add.invoke({'a': 3, 'b': 5}))  # 8\n",
    "print(multiply.invoke({'a': 4, 'b': 6}))  # 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 복잡한 Tool 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "@tool\n",
    "def get_current_time(format_type: Literal[\"date\", \"time\", \"both\"] = \"both\") -> str:\n",
    "    \"\"\"현재 날짜와 시간을 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        format_type: 반환할 형식 ('date', 'time', 'both' 중 선택)\n",
    "    \n",
    "    Returns:\n",
    "        포맷된 날짜/시간 문자열\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    \n",
    "    if format_type == \"date\":\n",
    "        return now.strftime(\"%Y년 %m월 %d일\")\n",
    "    elif format_type == \"time\":\n",
    "        return now.strftime(\"%H시 %M분 %S초\")\n",
    "    else:\n",
    "        return now.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
    "\n",
    "@tool\n",
    "def calculate_age(birth_year: int) -> str:\n",
    "    \"\"\"태어난 년도를 입력받아 나이를 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        birth_year: 태어난 년도 (예: 1990)\n",
    "    \n",
    "    Returns:\n",
    "        계산된 나이\n",
    "    \"\"\"\n",
    "    current_year = datetime.now().year\n",
    "    age = current_year - birth_year\n",
    "    return f\"{age}세\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tool을 LLM에 연결하기\n",
    "\n",
    "#### 2.1 기본 연결 방법\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_OVWFVw09ljA4O1Xz2znxH7WL', 'function': {'arguments': '{\"a\":15,\"b\":23}', 'name': 'add'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 249, 'total_tokens': 266, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26WBQdEvAYxVsqGagdBO35Smfj2C', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--f8e86967-db42-44c8-8f25-bda72d44af61-0' tool_calls=[{'name': 'add', 'args': {'a': 15, 'b': 23}, 'id': 'call_OVWFVw09ljA4O1Xz2znxH7WL', 'type': 'tool_call'}] usage_metadata={'input_tokens': 249, 'output_tokens': 17, 'total_tokens': 266, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 도구 목록 생성\n",
    "tools = [add, multiply, get_current_time, calculate_age]\n",
    "\n",
    "# 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# 계산 도구 호출 테스트\n",
    "response = llm_with_tools.invoke(\"15와 23을 더해주세요\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'add', 'args': {'a': 15, 'b': 23}, 'id': 'call_OVWFVw09ljA4O1Xz2znxH7WL', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_1j9ImJDtiqHcITZGTV3nAHWZ', 'function': {'arguments': '{\"format_type\":\"both\"}', 'name': 'get_current_time'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 246, 'total_tokens': 262, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26WfnDWI4eD0jg6hJq5s3lKfg6ut', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--fe8d2ef9-fd57-4e66-a46a-c9b056707a21-0' tool_calls=[{'name': 'get_current_time', 'args': {'format_type': 'both'}, 'id': 'call_1j9ImJDtiqHcITZGTV3nAHWZ', 'type': 'tool_call'}] usage_metadata={'input_tokens': 246, 'output_tokens': 16, 'total_tokens': 262, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 날짜 시간 도구 호출 테스트\n",
    "response = llm_with_tools.invoke(\"현재 시간을 알려주세요\")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_current_time', 'args': {'format_type': 'both'}, 'id': 'call_1j9ImJDtiqHcITZGTV3nAHWZ', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_zSvxP6xgRpWswBANvgNvWwJ1', 'function': {'arguments': '{\"birth_year\":1990}', 'name': 'calculate_age'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 261, 'total_tokens': 277, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26X1vNpZlsuoNfowBA9dDyhSfrF5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--1f96ca25-3025-44c8-ad2d-14049d4a4f5e-0' tool_calls=[{'name': 'calculate_age', 'args': {'birth_year': 1990}, 'id': 'call_zSvxP6xgRpWswBANvgNvWwJ1', 'type': 'tool_call'}] usage_metadata={'input_tokens': 261, 'output_tokens': 16, 'total_tokens': 277, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 나이 계산 도구 호출 테스트\n",
    "response = llm_with_tools.invoke(\"내가 태어난 년도는 1990년입니다. 내 나이를 알려주세요.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'calculate_age', 'args': {'birth_year': 1990}, 'id': 'call_zSvxP6xgRpWswBANvgNvWwJ1', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Tool Choice 옵션\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_KDOVW2Pa25VvBraH5J4PwjOe', 'function': {'arguments': '{\"a\":10,\"b\":20}', 'name': 'add'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 258, 'total_tokens': 267, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26YCMgK8YUkJVN229FMwi5JW3EXx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--fa67ef18-7a42-4a7d-aa4e-3271d279a699-0' tool_calls=[{'name': 'add', 'args': {'a': 10, 'b': 20}, 'id': 'call_KDOVW2Pa25VvBraH5J4PwjOe', 'type': 'tool_call'}] usage_metadata={'input_tokens': 258, 'output_tokens': 9, 'total_tokens': 267, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 특정 도구를 강제로 사용하도록 설정\n",
    "llm_forced_add = llm.bind_tools(tools, tool_choice=\"add\")\n",
    "response = llm_forced_add.invoke(\"10+20계산을 해주세요\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'add', 'args': {'a': 10, 'b': 20}, 'id': 'call_KDOVW2Pa25VvBraH5J4PwjOe', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_yycg8TlIiWb4Jf0daL4jydT4', 'function': {'arguments': '{\"format_type\":\"both\"}', 'name': 'get_current_time'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 244, 'total_tokens': 260, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26YNPwviLCAT4lQb8WNjOPz1WPS9', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--9efe953d-7782-439a-93de-762345d6bba5-0' tool_calls=[{'name': 'get_current_time', 'args': {'format_type': 'both'}, 'id': 'call_yycg8TlIiWb4Jf0daL4jydT4', 'type': 'tool_call'}] usage_metadata={'input_tokens': 244, 'output_tokens': 16, 'total_tokens': 260, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 반드시 어떤 도구든 사용하도록 설정\n",
    "llm_must_use_tool = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "response = llm_must_use_tool.invoke(\"안녕하세요\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_current_time', 'args': {'format_type': 'both'}, 'id': 'call_yycg8TlIiWb4Jf0daL4jydT4', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_9kW3b2Lo8IgccZyZWudDsbTB', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'add'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 253, 'total_tokens': 270, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26Yn3IlhKgn3lO845VjcyXXUBF0o', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ae1e1d93-71f5-4af2-ac98-12efe6632def-0' tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_9kW3b2Lo8IgccZyZWudDsbTB', 'type': 'tool_call'}] usage_metadata={'input_tokens': 253, 'output_tokens': 17, 'total_tokens': 270, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 병렬 도구 호출 비활성화\n",
    "llm_sequential = llm.bind_tools(tools, parallel_tool_calls=False)\n",
    "response = llm_sequential.invoke(\"3+5와 4*6을 계산해주세요\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_9kW3b2Lo8IgccZyZWudDsbTB', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_8U4Wi348dqABztgIi6e7AbYg', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_o47Pcy12lNz9c98qyAf2yflx', 'function': {'arguments': '{\"a\": 4, \"b\": 6}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 253, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26Z6EnJupzzMoO0LTwMXjIvkk4oA', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--b330adde-5840-49ce-9537-6cba49007954-0' tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_8U4Wi348dqABztgIi6e7AbYg', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 4, 'b': 6}, 'id': 'call_o47Pcy12lNz9c98qyAf2yflx', 'type': 'tool_call'}] usage_metadata={'input_tokens': 253, 'output_tokens': 50, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 병렬 도구 호출 활성화\n",
    "llm_sequential = llm.bind_tools(tools, parallel_tool_calls=True)\n",
    "response = llm_sequential.invoke(\"3+5와 4*6을 계산해주세요\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_8U4Wi348dqABztgIi6e7AbYg', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 4, 'b': 6}, 'id': 'call_o47Pcy12lNz9c98qyAf2yflx', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8U4Wi348dqABztgIi6e7AbYg', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_o47Pcy12lNz9c98qyAf2yflx', 'function': {'arguments': '{\"a\": 4, \"b\": 6}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 253, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C26Z6EnJupzzMoO0LTwMXjIvkk4oA', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b330adde-5840-49ce-9537-6cba49007954-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_8U4Wi348dqABztgIi6e7AbYg', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 4, 'b': 6}, 'id': 'call_o47Pcy12lNz9c98qyAf2yflx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 253, 'output_tokens': 50, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tool Calling 처리하기\n",
    "\n",
    "#### 3.1 Tool Calls 확인하고 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도구: get_current_time\n",
      "결과: 2025년 08월 08일\n"
     ]
    }
   ],
   "source": [
    "def execute_tool_calls(message, tools_dict):\n",
    "    \"\"\"Tool calls를 실행하고 결과를 반환합니다.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for tool_call in message.tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        \n",
    "        if tool_name in tools_dict:\n",
    "            tool = tools_dict[tool_name]\n",
    "            result = tool.invoke(tool_args)\n",
    "            results.append({\n",
    "                'tool_call_id': tool_call['id'],\n",
    "                'tool_name': tool_name,\n",
    "                'result': result\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 도구 딕셔너리 생성\n",
    "tools_dict = {tool.name: tool for tool in tools}\n",
    "\n",
    "# 테스트\n",
    "response = llm_with_tools.invoke(\"오늘 날짜를 알려주세요\")\n",
    "if response.tool_calls:\n",
    "    results = execute_tool_calls(response, tools_dict)\n",
    "    for result in results:\n",
    "        print(f\"도구: {result['tool_name']}\")\n",
    "        print(f\"결과: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 완전한 대화 흐름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 곱하기 8은 120입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "def chat_with_tools(user_input: str, llm_with_tools, tools_dict):\n",
    "    \"\"\"도구를 사용한 완전한 대화 처리\"\"\"\n",
    "    messages = [HumanMessage(content=user_input)]\n",
    "    \n",
    "    # LLM 호출\n",
    "    ai_response = llm_with_tools.invoke(messages)\n",
    "    messages.append(ai_response)\n",
    "    \n",
    "    # Tool calls가 있으면 실행\n",
    "    if ai_response.tool_calls:\n",
    "        for tool_call in ai_response.tool_calls:\n",
    "            tool_name = tool_call['name']\n",
    "            tool_args = tool_call['args']\n",
    "            tool_id = tool_call['id']\n",
    "            \n",
    "            # 도구 실행\n",
    "            if tool_name in tools_dict:\n",
    "                tool_result = tools_dict[tool_name].invoke(tool_args)\n",
    "                # ToolMessage 추가\n",
    "                messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=str(tool_result),\n",
    "                        tool_call_id=tool_id\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        # 최종 응답 생성\n",
    "        final_response = llm_with_tools.invoke(messages)\n",
    "        return final_response.content\n",
    "    else:\n",
    "        return ai_response.content\n",
    "\n",
    "# 테스트\n",
    "result = chat_with_tools(\"15 곱하기 8은 얼마인가요?\", llm_with_tools, tools_dict)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 고급 Tool Calling 기법\n",
    "\n",
    "#### 4.1 오류 처리가 포함된 Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def safe_divide(a: float, b: float) -> str:\n",
    "    \"\"\"두 수를 나눕니다. (0으로 나누기 방지)\n",
    "    \n",
    "    Args:\n",
    "        a: 피제수\n",
    "        b: 제수\n",
    "    \n",
    "    Returns:\n",
    "        나눗셈 결과 또는 오류 메시지\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if b == 0:\n",
    "            return \"오류: 0으로 나눌 수 없습니다.\"\n",
    "        result = a / b\n",
    "        return f\"{a} ÷ {b} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"계산 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def validate_input(value: str, data_type: Literal[\"int\", \"float\", \"email\"]) -> str:\n",
    "    \"\"\"입력값을 검증합니다.\n",
    "    \n",
    "    Args:\n",
    "        value: 검증할 값\n",
    "        data_type: 데이터 타입 ('int', 'float', 'email')\n",
    "    \n",
    "    Returns:\n",
    "        검증 결과\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    if data_type == \"int\":\n",
    "        try:\n",
    "            int(value)\n",
    "            return f\"'{value}'는 유효한 정수입니다.\"\n",
    "        except ValueError:\n",
    "            return f\"'{value}'는 유효하지 않은 정수입니다.\"\n",
    "    \n",
    "    elif data_type == \"float\":\n",
    "        try:\n",
    "            float(value)\n",
    "            return f\"'{value}'는 유효한 실수입니다.\"\n",
    "        except ValueError:\n",
    "            return f\"'{value}'는 유효하지 않은 실수입니다.\"\n",
    "    \n",
    "    elif data_type == \"email\":\n",
    "        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "        if re.match(pattern, value):\n",
    "            return f\"'{value}'는 유효한 이메일 주소입니다.\"\n",
    "        else:\n",
    "            return f\"'{value}'는 유효하지 않은 이메일 주소입니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'safe_divide', 'args': {'a': 10, 'b': 3}, 'id': 'call_4H5UwdmpkAaOEMMuqLor0jC2', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 도구 목록 생성\n",
    "tools = [safe_divide, validate_input]\n",
    "\n",
    "# 채팅 모델에 도구 바인딩\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# 모델이 도구를 사용하도록 요청\n",
    "response = model_with_tools.invoke(\"10을 3으로 나눠주세요\")\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'validate_input', 'args': {'value': 'test@example.com', 'data_type': 'email'}, 'id': 'call_dU50rZDSeBhDd8YiQVT9UkyI', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# 이메일 검증 요청\n",
    "response = model_with_tools.invoke(\"test@example.com이 유효한 이메일인지 확인해주세요\")\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 파일 처리 Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "@tool\n",
    "def read_file(file_path: str, encoding: str = \"utf-8\") -> str:\n",
    "    \"\"\"파일을 읽어서 내용을 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        file_path: 읽을 파일 경로\n",
    "        encoding: 파일 인코딩 (기본: utf-8)\n",
    "    \n",
    "    Returns:\n",
    "        파일 내용 또는 오류 메시지\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            content = file.read()\n",
    "            return f\"파일 '{file_path}' 내용:\\n{content}\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"오류: 파일 '{file_path}'를 찾을 수 없습니다.\"\n",
    "    except Exception as e:\n",
    "        return f\"파일 읽기 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def write_file(file_path: str, content: str, encoding: str = \"utf-8\") -> str:\n",
    "    \"\"\"파일에 내용을 씁니다.\n",
    "    \n",
    "    Args:\n",
    "        file_path: 쓸 파일 경로\n",
    "        content: 쓸 내용\n",
    "        encoding: 파일 인코딩 (기본: utf-8)\n",
    "    \n",
    "    Returns:\n",
    "        작업 결과 메시지\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding=encoding) as file:\n",
    "            file.write(content)\n",
    "            return f\"파일 '{file_path}'에 성공적으로 저장했습니다.\"\n",
    "    except Exception as e:\n",
    "        return f\"파일 쓰기 오류: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def process_json_data(json_string: str, operation: Literal[\"validate\", \"pretty\", \"minify\"]) -> str:\n",
    "    \"\"\"JSON 데이터를 처리합니다.\n",
    "    \n",
    "    Args:\n",
    "        json_string: JSON 문자열\n",
    "        operation: 수행할 작업 ('validate', 'pretty', 'minify')\n",
    "    \n",
    "    Returns:\n",
    "        처리 결과\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        \n",
    "        if operation == \"validate\":\n",
    "            return \"유효한 JSON 형식입니다.\"\n",
    "        elif operation == \"pretty\":\n",
    "            return json.dumps(data, indent=2, ensure_ascii=False)\n",
    "        elif operation == \"minify\":\n",
    "            return json.dumps(data, separators=(',', ':'), ensure_ascii=False)\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        return f\"JSON 파싱 오류: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"처리 오류: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예제 1: test.txt 파일에 '안녕하세요, LangChain!'이라는 내용을 저장해주세요.\n",
      "결과: 파일 'test.txt'에 '안녕하세요, LangChain!'이라는 내용을 성공적으로 저장했습니다.\n",
      "--------------------------------------------------\n",
      "예제 2: test.txt 파일을 읽어주세요.\n",
      "결과: test.txt 파일 내용을 읽었습니다. 파일 내용은 \"안녕하세요, LangChain!\" 입니다.\n",
      "--------------------------------------------------\n",
      "예제 3: {\"name\": \"김철수\", \"age\": 30, \"city\": \"서울\"} JSON을 예쁘게 포맷팅해주세요.\n",
      "결과: {\n",
      "  \"name\": \"김철수\",\n",
      "  \"age\": 30,\n",
      "  \"city\": \"서울\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "예제 4: config.json 파일에 {\"database\": {\"host\": \"localhost\", \"port\": 5432}} 내용을 저장하고 읽어주세요.\n",
      "결과: config.json 파일에 {\"database\": {\"host\": \"localhost\", \"port\": 5432}} 내용을 성공적으로 저장했습니다.\n",
      "파일 내용도 동일하게 잘 읽혔습니다. 다른 작업 도와드릴까요?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 도구 목록 생성\n",
    "tools = [read_file, write_file, process_json_data]\n",
    "\n",
    "# 채팅 모델에 도구 바인딩\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# 도구 딕셔너리 생성\n",
    "tools_dict = {tool.name: tool for tool in tools}\n",
    "\n",
    "# 모델이 도구를 사용하도록 요청\n",
    "examples = [\n",
    "    \"test.txt 파일에 '안녕하세요, LangChain!'이라는 내용을 저장해주세요.\",\n",
    "    \"test.txt 파일을 읽어주세요.\",\n",
    "    '{\"name\": \"김철수\", \"age\": 30, \"city\": \"서울\"} JSON을 예쁘게 포맷팅해주세요.',\n",
    "    'config.json 파일에 {\"database\": {\"host\": \"localhost\", \"port\": 5432}} 내용을 저장하고 읽어주세요.'\n",
    "]\n",
    "\n",
    "for i, example in enumerate(examples, 1):\n",
    "    print(f\"예제 {i}: {example}\")\n",
    "\n",
    "    result = chat_with_tools(example, model_with_tools, tools_dict)\n",
    "    print(f\"결과: {result}\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Tool Calling 사용 시 **고려사항**\n",
    "\n",
    "- **모델 호환성**이 Tool Calling 성능에 직접 영향\n",
    "\n",
    "- **명확한 도구 정의**가 모델의 이해도와 활용도 향상\n",
    "\n",
    "- **단순한 기능**의 도구가 더 효과적으로 작동\n",
    "\n",
    "- **과다한 도구**는 모델 성능 저하 유발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Agent 개념과 실습\n",
    "\n",
    "- **Agent**는 LLM을 의사결정 엔진으로 사용하여 복잡한 작업을 자동으로 수행하는 시스템\n",
    "- Agent의 구성 요소:\n",
    "    1. **LLM (추론 엔진)**: 상황을 분석하고 다음 행동을 결정\n",
    "    2. **Tools (도구)**: Agent가 사용할 수 있는 기능들\n",
    "    3. **Memory (메모리)**: 이전 대화나 작업 기록 저장\n",
    "    4. **Prompt (프롬프트)**: Agent의 역할과 행동 지침 정의\n",
    "- **LangGraph** 활용\n",
    "    - **LangGraph**는 LangChain의 확장 도구로 **고급 에이전트 개발**을 지원\n",
    "    - **그래프 기반 워크플로우**를 통해 복잡한 에이전트 로직을 구현할 수 있음 \n",
    "    - 상태 관리와 **타입 안전성**을 통해 안정적인 에이전트 실행을 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph Agent 응답:\n",
      "AI: 오늘 42세인 사람의 생년도를 계산하려면 현재 연도에서 42를 빼면 됩니다. 현재 연도를 확인한 후 계산해드리겠습니다. 잠시만 기다려 주세요.\n",
      "AI: 오늘이 2025년 8월 8일이고, 42세인 사람의 생년은 1983년입니다. 생년월일은 1983년 8월 8일 이전에 태어났음을 의미합니다. 정확한 생일은 추가 정보가 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# # 상태 정의\n",
    "# class AgentState(TypedDict):\n",
    "#     messages: List[BaseMessage]\n",
    "\n",
    "# 기본 React Agent 생성\n",
    "tools = [add, multiply, get_current_time, calculate_age, safe_divide, validate_input, read_file, write_file, process_json_data]\n",
    "langgraph_agent = create_react_agent(llm, tools)\n",
    "\n",
    "# 실행\n",
    "response = langgraph_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"오늘 42세인 사람의 생년월일은?\")]\n",
    "})\n",
    "\n",
    "print(\"LangGraph Agent 응답:\")\n",
    "for message in response['messages']:\n",
    "    if isinstance(message, AIMessage) and message.content:\n",
    "        print(f\"AI: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='오늘 42세인 사람의 생년월일은?', additional_kwargs={}, response_metadata={}, id='e8774344-fe2c-475a-87ca-046c88669318'),\n",
       " AIMessage(content='오늘 42세인 사람의 생년도를 계산하려면 현재 연도에서 42를 빼면 됩니다. 현재 연도를 확인한 후 계산해드리겠습니다. 잠시만 기다려 주세요.', additional_kwargs={'tool_calls': [{'id': 'call_zgbU43Tpc4dN7V6P1YoVTNOK', 'function': {'arguments': '{\"format_type\":\"date\"}', 'name': 'get_current_time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 602, 'total_tokens': 663, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C271MTxUPBKiT06aX3dnBoXbeb4cm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d5147596-9f96-4ded-aff4-8dd0bc43829a-0', tool_calls=[{'name': 'get_current_time', 'args': {'format_type': 'date'}, 'id': 'call_zgbU43Tpc4dN7V6P1YoVTNOK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 602, 'output_tokens': 61, 'total_tokens': 663, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='2025년 08월 08일', name='get_current_time', id='386aa3c9-9a97-454d-a3a3-e452966109a5', tool_call_id='call_zgbU43Tpc4dN7V6P1YoVTNOK'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wFcyi2iinMjCtoamce1Bo9up', 'function': {'arguments': '{\"birth_year\":1983}', 'name': 'calculate_age'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 684, 'total_tokens': 700, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C271OLCbhKMviHNve4YZ1X69glsBM', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3c98dc3d-908f-48f2-9831-abeadd8be1c3-0', tool_calls=[{'name': 'calculate_age', 'args': {'birth_year': 1983}, 'id': 'call_wFcyi2iinMjCtoamce1Bo9up', 'type': 'tool_call'}], usage_metadata={'input_tokens': 684, 'output_tokens': 16, 'total_tokens': 700, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='42세', name='calculate_age', id='a77384ad-1ff4-4dc0-ab10-60a2dbfe8388', tool_call_id='call_wFcyi2iinMjCtoamce1Bo9up'),\n",
       " AIMessage(content='오늘이 2025년 8월 8일이고, 42세인 사람의 생년은 1983년입니다. 생년월일은 1983년 8월 8일 이전에 태어났음을 의미합니다. 정확한 생일은 추가 정보가 필요합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 710, 'total_tokens': 775, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C271P15jHLF1oED3S2xNtdX7dbQnB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3e3b0af7-3408-4b93-ac3b-03c694410802-0', usage_metadata={'input_tokens': 710, 'output_tokens': 65, 'total_tokens': 775, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktds-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
