{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV-Z1B-Pa4L1"
   },
   "source": [
    "# ğŸ¤– LLM ì›ë¦¬ + OpenAI Chat Completion API í™œìš©\n",
    "\n",
    "---\n",
    "\n",
    "## 1. LLM ê¸°ë³¸ ê°œë…\n",
    "\n",
    "### ğŸ§  LLM(Large Language Model)ì˜ ìƒì„± ì›ë¦¬\n",
    "\n",
    "**LLMì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?**\n",
    "- **íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°**: ëŒ€í™”í˜• AIì˜ í•µì‹¬ ì•„í‚¤í…ì²˜\n",
    "- **í† í° ì˜ˆì¸¡**: ë‹¤ìŒì— ì˜¬ ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡\n",
    "- **í•™ìŠµ ë°©ì‹**: ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨\n",
    "\n",
    "**í•µì‹¬ í”„ë¡œì„¸ìŠ¤**\n",
    "1. **í† í°í™”**: í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë‹¨ìœ„(í† í°)ë¡œ ë¶„í• \n",
    "2. **í™•ë¥  ê³„ì‚°**: ê° í† í°ì´ ë‹¤ìŒì— ì˜¬ í™•ë¥  ê³„ì‚°\n",
    "3. **í† í° ìƒì„±**: í™•ë¥  ë¶„í¬ì— ë”°ë¼ í† í° ì„ íƒ\n",
    "4. **ë°˜ë³µ**: ì¢…ë£Œ ì¡°ê±´ê¹Œì§€ ê³¼ì • ë°˜ë³µ\n",
    "\n",
    "\n",
    "**íŠ¸ëœìŠ¤í¬ë¨¸**:\n",
    "- **ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°**: ì…ë ¥ê³¼ ì¶œë ¥ì„ ë™ì‹œì— ì²˜ë¦¬\n",
    "- **ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**: ì…ë ¥ì˜ ëª¨ë“  ë¶€ë¶„ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘\n",
    "\n",
    "\n",
    "<div style=\"text-align: left; font-size: 12px;\">\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/440px-Transformer%2C_full_architecture.png\"\n",
    "        alt=\"Illustrations for the Transformer and attention mechanism showing the full Transformer architecture\"\n",
    "        width=\"600\"\n",
    "        style=\"border: 0;\">\n",
    "</div>\n",
    "\n",
    "**Image Title:** Transformer Architecture Illustration  \n",
    "**Source:** [GitHub - DL Visuals](https://github.com/dvgodoy/dl-visuals/?tab=readme-ov-file)  \n",
    "**License:** [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)  \n",
    "**Author(s):** dvgodoy  \n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2. OpenAI API í•µì‹¬ ê°œë…\n",
    "\n",
    "### ğŸ”§ ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "**1. ë©”ì‹œì§€ í˜•ì‹**\n",
    "\n",
    "  ```python\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "      {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"}\n",
    "  ]\n",
    "  ```\n",
    "\n",
    "**2. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” ëª¨ë¸ (2025ë…„ ê¸°ì¤€)**\n",
    "\n",
    "  - **gpt-4.1**: ìµœê³  ì„±ëŠ¥, ë³µì¡í•œ ì‘ì—…ìš©\n",
    "  - **gpt-4.1-mini**: ë¹ ë¥¸ ì†ë„, ë¹„ìš© íš¨ìœ¨ì \n",
    "  - **gpt-4.1-nano**: ì´ˆê³ ì†, ìµœì € ë¹„ìš©\n",
    "  - **o3, o4-mini**: ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ìš©\n",
    "  - **gpt-4o**: ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤)\n",
    "\n",
    "**3. API ì‘ë‹µ êµ¬ì¡°**\n",
    "\n",
    "  ```json\n",
    "  {\n",
    "    \"id\": \"chatcmpl-...\",\n",
    "    \"object\": \"chat.completion\",\n",
    "    \"model\": \"gpt-4.1-mini\",\n",
    "    \"choices\": [\n",
    "      {\n",
    "        \"message\": {\n",
    "          \"role\": \"assistant\", \n",
    "          \"content\": \"ìƒì„±ëœ í…ìŠ¤íŠ¸\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"prompt_tokens\": 10,\n",
    "      \"completion_tokens\": 50,\n",
    "      \"total_tokens\": 60\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 3. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "\n",
    "### ğŸš€ uv í”„ë¡œì íŠ¸ ì„¤ì •\n",
    "- **í”„ë¡œì íŠ¸ ìƒì„±**: `uv init [í”„ë¡œì íŠ¸ëª…]`\n",
    "- **ê°€ìƒí™˜ê²½ ìƒì„±**: `uv venv --python=3.12`\n",
    "- **ê°€ìƒí™˜ê²½ í™œì„±í™”**: `.venv/bin/activate` (Unix) ë˜ëŠ” `.venv\\Scripts\\activate` (Windows)\n",
    "\n",
    "\n",
    "### ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "```bash\n",
    "# uv ì‚¬ìš© (ê¶Œì¥)\n",
    "uv add langchain langchain_openai python-dotenv ipykernel\n",
    "\n",
    "# pip ì‚¬ìš©\n",
    "pip install langchain langchain_openai python-dotenv ipykernel\n",
    "```\n",
    "\n",
    "### ğŸ” API í‚¤ ì„¤ì •\n",
    "```python\n",
    "# .env íŒŒì¼ ìƒì„±\n",
    "OPENAI_API_KEY=your_api_key_here\n",
    "\n",
    "# Pythonì—ì„œ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pythonì—ì„œ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 4. ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "\n",
    "### ğŸ’¡ ê°„ë‹¨í•œ ì§ˆì˜-ì‘ë‹µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì´ì¬ í•¨ìˆ˜ë€, íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œì˜ ë¬¶ìŒì´ì—ìš”. ë°˜ë³µí•´ì„œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì½”ë“œ ë¸”ë¡ì— ì´ë¦„ì„ ë¶™ì—¬ì„œ í•„ìš”í•  ë•Œë§ˆë‹¤ í˜¸ì¶œí•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì½”ë“œê°€ ë” ê¹”ë”í•˜ê³ , ì¬ì‚¬ìš©í•˜ê¸° ì‰¬ì›Œì ¸ìš”.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ë‘ ìˆ˜ë¥¼ ë”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ë³¼ê²Œìš”:\n",
      "\n",
      "```python\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "result = add(3, 5)\n",
      "print(result)  # 8\n",
      "```\n",
      "\n",
      "- `def` í‚¤ì›Œë“œë¡œ í•¨ìˆ˜ë¥¼ ì •ì˜í•´ìš”.\n",
      "- `add`ëŠ” í•¨ìˆ˜ ì´ë¦„ì´ê³ , `(a, b)`ëŠ” ë§¤ê°œë³€ìˆ˜(ì…ë ¥ê°’)ì˜ˆìš”.\n",
      "- `return`ì€ í•¨ìˆ˜ê°€ ê²°ê³¼ë¥¼ ëŒë ¤ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "í•„ìš”í•˜ë©´ ë” ê¶ê¸ˆí•œ ì  ë¬¼ì–´ë³´ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = OpenAI()\n",
    "\n",
    "# ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì¹œê·¼í•œ í”„ë¡œê·¸ë˜ë° íŠœí„°ì…ë‹ˆë‹¤. \"},\n",
    "        {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ í•¨ìˆ˜ë€ ë¬´ì—‡ì¸ê°€ìš”?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ ì½”ë“œ ì„¤ëª…ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì½”ë“œëŠ” **í€µì†ŒíŠ¸(Quick Sort)** ì•Œê³ ë¦¬ì¦˜ì„ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤. í€µì†ŒíŠ¸ëŠ” ëŒ€í‘œì ì¸ ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ë¡œ, ë¶„í•  ì •ë³µ(divide and conquer) ë°©ì‹ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ì½”ë“œë¥¼ í•œ ì¤„ì”© ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”.\n",
      "\n",
      "```python\n",
      "def quicksort(arr):\n",
      "```\n",
      "- `quicksort`ë¼ëŠ” ì´ë¦„ì˜ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
      "- ì…ë ¥ìœ¼ë¡œ ì •ë ¬í•˜ê³ ì í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ `arr`ë¥¼ ë°›ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "```\n",
      "- ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´ê°€ 1 ì´í•˜ì´ë©´, ì´ë¯¸ ì •ë ¬ëœ ìƒíƒœì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "- ì´ê²ƒì´ ì¬ê·€ í˜¸ì¶œì˜ ì¢…ë£Œ ì¡°ê±´ì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "    pivot = arr[len(arr) // 2]\n",
      "```\n",
      "- ë¦¬ìŠ¤íŠ¸ì˜ ì¤‘ê°„ ì¸ë±ìŠ¤ì— ìœ„ì¹˜í•œ ê°’ì„ `pivot`(ê¸°ì¤€ê°’)ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "- ì˜ˆë¥¼ ë“¤ì–´, ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ê°€ 5ë¼ë©´ `len(arr)//2`ëŠ” 2ê°€ ë˜ì–´ `arr[2]`ê°€ pivotì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "    left = [x for x in arr if x < pivot]\n",
      "```\n",
      "- ë¦¬ìŠ¤íŠ¸ì—ì„œ `pivot`ë³´ë‹¤ ì‘ì€ ê°’ë“¤ë§Œ ëª¨ì•„ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ `left`ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "```\n",
      "- ë¦¬ìŠ¤íŠ¸ì—ì„œ `pivot`ê³¼ ê°™ì€ ê°’ë“¤ë§Œ ëª¨ì•„ `middle` ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
      "- ì¤‘ë³µëœ ê°’ë“¤ë„ ëª¨ë‘ í¬í•¨ë©ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "    right = [x for x in arr if x > pivot]\n",
      "```\n",
      "- ë¦¬ìŠ¤íŠ¸ì—ì„œ `pivot`ë³´ë‹¤ í° ê°’ë“¤ë§Œ ëª¨ì•„ `right` ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "```\n",
      "- `left` ë¦¬ìŠ¤íŠ¸ì™€ `right` ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ê°ê° ì¬ê·€ì ìœ¼ë¡œ `quicksort` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì •ë ¬í•©ë‹ˆë‹¤.\n",
      "- ì •ë ¬ëœ `left`, `middle`, `right` ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ í•©ì³ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ìš”ì•½\n",
      "- ë¦¬ìŠ¤íŠ¸ê°€ 1ê°œ ì´í•˜ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "- ì¤‘ê°„ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„¸ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤: ì‘ì€ ê°’ë“¤, ê°™ì€ ê°’ë“¤, í° ê°’ë“¤.\n",
      "- ì‘ì€ ê°’ë“¤ê³¼ í° ê°’ë“¤ì— ëŒ€í•´ ì¬ê·€ì ìœ¼ë¡œ ì •ë ¬ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "- ì •ë ¬ëœ ì‘ì€ ê°’ë“¤ + ê°™ì€ ê°’ë“¤ + ì •ë ¬ëœ í° ê°’ë“¤ì„ í•©ì³ì„œ ìµœì¢… ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë°©ì‹ì€ í‰ê· ì ìœ¼ë¡œ ë§¤ìš° ë¹ ë¥¸ ì •ë ¬ ì†ë„ë¥¼ ë³´ì—¬ì£¼ë©°, ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì½”ë“œì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "def explain_code(code):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ì½”ë“œë¥¼ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"ì´ ì½”ë“œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”:\\n\\n{code}\"}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "code = \"\"\"\n",
    "def quicksort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr[len(arr) // 2]\n",
    "    left = [x for x in arr if x < pivot]\n",
    "    middle = [x for x in arr if x == pivot]\n",
    "    right = [x for x in arr if x > pivot]\n",
    "    return quicksort(left) + middle + quicksort(right)\n",
    "\"\"\"\n",
    "\n",
    "explanation = explain_code(code)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_PyJkbpa4L5"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. êµ¬ì¡°í™”ëœ ì¶œë ¥\n",
    "\n",
    "### ğŸ“Š JSON ìŠ¤í‚¤ë§ˆ í™œìš©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"brand\": \"ì‚¼ì„±\",\n",
      "  \"model\": \"ê°¤ëŸ­ì‹œ S24 Ultra\",\n",
      "  \"storage\": \"512GB\",\n",
      "  \"color\": \"í‹°íƒ€ëŠ„ ê·¸ë ˆì´\",\n",
      "  \"price\": 1698400,\n",
      "  \"category\": \"ìŠ¤ë§ˆíŠ¸í°\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì˜ˆì œ\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"ìƒí’ˆ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"ì‚¼ì„± ê°¤ëŸ­ì‹œ S24 Ultra 512GB (í‹°íƒ€ëŠ„ ê·¸ë ˆì´) - 1,698,400ì›\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"product_schema\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"brand\": {\"type\": \"string\", \"description\": \"ë¸Œëœë“œëª…\"},\n",
    "                    \"model\": {\"type\": \"string\", \"description\": \"ëª¨ë¸ëª…\"},\n",
    "                    \"storage\": {\"type\": \"string\", \"description\": \"ì €ì¥ìš©ëŸ‰\"},\n",
    "                    \"color\": {\"type\": \"string\", \"description\": \"ìƒ‰ìƒ\"},\n",
    "                    \"price\": {\"type\": \"number\", \"description\": \"ê°€ê²©(ì›)\"},\n",
    "                    \"category\": {\"type\": \"string\", \"description\": \"ì œí’ˆ ì¹´í…Œê³ ë¦¬\"}\n",
    "                },\n",
    "                \"required\": [\"brand\", \"model\", \"price\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# JSON íŒŒì‹±\n",
    "product_data = json.loads(response.choices[0].message.content)\n",
    "print(json.dumps(product_data, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ë§¤ê°œë³€ìˆ˜ ìµœì í™”\n",
    "\n",
    "### âš™ï¸ í•µì‹¬ ë§¤ê°œë³€ìˆ˜ ê°€ì´ë“œ\n",
    "\n",
    "| ë§¤ê°œë³€ìˆ˜ | ë²”ìœ„ | ìš©ë„ | ì¶”ì²œê°’ |\n",
    "|---------|------|------|--------|\n",
    "| `temperature` | 0~2 | ì°½ì˜ì„± ì¡°ì ˆ | 0.3 (ì •í™•ì„±), 0.7 (ê· í˜•), 1.2 (ì°½ì˜ì„±) |\n",
    "| `top_p` | 0~1 | ì‘ë‹µ ë‹¤ì–‘ì„± | 0.9 (ê¸°ë³¸), 0.3 (ì§‘ì¤‘ì ) |\n",
    "| `max_tokens` | 1~8192+ | ìµœëŒ€ ê¸¸ì´ | ì‘ì—…ì— ë”°ë¼ ì¡°ì ˆ |\n",
    "| `frequency_penalty` | -2~2 | ë°˜ë³µ ì–µì œ | 0.3~0.6 |\n",
    "| `presence_penalty` | -2~2 | ìƒˆ ì£¼ì œ ë„ì… | 0.3~0.6 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¨ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì •\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ì •í™•í•œ ì •ë³´ ì œê³µ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬(dictionary)ëŠ” í‚¤(key)ì™€ ê°’(value)ì˜ ìŒìœ¼ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ìë£Œêµ¬ì¡°ì…ë‹ˆë‹¤. ë”•ì…”ë„ˆë¦¬ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë©”ì„œë“œë“¤ì„ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. `dict.get(key, default=None)`\n",
      "- **ì„¤ëª…**: ë”•ì…”ë„ˆë¦¬ì—ì„œ `key`ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ë§Œì•½ `key`ê°€ ì—†ìœ¼ë©´ `default` ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. `default`ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ `None`ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "- **ì˜ˆì‹œ**:\n",
      "  ```python\n",
      "  d = {'a': 1, 'b': 2}\n",
      "  print(d.get('a'))       # ì¶œë ¥: 1\n",
      "  print(d.get('c', 0))    # ì¶œë ¥: 0\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### 2. `dict.keys()`\n",
      "- **ì„¤ëª…**: ë”•ì…”ë„ˆë¦¬ì˜ ëª¨ë“  í‚¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ë°˜í™˜ê°’ì€ `dict_keys` ê°ì²´ë¡œ, ë¦¬ìŠ¤íŠ¸ì²˜ëŸ¼ ë°˜ë³µ(iterate)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ì˜ˆì‹œ**:\n",
      "  ```python\n",
      "  d = {'a': 1, 'b': 2}\n",
      "  print(d.keys())         # ì¶œë ¥: dict_keys(['a', 'b'])\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### 3. `dict.values()`\n",
      "- **ì„¤ëª…**: ë”•ì…”ë„ˆë¦¬ì˜ ëª¨ë“  ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ë°˜í™˜ê°’ì€ `dict_values` ê°ì²´ì…ë‹ˆë‹¤.\n",
      "- **ì˜ˆì‹œ**:\n",
      "  ```python\n",
      "  d = {'a': 1, 'b': 2}\n",
      "  print(d.values())       # ì¶œë ¥: dict_values([1, 2])\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### 4. `dict.items()`\n",
      "- **ì„¤ëª…**: ë”•ì…”ë„ˆë¦¬ì˜ ëª¨ë“  (í‚¤, ê°’) ìŒì„ íŠœí”Œ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. ë°˜í™˜ê°’ì€ `dict_items` ê°ì²´ì…ë‹ˆë‹¤.\n",
      "- **ì˜ˆì‹œ**:\n",
      "  ```python\n",
      "  d = {'a': 1, 'b': 2}\n",
      "  print(d.items())        # ì¶œë ¥: dict_items([('a', 1), ('b', 2)])\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### 5. `dict.update(other_dict)`\n",
      "- **ì„¤ëª…**: ë‹¤ë¥¸ ë”•ì…”ë„ˆë¦¬ë‚˜ í‚¤-ê°’ ìŒì„ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€í•˜ê±°ë‚˜ ê¸°ì¡´ í‚¤ì˜ ê°’ì„ ê°±ì‹ í•©ë‹ˆë‹¤.\n",
      "- **ì˜ˆì‹œ\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ ë©”ì„œë“œë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=0.2,  # ë‚®ì€ ì°½ì˜ì„±\n",
    "    top_p=0.3,        # ì§‘ì¤‘ì  ì‘ë‹µ\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ì°½ì˜ì  ê¸€ì“°ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì°½ë¬¸ ë„ˆë¨¸ë¡œ ì§€êµ¬ê°€ ì²œì²œíˆ ëˆë‹¤. ê²€í‘¸ë¥¸ í–‰ì„± ìœ„ë¡œ ì–‡ì€ êµ¬ë¦„ì´ í˜ëŸ¬ê°€ê³ , ë‚¨ë°˜êµ¬ì—” ì€ì€í•œ ì˜¤ë¡œë¼ê°€ í¼ì³ì§„ë‹¤. ê¹€ìˆ˜ì§„ì€ ì—¬ëŠ ë•Œì²˜ëŸ¼ ìš°ì£¼ ì •ê±°ì¥ 3ë²ˆ ëª¨ë“ˆì˜ ì‘ì€ ì¡°ë¦¬ì‹¤ì—ì„œ ë– ë‹¤ë‹ˆëŠ” ì•„ì¹¨ ì‹ì‚¬ë¥¼ ì¤€ë¹„í•œë‹¤. íŠœë¸Œì—ì„œ ì§œë‚´ëŠ” ì»¤í”¼ì™€ ë°”ë‹ë¼ ë§› ì—ë„ˆì§€ë°”ëŠ” ë²Œì¨ ìµìˆ™í•˜ë‹¤.\n",
      "\n",
      "â€œêµ¿ëª¨ë‹, ìˆ˜ì§„.â€  \n",
      "ë™ë£Œì¸ ì•Œë ‰ìŠ¤ê°€ ìº¡ìŠí˜• ì¹¨ë‚­ì„ ë‚˜ì™€ ë¯¸ì†Œ ì§“ëŠ”ë‹¤. ê¸´ ë¨¸ë¦¬ê°€ ë‘¥ë‘¥ ë– ë‹¤ë‹Œë‹¤. ì„œë¡œ ì†ì§“ìœ¼ë¡œ ì¸ì‚¬í•˜ë©° ë°ì´í„° íŒ¨ë“œë¥¼ ì§‘ëŠ”ë‹¤. ì˜¤ëŠ˜ì€ íƒœì–‘ í‘ì  ê´€ì¸¡ê³¼ ì‹ë¬¼ ì„±ì¥ ì‹¤í—˜ ì¼ì •ì´ ì¡í˜€ ìˆë‹¤.\n",
      "\n",
      "ìˆ˜ì§„ì€ ì‹¤í—˜ ëª¨ë“ˆë¡œ ì´ë™í•œë‹¤. ë‘¥ë‘¥ ë– ì„œ ë²½ì„ ë°€ê³ , ì†ì¡ì´ë¥¼ ë¶™ì¡ëŠ”ë‹¤. ë¬´ì¤‘ë ¥ ìƒíƒœì˜ ëª¸ì´ ì•„ì§ë„ ì‹ ê¸°í•˜ë‹¤. ì‹¤í—˜ëŒ€ ìœ„ì—ëŠ” ì‘ì€ í† ë§ˆí†  í™”ë¶„ì´ ìë¼ê³  ìˆë‹¤. â€˜ì§€êµ¬ì˜ ì•„íŒŒíŠ¸ ë² ë€ë‹¤ê°€ ì•„ë‹ˆë¼ë‹ˆ, ë„ˆë„ ì°¸ ëŒ€ê²¬í•˜ë‹¤.â€™ ì†ìœ¼ë¡œ ì¤‘ì–¼ê±°ë¦¬ë©° ìì‚¬ê·€ì— ìƒê¸´ ì´ìŠ¬ì„ ë‹¦ì•„ë‚¸ë‹¤.\n",
      "\n",
      "ì•Œë ‰ìŠ¤ì™€ í•¨ê»˜ ë§ì›ê²½ ì•ì— ì•‰ëŠ”ë‹¤. ì°½ë°–ì—ëŠ” í–‡ë¹›ì´ ê°•ë ¬í•˜ê²Œ ìŸì•„ì§€ê³ , ë©€ë¦¬ ê±°ëŒ€í•œ í‘ì ë“¤ì´ ë³´ì¸ë‹¤. ë‘˜ì€ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ê³  ì§€ìƒì— ë³´ê³ ì„œë¥¼ ë³´ë‚¸ë‹¤.\n",
      "\n",
      "ì‹œê°„ì´ íë¥¸ë‹¤. ìˆ˜ì§„ì€ ì •ê±°ì¥ ë‚´ ìì „ê±° í˜ë‹¬ì„ ë°Ÿìœ¼ë©° ìš´ë™ì„ í•œë‹¤. ë•€ì´ ì‘ì€ ë°©ìš¸ ë˜ì–´ ì²œì²œíˆ ë‚ ì•„ê°„ë‹¤. ì¹œêµ¬ë“¤ê³¼ ì˜ìƒí†µí™”ë„ í•˜ê³ , ì¢‹ì•„í•˜ëŠ” ìŒì•…ë„ ë“£ëŠ”ë‹¤.\n",
      "\n",
      "ì €ë…ì´ ë˜ë©´ ìŠ¹ë¬´ì› ëª¨ë‘ê°€ ëª¨ì—¬ ì°½ë°–ìœ¼ë¡œ í‘¸ë¥¸ ì§€êµ¬ë¥¼ ë°”ë¼ë³¸ë‹¤. ë§ì—†ì´, ê·¸ëƒ¥ ì˜¤ë˜ë„ë¡ ë°”ë¼ë³¸ë‹¤.\n",
      "\n",
      "ì–´ì©Œë©´ ì˜¤ëŠ˜ í•˜ë£¨ë„ íŠ¹ë³„í•˜ì§€ ì•Šì§€ë§Œ, ê·¸ë˜ë„ ìš°ì£¼ë¼ëŠ” ì´ ê³ ìš”í•˜ê³  ê´‘í™œí•œ ê³³ì—ì„œ í•˜ë£¨ë¥¼ ë³´ëƒˆë‹¤ëŠ” ì‚¬ì‹¤ë§Œìœ¼ë¡œ ê°€ìŠ´ í•œì¼ ì´ ë”°ëœ»í•´ì§„ë‹¤.\n",
      "\n",
      "ìˆ˜ì§„ì€ ì ìë¦¬ì— ë“¤ê¸° ì „ ì¼ê¸°ë¥¼ ì“´ë‹¤.\n",
      "\n",
      "â€˜ì§€êµ¬ëŠ” ì—¬ì „íˆ ì•„ë¦„ë‹µê³  ê·¸ë¦½ê³ â€¦ ë‚˜ëŠ” ì´ê³³ì—ì„œ ë˜ í•˜ë£¨ë¥¼ ì‚´ì•„ëƒˆë‹¤.â€™\n",
      "\n",
      "ì°½ë¬¸ ë„ˆë¨¸ ë°¤í•˜ëŠ˜ì— ë³„ë“¤ì´ ë°˜ì§ì¸ë‹¤â€”ì •ê±°ì¥ì€ ë˜ í•œ ë²ˆ ì§€êµ¬ë¥¼ ëˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ìš°ì£¼ ì •ê±°ì¥ì—ì„œì˜ í•˜ë£¨ë¥¼ ì†Œì„¤ë¡œ ì¨ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=1.1,  # ë†’ì€ ì°½ì˜ì„±\n",
    "    top_p=0.9,        # ë‹¤ì–‘í•œ í‘œí˜„\n",
    "    max_tokens=1000,\n",
    "    frequency_penalty=0.5  # ë°˜ë³µ ë°©ì§€\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ì½”ë“œ ìƒì„±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ì›¹ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ Python í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=0.4,  # ì•½ê°„ì˜ ì°½ì˜ì„±\n",
    "    max_tokens=800\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ì‹¤ìŠµ ë¬¸ì œ\n",
    "\n",
    "**ë¬¸ì œ 1: ì–¸ì–´ ë²ˆì—­ê¸° ë§Œë“¤ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(text, target_language):\n",
    "    # TODO: OpenAI APIë¥¼ ì‚¬ìš©í•´ì„œ ë²ˆì—­ í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "    pass\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = translator(\"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!\", \"ì˜ì–´\")\n",
    "print(result)  # ì˜ˆìƒ ì¶œë ¥: Hello, the weather is nice today!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ë¬¸ì œ 2: ê°ì • ë¶„ì„ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    # TODO: í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”\n",
    "    # ë°˜í™˜ í˜•íƒœ: {\"sentiment\": \"positive/negative/neutral\", \"confidence\": 0.85}\n",
    "    # íŒíŠ¸: client.chat.completions.create()ë¥¼ ì‚¬ìš©í•˜ê³  response_formatìœ¼ë¡œ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ì„¸ìš”\n",
    "    pass\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = analyze_sentiment(\"ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.\")\n",
    "print(result)\n",
    "# ì˜ˆìƒ ì¶œë ¥: {'sentiment': 'positive', 'confidence': 0.95}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— ìœ ìš©í•œ ë§í¬\n",
    "- [OpenAI API ê³µì‹ ë¬¸ì„œ](https://platform.openai.com/docs)\n",
    "- [OpenAI í† í° ê³„ì‚°ê¸°](https://platform.openai.com/tokenizer)\n",
    "- [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì‹¤ìŠµ 7-1 ë‹µì•ˆ\n",
    "\n",
    "def translator(text, target_language):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following text to {target_language}: {text}\"}\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=600\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = translator(\"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!\", \"ì˜ì–´\")\n",
    "print(result)  # ì˜ˆìƒ ì¶œë ¥: Hello, the weather is nice today!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì‹¤ìŠµ 7-2 ë‹µì•ˆ\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # TODO: í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”\n",
    "    # ë°˜í™˜ í˜•íƒœ: {\"sentiment\": \"positive/negative/neutral\", \"confidence\": 0.85}\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Analyze the sentiment of this text: {text}\"}\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"sentiment_schema\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"sentiment\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"positive\", \"negative\", \"neutral\"],\n",
    "                            \"description\": \"ê°ì • ë¶„ë¥˜\"\n",
    "                        },\n",
    "                        \"confidence\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"minimum\": 0,\n",
    "                            \"maximum\": 1,\n",
    "                            \"description\": \"ë¶„ì„ ì‹ ë¢°ë„ (0~1)\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"sentiment\", \"confidence\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = analyze_sentiment(\"ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ktds-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
