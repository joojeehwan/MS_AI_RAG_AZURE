{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f191d1cf",
   "metadata": {},
   "source": [
    "#  RAG 체인 구성\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ec21",
   "metadata": {},
   "source": [
    "## RAG란 무엇인가?\n",
    "\n",
    "### 🎯 핵심 개념\n",
    "**Retrieval Augmented Generation (RAG)** 는 대규모 언어 모델(LLM)에 외부 지식을 연결하여 더 정확하고 최신의 정보를 제공하는 AI 프레임워크입니다.\n",
    "\n",
    "### 🔍 RAG의 작동 원리\n",
    "```\n",
    "사용자 질문 → 관련 문서 검색 → 컨텍스트와 함께 LLM에 전달 → 답변 생성\n",
    "```\n",
    "\n",
    "### 📊 RAG vs 일반 LLM 비교\n",
    "| 구분 | 일반 LLM | RAG |\n",
    "|------|----------|-----|\n",
    "| 정보 소스 | 사전 훈련 데이터만 | 외부 지식베이스 + 사전 훈련 데이터 |\n",
    "| 최신성 | 훈련 시점까지 | 실시간 업데이트 가능 |\n",
    "| 정확성 | 환각(hallucination) 가능성 | 검증된 문서 기반 답변 |\n",
    "| 사용 사례 | 일반적인 질문 답변 | 특정 도메인의 전문적 답변 |\n",
    "\n",
    "---\n",
    "\n",
    "## 환경 설정\n",
    "\n",
    "### 🛠️ 필수 라이브러리 설치\n",
    "\n",
    "```bash\n",
    "# 기본 LangChain 패키지\n",
    "pip install langchain langchain-community langchain-core\n",
    "\n",
    "# 텍스트 분할\n",
    "pip install langchain-text-splitters\n",
    "\n",
    "# 임베딩 모델\n",
    "pip install langchain-openai langchain-huggingface\n",
    "\n",
    "# 벡터 저장소\n",
    "pip install langchain-chroma\n",
    "\n",
    "# 문서 처리\n",
    "pip install pypdf python-dotenv\n",
    "\n",
    "# 웹 스크래핑\n",
    "pip install beautifulsoup4\n",
    "\n",
    "# 토크나이저\n",
    "pip install tiktoken transformers sentence-transformers\n",
    "\n",
    "# 실험적 기능 (SemanticChunker)\n",
    "pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be5eb8",
   "metadata": {},
   "source": [
    "### 🔑 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829d8712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .env 파일 생성\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키 설정 (필요시)\n",
    "# OPENAI_API_KEY=your_openai_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5989430",
   "metadata": {},
   "source": [
    "### 📋 기본 라이브러리 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa02fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c23a89",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 문서 로더 (Document Loaders)\n",
    "\n",
    "### 🎯 문서 로더란?\n",
    "**Document Loader**는 다양한 소스에서 문서를 로드하여 LangChain의 `Document` 객체로 변환하는 도구입니다.\n",
    "\n",
    "### 📄 Document 객체 구조\n",
    "```python\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Document 객체의 기본 구조\n",
    "document = Document(\n",
    "    page_content=\"문서의 텍스트 내용\",\n",
    "    metadata={\n",
    "        \"source\": \"문서 출처\",\n",
    "        \"page\": 1,\n",
    "        \"title\": \"문서 제목\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### 📄 문서 로더의 종류\n",
    "- PDF 파일 로더\n",
    "- 웹 페이지 로더 \n",
    "- CSV 데이터 로더\n",
    "- 디렉토리 로더\n",
    "- HTML 데이터 로더\n",
    "- JSON 데이터 로더\n",
    "- Markdown 데이터 로더\n",
    "- Microsoft Office 데이터 로더\n",
    "\n",
    "\n",
    "### 1. 🌐 웹 문서 로더 (WebBaseLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c00ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 2\n",
      "첫 번째 문서 메타데이터: {'source': 'https://python.langchain.com/docs/tutorials/rag/', 'title': 'Build a Retrieval Augmented Generation (RAG) App: Part 1 | 🦜️🔗 LangChain', 'description': 'One of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "# 기본 웹 문서 로드\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://python.langchain.com/docs/tutorials/rag/\",\n",
    "        \"https://js.langchain.com/docs/tutorials/rag/\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "web_docs = web_loader.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs)}\")\n",
    "print(f\"첫 번째 문서 메타데이터: {web_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eebd4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Build a Retrieval Augmented Generation (RAG) App: Part 1 | 🦜️🔗 LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild a Retrieval Augmented Generation (RAG) App: Part 1On this pageBuild a Retrieval Augmented Generation (RAG) App: Part 1\n",
      "One of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.\n",
      "This is a multi-part tutorial:\n",
      "\n",
      "Part 1 (this guide) introduces RAG and walks through a minimal implementation.\n",
      "Part 2 extends the implementation to accommodate conversation-style interactions and multi-step retrieval processes.\n",
      "\n",
      "This tutorial will show how to build a simple Q&A application\n",
      "over a text data source. Along the way we’ll go over a typical Q&A\n",
      "architecture and highlight additional resources for more advanced Q&A techniques. We’ll also see\n",
      "how LangSmith can help us trace and understand our application.\n",
      "LangSmith will become increasingly helpful as our application grows in\n",
      "complexity.\n",
      "If you're already familiar with basic retrieval, you might also be interested in\n",
      "this high-level overview of different retrieval techniques.\n",
      "Note: Here we focus on Q&A for unstructured data. If you are interested for RAG over structured data, check out our tutorial on doing question/answering over SQL data.\n",
      "Overview​\n",
      "A typical RAG application has two main components:\n",
      "Indexing: a pipeline for ingesting data from a source and indexing it. This usually happens offline.\n",
      "Retrieval and generation: the actual RAG chain, which takes the user query at run time and retrieves the relevant data from the index, then passes that to the model.\n",
      "Note: the indexing portion of this tutorial will largely follow the semantic search tutorial.\n",
      "The most common full sequence from raw data to answer looks like:\n",
      "Indexing​\n",
      "\n",
      "Load: First we need to load our data. This is done with Document Loaders.\n",
      "Split: Text splitters break large Documents into smaller chunks. This is useful both for indexing data and passing it into a model, as large chunks are harder to search over and won't fit in a model's finite context window.\n",
      "Store: We need somewhere to store and index our splits, so that they can be searched over later. This is often done using a VectorStore and Embeddings model.\n",
      "\n",
      "\n",
      "Retrieval and generation​\n",
      "\n",
      "Retrieve: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
      "Generate: A ChatModel / LLM produces an answer using a prompt that includes both the question with the retrieved data\n",
      "\n",
      "\n",
      "Once we've indexed our data, we will use LangGraph as our orchestration framework to implement the retrieval and generation steps.\n",
      "Setup​\n",
      "Jupyter Notebook​\n",
      "This and other tutorials are perhaps most conveniently run in a Jupyter notebooks. Going through guides in an interactive environment is a great way to better understand them. See here for instructions on how to install.\n",
      "Installation​\n",
      "This tutorial requires these langchain dependencies:\n",
      "\n",
      "PipConda%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraphconda install langchain-text-splitters langchain-community langgraph -c conda-forge\n",
      "For more details, see our Installation guide.\n",
      "LangSmith​\n",
      "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\n",
      "As these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\n",
      "The best way to do this is with LangSmith.\n",
      "After you sign up at the link above, make sure to set your environment variables to start logging traces:\n",
      "export LANGSMITH_TRACING=\"true\"export LANGSMITH_API_KEY=\"...\"\n",
      "Or, if in a notebook, you can set them with:\n",
      "import getpassimport osos.environ[\"LANGSMITH_TRACING\"] = \"true\"os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
      "Components​\n",
      "We will need to select three components from LangChain's suite of integrations.\n",
      "\n",
      "Select chat model:Google Gemini▾OpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelllm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
      "\n",
      "Select embeddings model:OpenAI▾OpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get(\"OPENAI_API_KEY\"):  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
      "\n",
      "Select vector store:In-memory▾In-memoryAstraDBChromaFAISSMilvusMongoDBPGVectorPGVectorStorePineconeQdrantpip install -qU langchain-corefrom langchain_core.vectorstores import InMemoryVectorStorevector_store = InMemoryVectorStore(embeddings)\n",
      "Preview​\n",
      "In this guide we’ll build an app that answers questions about the website's content. The specific website we will use is the LLM Powered Autonomous\n",
      "Agents blog post\n",
      "by Lilian Weng, which allows us to ask questions about the contents of\n",
      "the post.\n",
      "We can create a simple indexing pipeline and RAG chain to do this in ~50\n",
      "lines of code.\n",
      "import bs4from langchain import hubfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_core.documents import Documentfrom langchain_text_splitters import RecursiveCharacterTextSplitterfrom langgraph.graph import START, StateGraphfrom typing_extensions import List, TypedDict# Load and chunk contents of the blogloader = WebBaseLoader(    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),    bs_kwargs=dict(        parse_only=bs4.SoupStrainer(            class_=(\"post-content\", \"post-title\", \"post-header\")        )    ),)docs = loader.load()text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)all_splits = text_splitter.split_documents(docs)# Index chunks_ = vector_store.add_documents(documents=all_splits)# Define prompt for question-answering# N.B. for non-US LangSmith endpoints, you may need to specify# api_url=\"https://api.smith.langchain.com\" in hub.pull.prompt = hub.pull(\"rlm/rag-prompt\")# Define state for applicationclass State(TypedDict):    question: str    context: List[Document]    answer: str# Define application stepsdef retrieve(state: State):    retrieved_docs = vector_store.similarity_search(state[\"question\"])    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}# Compile application and testgraph_builder = StateGraph(State).add_sequence([retrieve, generate])graph_builder.add_edge(START, \"retrieve\")graph = graph_builder.compile()API Reference:Document | StateGraph\n",
      "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})print(response[\"answer\"])\n",
      "Task Decomposition is the process of breaking down a complicated task into smaller, manageable steps to facilitate easier execution and understanding. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) guide models to think step-by-step, allowing them to explore multiple reasoning possibilities. This method enhances performance on complex tasks and provides insight into the model's thinking process.\n",
      "Check out the LangSmith\n",
      "trace.\n",
      "Detailed walkthrough​\n",
      "Let’s go through the above code step-by-step to really understand what’s\n",
      "going on.\n",
      "1. Indexing​\n",
      "noteThis section is an abbreviated version of the content in the semantic search tutorial.\n",
      "If you're comfortable with document loaders, embeddings, and vector stores,\n",
      "feel free to skip to the next section on retrieval and generation.\n",
      "Loading documents​\n",
      "We need to first load the blog post contents. We can use\n",
      "DocumentLoaders\n",
      "for this, which are objects that load in data from a source and return a\n",
      "list of\n",
      "Document\n",
      "objects.\n",
      "In this case we’ll use the\n",
      "WebBaseLoader,\n",
      "which uses urllib to load HTML from web URLs and BeautifulSoup to\n",
      "parse it to text. We can customize the HTML -> text parsing by passing\n",
      "in parameters into the BeautifulSoup parser via bs_kwargs (see\n",
      "BeautifulSoup\n",
      "docs).\n",
      "In this case only HTML tags with class “post-content”, “post-title”, or\n",
      "“post-header” are relevant, so we’ll remove all others.\n",
      "import bs4from langchain_community.document_loaders import WebBaseLoader# Only keep post title, headers, and content from the full HTML.bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))loader = WebBaseLoader(    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),    bs_kwargs={\"parse_only\": bs4_strainer},)docs = loader.load()assert len(docs) == 1print(f\"Total characters: {len(docs[0].page_content)}\")\n",
      "Total characters: 43131\n",
      "print(docs[0].page_content[:500])\n",
      "      LLM Powered Autonomous Agents    Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian WengBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.Agent System Overview#In\n",
      "Go deeper​\n",
      "DocumentLoader: Object that loads data from a source as list of Documents.\n",
      "\n",
      "Docs:\n",
      "Detailed documentation on how to use DocumentLoaders.\n",
      "Integrations: 160+\n",
      "integrations to choose from.\n",
      "Interface:\n",
      "API reference for the base interface.\n",
      "\n",
      "Splitting documents​\n",
      "Our loaded document is over 42k characters which is too long to fit\n",
      "into the context window of many models. Even for those models that could\n",
      "fit the full post in their context window, models can struggle to find\n",
      "information in very long inputs.\n",
      "To handle this we’ll split the Document into chunks for embedding and\n",
      "vector storage. This should help us retrieve only the most relevant parts\n",
      "of the blog post at run time.\n",
      "As in the semantic search tutorial, we use a\n",
      "RecursiveCharacterTextSplitter,\n",
      "which will recursively split the document using common separators like\n",
      "new lines until each chunk is the appropriate size. This is the\n",
      "recommended text splitter for generic text use cases.\n",
      "from langchain_text_splitters import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(    chunk_size=1000,  # chunk size (characters)    chunk_overlap=200,  # chunk overlap (characters)    add_start_index=True,  # track index in original document)all_splits = text_splitter.split_documents(docs)print(f\"Split blog post into {len(all_splits)} sub-documents.\")\n",
      "Split blog post into 66 sub-documents.\n",
      "Go deeper​\n",
      "TextSplitter: Object that splits a list of Documents into smaller\n",
      "chunks. Subclass of DocumentTransformers.\n",
      "\n",
      "Learn more about splitting text using different methods by reading the how-to docs\n",
      "Code (py or js)\n",
      "Scientific papers\n",
      "Interface: API reference for the base interface.\n",
      "\n",
      "DocumentTransformer: Object that performs a transformation on a list\n",
      "of Document objects.\n",
      "\n",
      "Docs: Detailed documentation on how to use DocumentTransformers\n",
      "Integrations\n",
      "Interface: API reference for the base interface.\n",
      "\n",
      "Storing documents​\n",
      "Now we need to index our 66 text chunks so that we can search over them\n",
      "at runtime. Following the semantic search tutorial,\n",
      "our approach is to embed the contents of each document split and insert these embeddings\n",
      "into a vector store. Given an input query, we can then use\n",
      "vector search to retrieve relevant documents.\n",
      "We can embed and store all of our document splits in a single command\n",
      "using the vector store and embeddings model selected at the start of the tutorial.\n",
      "document_ids = vector_store.add_documents(documents=all_splits)print(document_ids[:3])\n",
      "['07c18af6-ad58-479a-bfb1-d508033f9c64', '9000bf8e-1993-446f-8d4d-f4e507ba4b8f', 'ba3b5d14-bed9-4f5f-88be-44c88aedc2e6']\n",
      "Go deeper​\n",
      "Embeddings: Wrapper around a text embedding model, used for converting\n",
      "text to embeddings.\n",
      "\n",
      "Docs: Detailed documentation on how to use embeddings.\n",
      "Integrations: 30+ integrations to choose from.\n",
      "Interface: API reference for the base interface.\n",
      "\n",
      "VectorStore: Wrapper around a vector database, used for storing and\n",
      "querying embeddings.\n",
      "\n",
      "Docs: Detailed documentation on how to use vector stores.\n",
      "Integrations: 40+ integrations to choose from.\n",
      "Interface: API reference for the base interface.\n",
      "\n",
      "This completes the Indexing portion of the pipeline. At this point\n",
      "we have a query-able vector store containing the chunked contents of our\n",
      "blog post. Given a user question, we should ideally be able to return\n",
      "the snippets of the blog post that answer the question.\n",
      "2. Retrieval and Generation​\n",
      "Now let’s write the actual application logic. We want to create a simple\n",
      "application that takes a user question, searches for documents relevant\n",
      "to that question, passes the retrieved documents and initial question to\n",
      "a model, and returns an answer.\n",
      "For generation, we will use the chat model selected at the start of the tutorial.\n",
      "We’ll use a prompt for RAG that is checked into the LangChain prompt hub\n",
      "(here).\n",
      "from langchain import hub# N.B. for non-US LangSmith endpoints, you may need to specify# api_url=\"https://api.smith.langchain.com\" in hub.pull.prompt = hub.pull(\"rlm/rag-prompt\")example_messages = prompt.invoke(    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}).to_messages()assert len(example_messages) == 1print(example_messages[0].content)\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.Question: (question goes here) Context: (context goes here) Answer:\n",
      "We'll use LangGraph to tie together the retrieval and generation steps into a single application. This will bring a number of benefits:\n",
      "\n",
      "We can define our application logic once and automatically support multiple invocation modes, including streaming, async, and batched calls.\n",
      "We get streamlined deployments via LangGraph Platform.\n",
      "LangSmith will automatically trace the steps of our application together.\n",
      "We can easily add key features to our application, including persistence and human-in-the-loop approval, with minimal code changes.\n",
      "\n",
      "To use LangGraph, we need to define three things:\n",
      "\n",
      "The state of our application;\n",
      "The nodes of our application (i.e., application steps);\n",
      "The \"control flow\" of our application (e.g., the ordering of the steps).\n",
      "\n",
      "State:​\n",
      "The state of our application controls what data is input to the application, transferred between steps, and output by the application. It is typically a TypedDict, but can also be a Pydantic BaseModel.\n",
      "For a simple RAG application, we can just keep track of the input question, retrieved context, and generated answer:\n",
      "from langchain_core.documents import Documentfrom typing_extensions import List, TypedDictclass State(TypedDict):    question: str    context: List[Document]    answer: strAPI Reference:Document\n",
      "Nodes (application steps)​\n",
      "Let's start with a simple sequence of two steps: retrieval and generation.\n",
      "def retrieve(state: State):    retrieved_docs = vector_store.similarity_search(state[\"question\"])    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}\n",
      "Our retrieval step simply runs a similarity search using the input question, and the generation step formats the retrieved context and original question into a prompt for the chat model.\n",
      "Control flow​\n",
      "Finally, we compile our application into a single graph object. In this case, we are just connecting the retrieval and generation steps into a single sequence.\n",
      "from langgraph.graph import START, StateGraphgraph_builder = StateGraph(State).add_sequence([retrieve, generate])graph_builder.add_edge(START, \"retrieve\")graph = graph_builder.compile()API Reference:StateGraph\n",
      "LangGraph also comes with built-in utilities for visualizing the control flow of your application:\n",
      "from IPython.display import Image, displaydisplay(Image(graph.get_graph().draw_mermaid_png()))\n",
      "\n",
      "Do I need to use LangGraph?LangGraph is not required to build a RAG application. Indeed, we can implement the same application logic through invocations of the individual components:question = \"...\"retrieved_docs = vector_store.similarity_search(question)docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)prompt = prompt.invoke({\"question\": question, \"context\": docs_content})answer = llm.invoke(prompt)The benefits of LangGraph include:\n",
      "Support for multiple invocation modes: this logic would need to be rewritten if we wanted to stream output tokens, or stream the results of individual steps;\n",
      "Automatic support for tracing via LangSmith and deployments via LangGraph Platform;\n",
      "Support for persistence, human-in-the-loop, and other features.\n",
      "Many use-cases demand RAG in a conversational experience, such that a user can receive context-informed answers via a stateful conversation. As we will see in Part 2 of the tutorial, LangGraph's management and persistence of state simplifies these applications enormously.\n",
      "Usage​\n",
      "Let's test our application! LangGraph supports multiple invocation modes, including sync, async, and streaming.\n",
      "Invoke:\n",
      "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})print(f\"Context: {result['context']}\\n\\n\")print(f\"Answer: {result['answer']}\")\n",
      "Context: [Document(id='a42dc78b-8f76-472a-9e25-180508af74f3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='c0e45887-d0b0-483d-821a-bb5d8316d51d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='4cc7f318-35f5-440f-a4a4-145b5f0b918d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 29630}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(id='f621ade4-9b0d-471f-a522-44eb5feeba0c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19373}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]Answer: Task decomposition is a technique used to break down complex tasks into smaller, manageable steps, allowing for more efficient problem-solving. This can be achieved through methods like chain of thought prompting or the tree of thoughts approach, which explores multiple reasoning possibilities at each step. It can be initiated through simple prompts, task-specific instructions, or human inputs.\n",
      "Stream steps:\n",
      "for step in graph.stream(    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"):    print(f\"{step}\\n\\n----------------\\n\")\n",
      "{'retrieve': {'context': [Document(id='a42dc78b-8f76-472a-9e25-180508af74f3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='c0e45887-d0b0-483d-821a-bb5d8316d51d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='4cc7f318-35f5-440f-a4a4-145b5f0b918d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 29630}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(id='f621ade4-9b0d-471f-a522-44eb5feeba0c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19373}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]}}----------------{'generate': {'answer': 'Task decomposition is the process of breaking down a complex task into smaller, more manageable steps. This technique, often enhanced by methods like Chain of Thought (CoT) or Tree of Thoughts, allows models to reason through tasks systematically and improves performance by clarifying the thought process. It can be achieved through simple prompts, task-specific instructions, or human inputs.'}}----------------\n",
      "Stream tokens:\n",
      "for message, metadata in graph.stream(    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"):    print(message.content, end=\"|\")\n",
      "|Task| decomposition| is| the| process| of| breaking| down| complex| tasks| into| smaller|,| more| manageable| steps|.| It| can| be| achieved| through| techniques| like| Chain| of| Thought| (|Co|T|)| prompting|,| which| encourages| the| model| to| think| step| by| step|,| or| through| more| structured| methods| like| the| Tree| of| Thoughts|.| This| approach| not| only| simplifies| task| execution| but| also| provides| insights| into| the| model|'s| reasoning| process|.||\n",
      "tipFor async invocations, use:result = await graph.ainvoke(...)andasync for step in graph.astream(...):\n",
      "Returning sources​\n",
      "Note that by storing the retrieved context in the state of the graph, we recover sources for the model's generated answer in the \"context\" field of the state. See this guide on returning sources for more detail.\n",
      "Go deeper​\n",
      "Chat models take in a sequence of messages and return a message.\n",
      "\n",
      "Docs\n",
      "Integrations: 25+ integrations to choose from.\n",
      "Interface: API reference for the base interface.\n",
      "\n",
      "Customizing the prompt\n",
      "As shown above, we can load prompts (e.g., this RAG\n",
      "prompt) from the prompt\n",
      "hub. The prompt can also be easily customized. For example:\n",
      "from langchain_core.prompts import PromptTemplatetemplate = \"\"\"Use the following pieces of context to answer the question at the end.If you don't know the answer, just say that you don't know, don't try to make up an answer.Use three sentences maximum and keep the answer as concise as possible.Always say \"thanks for asking!\" at the end of the answer.{context}Question: {question}Helpful Answer:\"\"\"custom_rag_prompt = PromptTemplate.from_template(template)API Reference:PromptTemplate\n",
      "Query analysis​\n",
      "So far, we are executing the retrieval using the raw input query. However, there are some advantages to allowing a model to generate the query for retrieval purposes. For example:\n",
      "\n",
      "In addition to semantic search, we can build in structured filters (e.g., \"Find documents since the year 2020.\");\n",
      "The model can rewrite user queries, which may be multifaceted or include irrelevant language, into more effective search queries.\n",
      "\n",
      "Query analysis employs models to transform or construct optimized search queries from raw user input. We can easily incorporate a query analysis step into our application. For illustrative purposes, let's add some metadata to the documents in our vector store. We will add some (contrived) sections to the document which we can filter on later.\n",
      "total_documents = len(all_splits)third = total_documents // 3for i, document in enumerate(all_splits):    if i < third:        document.metadata[\"section\"] = \"beginning\"    elif i < 2 * third:        document.metadata[\"section\"] = \"middle\"    else:        document.metadata[\"section\"] = \"end\"all_splits[0].metadata\n",
      "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8, 'section': 'beginning'}\n",
      "We will need to update the documents in our vector store. We will use a simple InMemoryVectorStore for this, as we will use some of its specific features (i.e., metadata filtering). Refer to the vector store integration documentation for relevant features of your chosen vector store.\n",
      "from langchain_core.vectorstores import InMemoryVectorStorevector_store = InMemoryVectorStore(embeddings)_ = vector_store.add_documents(all_splits)API Reference:InMemoryVectorStore\n",
      "Let's next define a schema for our search query. We will use structured output for this purpose. Here we define a query as containing a string query and a document section (either \"beginning\", \"middle\", or \"end\"), but this can be defined however you like.\n",
      "from typing import Literalfrom typing_extensions import Annotatedclass Search(TypedDict):    \"\"\"Search query.\"\"\"    query: Annotated[str, ..., \"Search query to run.\"]    section: Annotated[        Literal[\"beginning\", \"middle\", \"end\"],        ...,        \"Section to query.\",    ]\n",
      "Finally, we add a step to our LangGraph application to generate a query from the user's raw input:\n",
      "class State(TypedDict):    question: str    query: Search    context: List[Document]    answer: strdef analyze_query(state: State):    structured_llm = llm.with_structured_output(Search)    query = structured_llm.invoke(state[\"question\"])    return {\"query\": query}def retrieve(state: State):    query = state[\"query\"]    retrieved_docs = vector_store.similarity_search(        query[\"query\"],        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],    )    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])graph_builder.add_edge(START, \"analyze_query\")graph = graph_builder.compile()\n",
      "Full Code:from typing import Literalimport bs4from langchain import hubfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_core.documents import Documentfrom langchain_core.vectorstores import InMemoryVectorStorefrom langchain_text_splitters import RecursiveCharacterTextSplitterfrom langgraph.graph import START, StateGraphfrom typing_extensions import Annotated, List, TypedDict# Load and chunk contents of the blogloader = WebBaseLoader(    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),    bs_kwargs=dict(        parse_only=bs4.SoupStrainer(            class_=(\"post-content\", \"post-title\", \"post-header\")        )    ),)docs = loader.load()text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)all_splits = text_splitter.split_documents(docs)# Update metadata (illustration purposes)total_documents = len(all_splits)third = total_documents // 3for i, document in enumerate(all_splits):    if i < third:        document.metadata[\"section\"] = \"beginning\"    elif i < 2 * third:        document.metadata[\"section\"] = \"middle\"    else:        document.metadata[\"section\"] = \"end\"# Index chunksvector_store = InMemoryVectorStore(embeddings)_ = vector_store.add_documents(all_splits)# Define schema for searchclass Search(TypedDict):    \"\"\"Search query.\"\"\"    query: Annotated[str, ..., \"Search query to run.\"]    section: Annotated[        Literal[\"beginning\", \"middle\", \"end\"],        ...,        \"Section to query.\",    ]# Define prompt for question-answeringprompt = hub.pull(\"rlm/rag-prompt\")# Define state for applicationclass State(TypedDict):    question: str    query: Search    context: List[Document]    answer: strdef analyze_query(state: State):    structured_llm = llm.with_structured_output(Search)    query = structured_llm.invoke(state[\"question\"])    return {\"query\": query}def retrieve(state: State):    query = state[\"query\"]    retrieved_docs = vector_store.similarity_search(        query[\"query\"],        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],    )    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])graph_builder.add_edge(START, \"analyze_query\")graph = graph_builder.compile()API Reference:Document | InMemoryVectorStore | StateGraph\n",
      "display(Image(graph.get_graph().draw_mermaid_png()))\n",
      "\n",
      "We can test our implementation by specifically asking for context from the end of the post. Note that the model includes different information in its answer.\n",
      "for step in graph.stream(    {\"question\": \"What does the end of the post say about Task Decomposition?\"},    stream_mode=\"updates\",):    print(f\"{step}\\n\\n----------------\\n\")\n",
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}----------------{'retrieve': {'context': [Document(id='d6cef137-e1e8-4ddc-91dc-b62bd33c6020', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39221, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='d1834ae1-eb6a-43d7-a023-08dfa5028799', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39086, 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(id='ca7f06e4-2c2e-4788-9a81-2418d82213d9', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32942, 'section': 'end'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(id='1fcc2736-30f4-4ef6-90f2-c64af92118cb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35127, 'section': 'end'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n\\`\\`\\`LANG\\\\nCODE\\\\n\\`\\`\\`\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]}}----------------{'generate': {'answer': 'The end of the post highlights that task decomposition faces challenges in long-term planning and adapting to unexpected errors. LLMs struggle with adjusting their plans, making them less robust compared to humans who learn from trial and error. This indicates a limitation in effectively exploring the solution space and handling complex tasks.'}}----------------\n",
      "In both the streamed steps and the LangSmith trace, we can now observe the structured query that was fed into the retrieval step.\n",
      "Query Analysis is a rich problem with a wide range of approaches. Refer to the how-to guides for more examples.\n",
      "Next steps​\n",
      "We've covered the steps to build a basic Q&A app over data:\n",
      "\n",
      "Loading data with a Document Loader\n",
      "Chunking the indexed data with a Text Splitter to make it more easily usable by a model\n",
      "Embedding the data and storing the data in a vectorstore\n",
      "Retrieving the previously stored chunks in response to incoming questions\n",
      "Generating an answer using the retrieved chunks as context.\n",
      "\n",
      "In Part 2 of the tutorial, we will extend the implementation here to accommodate conversation-style interactions and multi-step retrieval processes.\n",
      "Further reading:\n",
      "\n",
      "Return sources: Learn how to return source documents\n",
      "Streaming: Learn how to stream outputs and intermediate steps\n",
      "Add chat history: Learn how to add chat history to your app\n",
      "Retrieval conceptual guide: A high-level overview of specific retrieval techniques\n",
      "Edit this pagePreviousTaggingNextBuild a semantic search engineOverviewIndexingRetrieval and generationSetupJupyter NotebookInstallationLangSmithComponentsPreviewDetailed walkthrough1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationQuery analysisNext stepsCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(web_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190061b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 1\n",
      "첫 번째 문서 메타데이터: {'source': 'https://python.langchain.com/docs/tutorials/rag/'}\n"
     ]
    }
   ],
   "source": [
    "# Beautiful Soup 파서 옵션 설정\n",
    "web_loader_advanced = WebBaseLoader(\n",
    "    web_paths=[\"https://python.langchain.com/docs/tutorials/rag/\"],\n",
    "    bs_kwargs={\n",
    "        \"parse_only\": bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "web_docs_advanced = web_loader_advanced.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs_advanced)}\")\n",
    "print(f\"첫 번째 문서 메타데이터: {web_docs_advanced[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17883f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 1\n",
      "첫 번째 문서 메타데이터: {'source': 'https://example.com', 'title': 'Example Domain', 'language': 'No language found.'}\n"
     ]
    }
   ],
   "source": [
    "# 헤더 설정 (예: User-Agent)\n",
    "web_loader_with_headers = WebBaseLoader(\n",
    "    web_paths=[\"https://example.com\"],\n",
    "    header_template={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; LangChain)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "web_docs_with_headers = web_loader_with_headers.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs_with_headers)}\")\n",
    "print(f\"첫 번째 문서 메타데이터: {web_docs_with_headers[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239cbc0",
   "metadata": {},
   "source": [
    "### 2. 📊 CSV 파일 로더 (CSVLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43ee6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 10\n",
      "첫 번째 문서:\n",
      "Team: KIA 타이거즈\n",
      "City: 광주\n",
      "Founded: 1982\n",
      "Home Stadium: 광주-기아 챔피언스 필드\n",
      "Championships: 11\n",
      "Introduction: KBO 리그의 전통 강호로, 역대 최다 우승 기록을 보유하고 있다. '타이거즈 스피릿'으로 유명하며, 양현종, 안치홍 등 스타 선수들을 배출했다. 광주를 연고로 하는 유일한 프로야구팀으로 지역 사랑이 강하다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 기본 CSV 로드\n",
    "csv_loader = CSVLoader(\"./data/kbo_teams_2023.csv\", encoding=\"utf-8\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(f\"문서 수: {len(csv_docs)}\")\n",
    "print(f\"첫 번째 문서:\\n{csv_docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb0731b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './data/kbo_teams_2023.csv', 'row': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d1fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 10\n",
      "첫 번째 문서 메타데이터: {'source': 'KIA 타이거즈', 'row': 0, 'Founded': '1982'}\n",
      "첫 번째 문서 내용:\n",
      "Introduction: KBO 리그의 전통 강호로, 역대 최다 우승 기록을 보유하고 있다. '타이거즈 스피릿'으로 유명하며, 양현종, 안치홍 등 스타 선수들을 배출했다. 광주를 연고로 하는 유일한 프로야구팀으로 지역 사랑이 강하다.\n"
     ]
    }
   ],
   "source": [
    "# 소스 컬럼 지정 및 인코딩 설정\n",
    "csv_loader_advanced = CSVLoader(\n",
    "    file_path=\"./data/kbo_teams_2023.csv\",\n",
    "    source_column=\"Team\",      # 이 컬럼이 메타데이터의 source가 됨\n",
    "    content_columns=[\"Introduction\"],  # 이 컬럼이 문서의 내용이 됨\n",
    "    metadata_columns=[\"Founded\"],  # 이 컬럼이 메타데이터에 추가됨\n",
    "    encoding=\"utf-8\",          # 인코딩 명시\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",      # 구분자\n",
    "        \"quotechar\": '\"',      # 인용 문자\n",
    "    }\n",
    ")\n",
    "\n",
    "csv_docs_advanced = csv_loader_advanced.load()\n",
    "\n",
    "# 문서 수와 첫 번째 문서 내용 출력\n",
    "print(f\"문서 수: {len(csv_docs_advanced)}\")\n",
    "print(f\"첫 번째 문서 메타데이터: {csv_docs_advanced[0].metadata}\")\n",
    "print(f\"첫 번째 문서 내용:\\n{csv_docs_advanced[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e9558",
   "metadata": {},
   "source": [
    "### 3. 📖 PDF 파일 로더 \n",
    "\n",
    "- **PyPDFLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d82df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 개수: 20\n",
      "페이지 1: 1811 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}\n",
      "페이지 2: 1709 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}\n",
      "페이지 3: 2164 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 초기화\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e68eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      " \n",
      "제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품\n"
     ]
    }
   ],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c964d1",
   "metadata": {},
   "source": [
    "- **다른 PDF 로더들**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a60f3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredPDFLoader,\n",
    "    PyMuPDFLoader,\n",
    "    PDFMinerLoader\n",
    ")\n",
    "\n",
    "# Unstructured PDF 로더 (이미지, 테이블 처리 가능) : 별도 의존성 설치 필요\n",
    "# unstructured_loader = UnstructuredPDFLoader(\"./data/labor_law.pdf\")\n",
    "\n",
    "# PyMuPDF 로더 (빠른 처리)\n",
    "pymupdf_loader = PyMuPDFLoader(\"./data/labor_law.pdf\")\n",
    "\n",
    "# PDFMiner 로더 (정확한 텍스트 추출)\n",
    "pdfminer_loader = PDFMinerLoader(\"./data/labor_law.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28116083",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "pymupdf package not found, please install it with `pip install pymupdf`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:954\u001b[39m, in \u001b[36mPyMuPDFParser._lazy_parse\u001b[39m\u001b[34m(self, blob, text_kwargs)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymupdf\u001b[39;00m\n\u001b[32m    956\u001b[39m     text_kwargs = text_kwargs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_kwargs\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pymupdf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# pymupdf_loader = PyMuPDFLoader(\"./data/labor_law.pdf\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pdf_docs = \u001b[43mpymupdf_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPDF 문서 개수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdf_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 각 페이지별 정보 확인\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:853\u001b[39m, in \u001b[36mPyMuPDFLoader.load\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m--> \u001b[39m\u001b[32m853\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:850\u001b[39m, in \u001b[36mPyMuPDFLoader._lazy_load\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     blob = Blob.from_path(\u001b[38;5;28mself\u001b[39m.file_path)\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m parser._lazy_parse(blob, text_kwargs=kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:991\u001b[39m, in \u001b[36mPyMuPDFParser._lazy_parse\u001b[39m\u001b[34m(self, blob, text_kwargs)\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[38;5;28mself\u001b[39m.extract_tables_settings = {\n\u001b[32m    966\u001b[39m             \u001b[38;5;66;03m# See https://pymupdf.readthedocs.io/en/latest/page.html#Page.find_tables\u001b[39;00m\n\u001b[32m    967\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33madd_lines\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# optional user-specified lines\u001b[39;00m\n\u001b[32m    989\u001b[39m         }\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpymupdf package not found, please install it \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith `pip install pymupdf`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m     )\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PyMuPDFParser._lock:\n\u001b[32m    997\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m blob.as_bytes_io() \u001b[38;5;28;01mas\u001b[39;00m file_path:\n",
      "\u001b[31mImportError\u001b[39m: pymupdf package not found, please install it with `pip install pymupdf`"
     ]
    }
   ],
   "source": [
    "# pymupdf_loader = PyMuPDFLoader(\"./data/labor_law.pdf\")\n",
    "pdf_docs = pymupdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfminer_loader = PDFMinerLoader(\"./data/labor_law.pdf\")\n",
    "pdf_docs = pdfminer_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907759c",
   "metadata": {},
   "source": [
    "### 4. 📝 텍스트 파일 로더 (TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e731e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 1\n",
      "첫 번째 문서 내용:\n",
      "1. 시그니처 스테이크\n",
      "   • 가격: ₩35,000\n",
      "   • 주요 식재료: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\n",
      "   • 설명: 셰프의 특제 시그니처 메뉴로, 21일간 건조 숙성한 최상급 한우 등심을 사용합니다. 미디엄 레어로 조리하여 육즙을 최대한 보존하며, 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여집니다. 레드와인 소스와 함께 제공되어 풍부한 맛을 더합니다.\n",
      "\n",
      "2. 트러플 리조또\n",
      "   • 가격: ₩22,000\n",
      "   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\n",
      "   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.\n",
      "\n",
      "3. 연어 타르타르\n",
      "   • 가격: ₩18,000\n",
      "   • 주요 식재료: 노르웨이산 생연어, 아보카도, 케이퍼, 적양파\n",
      "   • 설명: 신선한 노르웨이산 생연어를 곱게 다져 아보카도, 케이퍼, 적양파와 함께 섞어 만든 타르타르입니다. 레몬 드레싱으로 상큼한 맛을 더했으며, 바삭한 브리오쉬 토스트와 함께 제공됩니다. 전채요리로 완벽한 메뉴입니다.\n",
      "\n",
      "4. 버섯 크림 수프\n",
      "   • 가격: ₩10,000\n",
      "   • 주요 식재료: 양송이버섯, 표고버섯, 생크림, 트러플 오일\n",
      "   • 설명: 양송이버섯과 표고버섯을 오랜 시간 정성스레 끓여 만든 크림 수프입니다. 부드러운 텍스처와 깊은 버섯 향이 특징이며, 최상급 트러플 오일을 살짝 뿌려 고급스러운 향을 더했습니다. 파슬리를 곱게 다져 고명으로 올려 제공됩니다.\n",
      "\n",
      "5. 가든 샐러드\n",
      "   • 가격: ₩12,000\n",
      "   • 주요 식재료: 유기농 믹스 그린, 체리 토마토, 오이, 당근, 발사믹 드레싱\n",
      "   • 설명: 신선한 유기농 채소들로 구성된 건강한 샐러드입니다. 아삭한 식감의 믹스 그린에 달콤한 체리 토마토, 오이, 당근을 더해 다양한 맛과 식감을 즐길 \n",
      "첫 번째 문서 메타데이터: {'source': './data/restaurant_menu.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 단일 텍스트 파일 로드\n",
    "text_loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "text_docs = text_loader.load()\n",
    "\n",
    "print(f\"문서 수: {len(text_docs)}\")\n",
    "print(f\"첫 번째 문서 내용:\\n{text_docs[0].page_content[:1000]}\")  # 첫 1000자 출력\n",
    "print(f\"첫 번째 문서 메타데이터: {text_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4519ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서 수: 2\n",
      "첫 번째 문서 내용:\n",
      "1. 시그니처 스테이크\n",
      "   • 가격: ₩35,000\n",
      "   • 주요 식재료: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\n",
      "   • 설명: 셰프의 특제 시그니처 메뉴로, 21일간 건조 숙성한 최상급 한우 등심을 사용합니다. 미디엄 레어로 조리하여 육즙을 최대한 보존하며, 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여집니다. 레드와인 소스와 함께 제공되어 풍부한 맛을 더합니다.\n",
      "\n",
      "2. 트러플 리조또\n",
      "   • 가격: ₩22,000\n",
      "   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\n",
      "   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.\n",
      "\n",
      "3. 연어 타르타르\n",
      "   • 가격: ₩18,000\n",
      "   • 주요 식재료: 노르웨이산 생연어, 아보카도, 케이퍼, 적양파\n",
      "   • 설명: 신선한 노르웨이산 생연어를 곱게 다져 아보카도, 케이퍼, 적양파와 함께 섞어 만든 타르타르입니다. 레몬 드레싱으로 상큼한 맛을 더했으며, 바삭한 브리오쉬 토스트와 함께 제공됩니다. 전채요리로 완벽한 메뉴입니다.\n",
      "\n",
      "4. 버섯 크림 수프\n",
      "   • 가격: ₩10,000\n",
      "   • 주요 식재료: 양송이버섯, 표고버섯, 생크림, 트러플 오일\n",
      "   • 설명: 양송이버섯과 표고버섯을 오랜 시간 정성스레 끓여 만든 크림 수프입니다. 부드러운 텍스처와 깊은 버섯 향이 특징이며, 최상급 트러플 오일을 살짝 뿌려 고급스러운 향을 더했습니다. 파슬리를 곱게 다져 고명으로 올려 제공됩니다.\n",
      "\n",
      "5. 가든 샐러드\n",
      "   • 가격: ₩12,000\n",
      "   • 주요 식재료: 유기농 믹스 그린, 체리 토마토, 오이, 당근, 발사믹 드레싱\n",
      "   • 설명: 신선한 유기농 채소들로 구성된 건강한 샐러드입니다. 아삭한 식감의 믹스 그린에 달콤한 체리 토마토, 오이, 당근을 더해 다양한 맛과 식감을 즐길 \n",
      "첫 번째 문서 메타데이터: {'source': 'data\\\\restaurant_menu.txt'}\n"
     ]
    }
   ],
   "source": [
    "# 디렉토리 내 모든 텍스트 파일 로드\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "directory_loader = DirectoryLoader(\n",
    "    \"./data/\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "all_text_docs = directory_loader.load()\n",
    "\n",
    "print(f\"전체 문서 수: {len(all_text_docs)}\")\n",
    "print(f\"첫 번째 문서 내용:\\n{all_text_docs[0].page_content[:1000]}\")  # 첫 1000자 출력\n",
    "print(f\"첫 번째 문서 메타데이터: {all_text_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cb485",
   "metadata": {},
   "source": [
    "### 🎯 실습 1: 웹 문서 로더 연습   ~ 14:53분까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 웹 페이지들을 로드하고 메타데이터를 출력해보세요\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/concepts/\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb33946",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 텍스트 분할 (Text Splitting)\n",
    "\n",
    "### 🎯 텍스트 분할이 필요한 이유\n",
    "1. **토큰 제한**: LLM은 입력 토큰 수에 제한이 있음\n",
    "2. **검색 정확도**: 작은 청크가 더 정확한 검색 결과 제공\n",
    "3. **메모리 효율성**: 대용량 문서의 효율적 처리\n",
    "\n",
    "### 📊 분할 전략 비교\n",
    "| 방법 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|----------|\n",
    "| CharacterTextSplitter | 단순, 빠름 | 문맥 고려 안함 | 간단한 텍스트 |\n",
    "| RecursiveCharacterTextSplitter | 문맥 보존 우수 | 계산 복잡 | 일반적인 문서 |\n",
    "| SemanticChunker | 의미 기반 분할 | 느림, 비용 많음 | 중요한 문서 |\n",
    "| TokenTextSplitter | 정확한 토큰 수 | 토크나이저 의존 | API 비용 최적화 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa31164",
   "metadata": {},
   "source": [
    "### 1. CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2cb664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서의 텍스트 길이: 1811\n"
     ]
    }
   ],
   "source": [
    "long_text = pdf_docs[0].page_content\n",
    "print(f'첫 번째 문서의 텍스트 길이: {len(long_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a007e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크 수: 3\n",
      "1000\n",
      "1000\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 기본 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",        # 구분자\n",
    "    chunk_size=1000,         # 청크 크기\n",
    "    chunk_overlap=200,       # 중복 크기\n",
    "    length_function=len,     # 길이 측정 함수\n",
    "    is_separator_regex=False # 정규식 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "print(f\"분할된 청크 수: {len(chunks)}\")\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f3dedbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 620, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 단위로 분할된 청크 수: 4\n",
      "첫 번째 문장 청크 내용: 법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 정규식을 사용한 문장 단위 분할\n",
    "def create_improved_sentence_splitter():\n",
    "    \"\"\"\n",
    "    법률 문서와 공문서에 적합한 문장 분할기를 생성합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 간단하고 안전한 정규식 패턴\n",
    "    # 문장 끝 후 공백이 있고, 특정 패턴이 따라오지 않는 경우만 분할\n",
    "    improved_pattern = r'(?<=[.!?])\\s+(?!\\s*(?:\\d+|호|조|항|]|\\)|[가-힣]{1,2}\\s*\\)|[A-Za-z]\\s*\\)|[,;:]))'\n",
    "    \n",
    "    sentence_splitter = CharacterTextSplitter(\n",
    "        separator=improved_pattern,\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        is_separator_regex=True,\n",
    "        keep_separator=True\n",
    "    )\n",
    "    \n",
    "    return sentence_splitter\n",
    "\n",
    "\n",
    "# 정규식을 사용한 문장 단위 분할기 생성\n",
    "sentence_splitter = create_improved_sentence_splitter()\n",
    "\n",
    "# 문장 단위로 분할\n",
    "sentence_chunks = sentence_splitter.split_text(long_text)\n",
    "print(f\"문장 단위로 분할된 청크 수: {len(sentence_chunks)}\")\n",
    "print(f\"첫 번째 문장 청크 내용: {sentence_chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a04b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 번째 문장 청크 내용: 제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "말한다.\n",
      "6. “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을\n",
      "그 기간의 총일수로 나눈 금액을 말한다.\n"
     ]
    }
   ],
   "source": [
    "print(f\"두 번째 문장 청크 내용: {sentence_chunks[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824d6d1",
   "metadata": {},
   "source": [
    "### 2. RecursiveCharacterTextSplitter\n",
    "\n",
    "- 재귀적으로 텍스트를 분할하여 문맥을 최대한 보존하는 분할기입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93c8a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 56\n",
      "청크 1: 936 문자\n",
      "청크 2: 944 문자\n",
      "청크 3: 273 문자\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 기본 재귀 분할기\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", r'(?<=[.!?])\\s+(?!\\s*(?:\\d+|호|조|항|]|\\)|[가-힣]{1,2}\\s*\\)|[A-Za-z]\\s*\\)|[,;:]))']  # 우선순위 순서\n",
    ")\n",
    "\n",
    "# Document 객체 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "\n",
    "# 각 청크의 길이 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"청크 {i+1}: {len(chunk.page_content)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe18e1",
   "metadata": {},
   "source": [
    "### 3. 토큰 기반 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34cd7a",
   "metadata": {},
   "source": [
    "#### 🔧 TikToken 기반 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c97df91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 492 토큰\n",
      "청크 2: 449 토큰\n",
      "청크 3: 475 토큰\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 토크나이저 사용\n",
    "token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # GPT-4 인코딩\n",
    "    chunk_size=500,              # 토큰 수 기준\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = token_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "# 토큰 수 확인\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer.encode(chunk.page_content))\n",
    "    print(f\"청크 {i+1}: {token_count} 토큰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ba7a0",
   "metadata": {},
   "source": [
    "#### 🤗 Hugging Face 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e50854e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\ktds-llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 284 토큰\n",
      "청크 2: 298 토큰\n",
      "청크 3: 273 토큰\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# BGE-M3 토크나이저 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "hf_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = hf_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "# 토큰 수 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer(chunk.page_content)[\"input_ids\"])\n",
    "    print(f\"청크 {i+1}: {token_count} 토큰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bbc2e",
   "metadata": {},
   "source": [
    "### 4. **Semantic Chunking**\n",
    "\n",
    "- **SemanticChunker**는 텍스트를 의미 단위로 **분할**하는 특수한 텍스트 분할도구 \n",
    "\n",
    "- 단순 길이 기반이 아닌 **의미 기반**으로 텍스트를 청크화하는데 효과적\n",
    "\n",
    "- **breakpoint_threshold_type**: Text Splitting의 다양한 임계값(Threshold) 설정 방식 (통계적 기법) \n",
    "\n",
    "    - **Gradient** 방식: 임베딩 벡터 간의 **기울기 변화**를 기준으로 텍스트를 분할\n",
    "    - **Percentile** 방식: 임베딩 거리의 **백분위수**를 기준으로 분할 지점을 결정 (기본값: 95%)\n",
    "    - **Standard Deviation** 방식: 임베딩 거리의 **표준편차**를 활용하여 유의미한 변화점을 찾아서 분할\n",
    "    - **Interquartile** 방식: 임베딩 거리의 **사분위수 범위**를 기준으로 이상치를 감지하여 분할\n",
    "\n",
    "- 설치: pip install langchain_experimental 또는 uv add langchain_experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker \n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델을 사용하여 SemanticChunker를 초기화 \n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),         # OpenAI 임베딩 사용\n",
    "    breakpoint_threshold_type=\"gradient\",  # 임계값 타입 설정 (gradient, percentile, standard_deviation, interquartile)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956587ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb3dd5",
   "metadata": {},
   "source": [
    "### 5. 구조 기반 분할\n",
    "\n",
    "#### 📄 HTML 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30c51832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML 헤더로 분할된 청크 수: 4\n",
      "청크 1:\n",
      "page_content='제목 1' metadata={'Header 1': '제목 1'}\n",
      "----------------------------------------\n",
      "청크 2:\n",
      "page_content='내용 1' metadata={'Header 1': '제목 1'}\n",
      "----------------------------------------\n",
      "청크 3:\n",
      "page_content='소제목 1.1' metadata={'Header 1': '제목 1', 'Header 2': '소제목 1.1'}\n",
      "----------------------------------------\n",
      "청크 4:\n",
      "page_content='내용 1.1' metadata={'Header 1': '제목 1', 'Header 2': '소제목 1.1'}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>제목 1</h1>\n",
    "        <p>내용 1</p>\n",
    "        <h2>소제목 1.1</h2>\n",
    "        <p>내용 1.1</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"HTML 헤더로 분할된 청크 수: {len(html_header_splits)}\")\n",
    "for i, chunk in enumerate(html_header_splits):\n",
    "    print(f\"청크 {i+1}:\\n{chunk}\\n{'-'*40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764c948",
   "metadata": {},
   "source": [
    "#### 🧑‍💻 코드 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47f2273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 코드 청크 수: 2\n",
      "청크 1:\n",
      "def hello_world():\n",
      "    print(\"Hello, World!\")\n",
      "----------------------------------------\n",
      "청크 2:\n",
      "class MyClass:\n",
      "    def __init__(self):\n",
      "        self.value = 42\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter\n",
    ")\n",
    "\n",
    "# Python 코드 분할\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "python_code = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        self.value = 42\n",
    "\"\"\"\n",
    "\n",
    "python_docs = python_splitter.create_documents([python_code])\n",
    "\n",
    "print(f\"Python 코드 청크 수: {len(python_docs)}\")\n",
    "for i, doc in enumerate(python_docs):\n",
    "    print(f\"청크 {i+1}:\\n{doc.page_content}\\n{'-'*40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568bc61e",
   "metadata": {},
   "source": [
    "### 🎯 실습 2: 텍스트 분할 비교 ~ 15:47분까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 텍스트를 다양한 방법으로 분할하고 결과를 비교해보세요\n",
    "sample_text = \"\"\"\n",
    "인공지능은 현대 기술의 핵심입니다. \n",
    "머신러닝을 통해 컴퓨터는 학습할 수 있습니다.\n",
    "\n",
    "딥러닝은 신경망을 기반으로 합니다.\n",
    "자연어 처리는 텍스트를 이해하는 기술입니다.\n",
    "\n",
    "컴퓨터 비전은 이미지를 분석합니다.\n",
    "강화학습은 행동을 통해 학습합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec29fae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 문서 임베딩 (Document Embedding)\n",
    "\n",
    "### 🎯 임베딩이란?\n",
    "텍스트를 고차원 벡터 공간의 숫자 배열로 변환하여 의미적 유사도를 계산할 수 있게 하는 기술입니다.\n",
    "\n",
    "### 📊 임베딩 모델 비교\n",
    "| 모델 | 차원 | 언어 지원 | 비용 | 성능 | 사용 사례 |\n",
    "|------|------|----------|------|------|----------|\n",
    "| OpenAI text-embedding-3-small | 1536 | 다국어 | 유료 | 높음 | 프로덕션 |\n",
    "| OpenAI text-embedding-3-large | 3072 | 다국어 | 유료 | 최고 | 고성능 요구 |\n",
    "| BAAI/bge-m3 | 1024 | 다국어 | 무료 | 높음 | 한국어 특화 |\n",
    "| sentence-transformers/all-MiniLM-L6-v2 | 384 | 영어 | 무료 | 중간 | 로컬 개발 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d3272",
   "metadata": {},
   "source": [
    "### 1. OpenAI 임베딩\n",
    "\n",
    "#### 🔧 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf5008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 차원: 1536\n",
      "컨텍스트 길이: 8191\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 기본 임베딩 모델\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536,           # 차원 수 (기본값)\n",
    "    show_progress_bar=True,    # 진행률 표시\n",
    "    max_retries=3             # 재시도 횟수\n",
    ")\n",
    "\n",
    "print(f\"임베딩 차원: {embeddings_model.dimensions}\")\n",
    "print(f\"컨텍스트 길이: {embeddings_model.embedding_ctx_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9801824",
   "metadata": {},
   "source": [
    "#### 📝 문서 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19286db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터 수: 5\n",
      "각 벡터 차원: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 문서 컬렉션 임베딩\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 이미지를 분석하는 기술입니다.\"\n",
    "]\n",
    "\n",
    "# 배치 임베딩 (효율적)\n",
    "doc_embeddings = embeddings_model.embed_documents(documents)\n",
    "print(f\"임베딩 벡터 수: {len(doc_embeddings)}\")\n",
    "print(f\"각 벡터 차원: {len(doc_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa6525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리 임베딩 차원: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 임베딩\n",
    "query = \"AI 기술에 대해 알려주세요\"\n",
    "query_embedding = embeddings_model.embed_query(query)\n",
    "print(f\"쿼리 임베딩 차원: {len(query_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67317e58",
   "metadata": {},
   "source": [
    "#### 💡 차원 축소 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ab31808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "축소된 임베딩 벡터 수: 5\n",
      "축소된 각 벡터 차원: 512\n"
     ]
    }
   ],
   "source": [
    "# 비용 절약을 위한 차원 축소\n",
    "compact_embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    "    dimensions=512  # 원래 1536에서 512로 축소\n",
    ")\n",
    "\n",
    "# 성능과 비용의 균형점 찾는 것이 중요!!!\n",
    "compact_doc_embeddings = compact_embeddings.embed_documents(documents)\n",
    "print(f\"축소된 임베딩 벡터 수: {len(compact_doc_embeddings)}\")\n",
    "print(f\"축소된 각 벡터 차원: {len(compact_doc_embeddings[0])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137bbef1",
   "metadata": {},
   "source": [
    "### 2. Hugging Face 임베딩\n",
    "\n",
    "#### 🤗 BGE-M3 모델 (한국어 우수)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83222ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 임베딩 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# BGE-M3 모델 (다국어, 한국어 성능 우수)\n",
    "embeddings_bge = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={'device': 'cpu'},        # 'cuda' for GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}  # L2 정규화\n",
    ")\n",
    "\n",
    "# BGE-M3 모델로 문서 임베딩\n",
    "bge_hf_embeddings = embeddings_bge.embed_documents(documents)\n",
    "print(f\"한국어 임베딩 차원: {len(bge_hf_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a79ffb",
   "metadata": {},
   "source": [
    "#### 📱 경량 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ab84bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/new-impl:\n",
      "- configuration.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/new-impl:\n",
      "- modeling.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경량 모델 한국어 임베딩 차원: 768\n"
     ]
    }
   ],
   "source": [
    "# 빠른 처리를 위한 경량 모델\n",
    "embedding_gte = HuggingFaceEmbeddings(\n",
    "    model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "    model_kwargs={'device': 'cpu', 'trust_remote_code': True},  # trust_remote_code for custom models\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "    \n",
    "# 경량 모델로 문서 임베딩\n",
    "alibaba_hf_embeddings = embedding_gte.embed_documents(documents)\n",
    "print(f\"경량 모델 한국어 임베딩 차원: {len(alibaba_hf_embeddings[0])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc083cd",
   "metadata": {},
   "source": [
    "### 3. Ollama 임베딩 (로컬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ad5bbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로컬 임베딩 벡터 수: 5\n",
      "각 벡터 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Ollama 서버가 실행 중이어야 함\n",
    "embeddings_ollama = OllamaEmbeddings(\n",
    "    model=\"bge-m3\",                    # 사용할 모델\n",
    "    # base_url=\"http://localhost:11434\"  # Ollama 서버 주소\n",
    ")\n",
    "\n",
    "# 로컬 임베딩\n",
    "local_embeddings = embeddings_ollama.embed_documents(documents)\n",
    "\n",
    "print(f\"로컬 임베딩 벡터 수: {len(local_embeddings)}\")\n",
    "print(f\"각 벡터 차원: {len(local_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441df2cb",
   "metadata": {},
   "source": [
    "### 4. 유사도 계산 및 검색\n",
    "\n",
    "#### 📏 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87b9bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_most_similar(query, doc_embeddings, documents, embeddings_model):\n",
    "    \"\"\"가장 유사한 문서 찾기\"\"\"\n",
    "    # 쿼리 임베딩\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    \n",
    "    # 가장 유사한 문서 인덱스\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    \n",
    "    return {\n",
    "        \"document\": documents[most_similar_idx],\n",
    "        \"similarity\": similarities[most_similar_idx],\n",
    "        \"index\": most_similar_idx\n",
    "    }\n",
    "\n",
    "# 쿼리와 문서 임베딩을 사용하여 가장 유사한 문서 찾기 (OpenAI)\n",
    "query = \"딥러닝에 대해 알려주세요\"\n",
    "result = find_most_similar(query, doc_embeddings, documents, embeddings_model)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d78393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.7360\n"
     ]
    }
   ],
   "source": [
    "# HuggingFaceEmbeddings를 사용한 유사도 검색 (BGE-M3)\n",
    "result = find_most_similar(query, bge_hf_embeddings, documents, embeddings_bge)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34a9fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.7886\n"
     ]
    }
   ],
   "source": [
    "# Alibaba-NLP/gte-multilingual-base 모델로 유사도 검색\n",
    "result = find_most_similar(query, alibaba_hf_embeddings, documents, embedding_gte)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "157eced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.7352\n"
     ]
    }
   ],
   "source": [
    "# Ollama 모델로 유사도 검색 (bge-m3)\n",
    "result = find_most_similar(query, local_embeddings, documents, embeddings_ollama)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d40c4",
   "metadata": {},
   "source": [
    "### 🎯 실습 3: 임베딩 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 질문들에 대해 다른 임베딩 모델들의 검색 성능을 비교해보세요\n",
    "queries = [\n",
    "    \"기계학습이란 무엇인가요?\",\n",
    "    \"이미지 인식 기술에 대해 설명해주세요\",\n",
    "    \"언어 모델의 작동 원리는?\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ffa75",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 벡터 저장소 (Vector Store)\n",
    "\n",
    "### 🎯 벡터 저장소란?\n",
    "임베딩된 벡터를 효율적으로 저장하고 유사도 기반 검색을 수행하는 특수 데이터베이스입니다.\n",
    "\n",
    "### 📊 벡터 저장소 비교\n",
    "| 종류 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|----------|\n",
    "| Chroma | 설치 간단, 로컬 친화적 | 대용량 처리 한계 | 개발, 프로토타입 |\n",
    "| FAISS | 매우 빠름, 확장성 우수 | 설정 복잡 | 대용량 검색 |\n",
    "| Pinecone | 완전 관리형, 고성능 | 유료, 클라우드 의존 | 프로덕션 |\n",
    "| Weaviate | GraphQL 지원, 하이브리드 검색 | 학습 곡선 | 복합 검색 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bd40b",
   "metadata": {},
   "source": [
    "### 1. Chroma 벡터 저장소\n",
    "\n",
    "#### 🚀 Chroma 설치 및 설정\n",
    "```bash\n",
    "pip install langchain-chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb5d82",
   "metadata": {},
   "source": [
    "#### 📚 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cc15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 문서 수: 95\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 문서 준비\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "pdf_docs = pdf_loader.load()\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "\n",
    "# 임베딩 모델\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma 벡터 저장소 생성\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"labor_law\",\n",
    "    persist_directory=\"./local_chroma_db\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}  # 유사도 메트릭 (l2)\n",
    ")\n",
    "\n",
    "print(f\"저장된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d65858",
   "metadata": {},
   "source": [
    "#### 💾 벡터 저장소 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d62249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 95\n"
     ]
    }
   ],
   "source": [
    "# 기존 벡터 저장소 로드\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./local_chroma_db\"\n",
    ")\n",
    "\n",
    "print(f\"로드된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581bc215",
   "metadata": {},
   "source": [
    "#### 🔍 기본 검색 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e74be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_pages': 20,\n",
       " 'creator': 'PyPDF',\n",
       " 'creationdate': '2024-10-15T14:45:34+09:00',\n",
       " 'moddate': '2024-10-15T14:45:34+09:00',\n",
       " 'producer': 'iText 2.1.7 by 1T3XT',\n",
       " 'page_label': '3',\n",
       " 'page': 2,\n",
       " 'source': './data/labor_law.pdf'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1887e37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과 수: 5\n",
      "결과 1: [제목개정 2021. 5. 18.]\n",
      " \n",
      "제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\n",
      " \n",
      "       제4장 근로시간과 휴식\n",
      " \n",
      "제50조(근로시간) ① 1주 간의 근로시간은 휴게시간을 제외하고 40시간을 초과할 수 없다.\n",
      "② 1일의 근로시간은 휴게시간을 제외하고 8시간을 초과할 수 없다.\n",
      "③ 제1항 및 제2항에 따라 근로시간을 산정하는 경우 작업을 위하여 근로자가 사용자의 지휘ㆍ감독 아래에 있는 대\n",
      "기시간 등은 근로시간으로 본다.<신설 2012. 2. 1., 2020. 5. 26.>\n",
      " \n",
      "제51조(3개월 이내의 탄력적 근로시간제) ① 사용자는 취업규칙(취업규칙에 준하는 것을 포함한다)에서 정하는 바에 따\n",
      "라 2주 이내의 일정한 단위기간을 평균하여 1주 간의 근로시간이 제50조제1항의 근로시간을 초과하지 아니하는 범\n",
      "위에서 특정한 주에 제50조제1항의 근로시간을, 특정한 날에 제50조제2항의 근로시간을 초과하여 근로하게 할 수...\n",
      "----------------------------------------\n",
      "결과 2: 법제처                                                            9                                                       국가법령정보센터\n",
      "근로기준법\n",
      "[제목개정 2021. 1. 5.]\n",
      " \n",
      "제51조의2(3개월을 초과하는 탄력적 근로시간제) ① 사용자는 근로자대표와의 서면 합의에 따라 다음 각 호의 사항을\n",
      "정하면 3개월을 초과하고 6개월 이내의 단위기간을 평균하여 1주간의 근로시간이 제50조제1항의 근로시간을 초과\n",
      "하지 아니하는 범위에서 특정한 주에 제50조제1항의 근로시간을, 특정한 날에 제50조제2항의 근로시간을 초과하여\n",
      "근로하게 할 수 있다. 다만, 특정한 주의 근로시간은 52시간을, 특정한 날의 근로시간은 12시간을 초과할 수 없다.\n",
      "1. 대상 근로자의 범위\n",
      "2. 단위기간(3개월을 초과하고 6개월 이내의 일정한 기간으로 정하여야 한다)\n",
      "3. 단위기간의 주별 근로시간\n",
      "4. 그 밖에 대통령령으로...\n",
      "----------------------------------------\n",
      "결과 3: 동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 기준) 이 법에서 정하는 근로조건은 최저기준이므로 근로 관계 당사자는 이 기준을 이유로 근로조건\n",
      "을 낮출 수 없다.\n",
      " \n",
      "제4조(근로조건의 결정) 근로조건은 근로자와 사용자가 동등한 지위에서 자유의사에 따라 결정하여야 한다.\n",
      " \n",
      "제5조(근로조건의 준수) 근로자와 사용자는 각자가 단체협약, 취업규칙과 근로계약을 지키고 성실하게 이행할 의무가\n",
      "있다.\n",
      " \n",
      "제6조(균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로...\n",
      "----------------------------------------\n",
      "결과 4: 통상적으로 소정근로시간을 초과하여 근로할 필요가 있는 경우에는 그 업무의 수행에 통상 필요한 시간을 근로한\n",
      "것으로 본다.\n",
      "② 제1항 단서에도 불구하고 그 업무에 관하여 근로자대표와의 서면 합의를 한 경우에는 그 합의에서 정하는 시간\n",
      "을 그 업무의 수행에 통상 필요한 시간으로 본다.\n",
      "③ 업무의 성질에 비추어 업무 수행 방법을 근로자의 재량에 위임할 필요가 있는 업무로서 대통령령으로 정하는 업\n",
      "무는 사용자가 근로자대표와 서면 합의로 정한 시간을 근로한 것으로 본다. 이 경우 그 서면 합의에는 다음 각 호의\n",
      "사항을 명시하여야 한다.\n",
      "1. 대상 업무\n",
      "2. 사용자가 업무의 수행 수단 및 시간 배분 등에 관하여 근로자에게 구체적인 지시를 하지 아니한다는 내용\n",
      "3. 근로시간의 산정은 그 서면 합의로 정하는 바에 따른다는 내용\n",
      "④ 제1항과 제3항의 시행에 필요한 사항은 대통령령으로 정한다.\n",
      " \n",
      "제59조(근로시간 및 휴게시간의 특례) ① 「통계법」 제22조제1항에 따라 통계청장이 고시하는 산업에 관...\n",
      "----------------------------------------\n",
      "결과 5: 한다.\n",
      " \n",
      "제21조(전차금 상계의 금지) 사용자는 전차금(前借金)이나 그 밖에 근로할 것을 조건으로 하는 전대(前貸)채권과 임금\n",
      "을 상계하지 못한다.\n",
      " \n",
      "제22조(강제 저금의 금지) ① 사용자는 근로계약에 덧붙여 강제 저축 또는 저축금의 관리를 규정하는 계약을 체결하지\n",
      "못한다.\n",
      "② 사용자가 근로자의 위탁으로 저축을 관리하는 경우에는 다음 각 호의 사항을 지켜야 한다.\n",
      "1. 저축의 종류ㆍ기간 및 금융기관을 근로자가 결정하고, 근로자 본인의 이름으로 저축할 것\n",
      "2. 근로자가 저축증서 등 관련 자료의 열람 또는 반환을 요구할 때에는 즉시 이에 따를 것\n",
      " \n",
      "제23조(해고 등의 제한) ① 사용자는 근로자에게 정당한 이유 없이 해고, 휴직, 정직, 전직, 감봉, 그 밖의 징벌(懲罰)(이\n",
      "하 “부당해고등”이라 한다)을 하지 못한다.\n",
      "② 사용자는 근로자가 업무상 부상 또는 질병의 요양을 위하여 휴업한 기간과 그 후 30일 동안 또는 산전(産前)ㆍ산...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. 유사도 검색\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "similar_docs = chroma_db.similarity_search(\n",
    "    query=query,\n",
    "    k=5,  # 상위 5개 결과\n",
    "    filter={\"source\": \"./data/labor_law.pdf\"}  # 메타데이터 필터\n",
    ")\n",
    "\n",
    "print(f\"검색 결과 수: {len(similar_docs)}\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:500]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3be3abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수: 0.6994\n",
      "내용: [제목개정 2021. 5. 18.]\n",
      " \n",
      "제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\n",
      " \n",
      "       제4장 근로시간과 휴식\n",
      " \n",
      "제50...\n",
      "--------------------------------------------------\n",
      "점수: 0.7028\n",
      "내용: 법제처                                                            9                                    ...\n",
      "--------------------------------------------------\n",
      "점수: 0.7457\n",
      "내용: 동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. 점수와 함께 검색 (유사도 점수 포함)\n",
    "docs_with_scores = chroma_db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for doc, score in docs_with_scores:\n",
    "    print(f\"점수: {score:.4f}\")\n",
    "    print(f\"내용: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157b480",
   "metadata": {},
   "source": [
    "### 2. FAISS 벡터 저장소\n",
    "\n",
    "#### ⚡ FAISS 설치 및 사용\n",
    "```bash\n",
    "pip install faiss-cpu  # CPU 버전\n",
    "# pip install faiss-gpu  # GPU 버전\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c165e645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54d957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과 수: 5\n",
      "결과 1: [제목개정 2021. 5. 18.]\n",
      " \n",
      "제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\n",
      " \n",
      "       제4장 근로시간과 휴식\n",
      " \n",
      "제50...\n",
      "----------------------------------------\n",
      "결과 2: 법제처                                                            9                                    ...\n",
      "----------------------------------------\n",
      "결과 3: 동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 ...\n",
      "----------------------------------------\n",
      "결과 4: 통상적으로 소정근로시간을 초과하여 근로할 필요가 있는 경우에는 그 업무의 수행에 통상 필요한 시간을 근로한\n",
      "것으로 본다.\n",
      "② 제1항 단서에도 불구하고 그 업무에 관하여 근로자대표와...\n",
      "----------------------------------------\n",
      "결과 5: 한다.\n",
      " \n",
      "제21조(전차금 상계의 금지) 사용자는 전차금(前借金)이나 그 밖에 근로할 것을 조건으로 하는 전대(前貸)채권과 임금\n",
      "을 상계하지 못한다.\n",
      " \n",
      "제22조(강제 저금의 금지...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터 저장소 생성\n",
    "faiss_db = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# 로컬 저장\n",
    "faiss_db.save_local(\"./faiss_index\")\n",
    "\n",
    "# 로드\n",
    "faiss_db = FAISS.load_local(\n",
    "    \"./faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 검색\n",
    "similar_docs = faiss_db.similarity_search(query, k=5)\n",
    "\n",
    "print(f\"검색 결과 수: {len(similar_docs)}\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e9d91",
   "metadata": {},
   "source": [
    "### 3. 벡터 저장소 고급 기능\n",
    "\n",
    "#### 🎛️ 메타데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dca4ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링된 검색 결과 수: 5\n",
      "결과 1: 통상적으로 소정근로시간을 초과하여 근로할 필요가 있는 경우에는 그 업무의 수행에 통상 필요한 시간을 근로한\n",
      "것으로 본다.\n",
      "② 제1항 단서에도 불구하고 그 업무에 관하여 근로자대표와...\n",
      "10\n",
      "----------------------------------------\n",
      "결과 2: 쉬운 종류의 근로로 전환하여야 한다.<개정 2012. 2. 1.>\n",
      "⑥ 사업주는 제1항에 따른 출산전후휴가 종료 후에는 휴가 전과 동일한 업무 또는 동등한 수준의 임금을 지급하는\n",
      "직...\n",
      "13\n",
      "----------------------------------------\n",
      "결과 3: 제59조(근로시간 및 휴게시간의 특례) ① 「통계법」 제22조제1항에 따라 통계청장이 고시하는 산업에 관한 표준의 중분\n",
      "류 또는 소분류 중 다음 각 호의 어느 하나에 해당하는 사업...\n",
      "10\n",
      "----------------------------------------\n",
      "결과 4: 법제처                                                            15                                   ...\n",
      "14\n",
      "----------------------------------------\n",
      "결과 5: 서는 아니 된다.\n",
      "⑦ 제2항에 따라 직장 내 괴롭힘 발생 사실을 조사한 사람, 조사 내용을 보고받은 사람 및 그 밖에 조사 과정에 참여\n",
      "한 사람은 해당 조사 과정에서 알게 된 비밀...\n",
      "14\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 복합 필터 조건\n",
    "filter_criteria = {\n",
    "    \"$and\": [\n",
    "        {\"source\": {\"$eq\": \"./data/labor_law.pdf\"}},\n",
    "        {\"page\": {\"$gte\": 10}}  # 10페이지 이상\n",
    "    ]\n",
    "}\n",
    "\n",
    "filtered_results = chroma_db.similarity_search(\n",
    "    query=query,\n",
    "    k=5,\n",
    "    filter=filter_criteria\n",
    ")\n",
    "\n",
    "print(f\"필터링된 검색 결과 수: {len(filtered_results)}\")\n",
    "for i, doc in enumerate(filtered_results):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(doc.metadata['page'])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366f2ff",
   "metadata": {},
   "source": [
    "#### 🔄 문서 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9dab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab922fa2-cb37-4c71-8d0e-4955947ec5a6']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새 문서 추가\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "new_docs = [Document(page_content=\"새로운 내용\", metadata={\"source\": \"new\"})]\n",
    "chroma_db.add_documents(new_docs)\n",
    "\n",
    "# 문서 삭제 (ID 기반)\n",
    "# chroma_db.delete(ids=[\"doc_id_1\", \"doc_id_2\"])\n",
    "\n",
    "# 전체 컬렉션 삭제\n",
    "# chroma_db.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64df58",
   "metadata": {},
   "source": [
    "### 🎯 실습 4: 벡터 저장소 구축 ~ 16:42분까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 단계로 나만의 벡터 저장소를 구축해보세요:\n",
    "# 1. 웹에서 문서 로드\n",
    "# 2. 적절한 크기로 분할\n",
    "# 3. 임베딩 및 저장\n",
    "# 4. 검색 테스트\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528dd45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 검색기 (Retriever)\n",
    "\n",
    "### 🎯 Retriever란?\n",
    "벡터 저장소를 기반으로 사용자 질의에 가장 관련성 높은 문서를 검색하는 인터페이스입니다.\n",
    "\n",
    "### 📊 검색 전략 비교\n",
    "| 전략 | 설명 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|------|----------|\n",
    "| similarity | 단순 유사도 검색 | 빠름, 직관적 | 다양성 부족 | 일반적인 검색 |\n",
    "| similarity_score_threshold | 임계값 기반 검색 | 품질 보장 | 결과 수 불안정 | 고품질 결과 필요 |\n",
    "| mmr | 최대 한계 관련성 | 다양성 우수 | 느림 | 포괄적 정보 필요 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e572d",
   "metadata": {},
   "source": [
    "### 1. 기본 유사도 검색\n",
    "\n",
    "#### 🔍 Top-K 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f3c1f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 수: 5\n",
      "문서 1:\n",
      "내용: [제목개정 2021. 5. 18.]\n",
      " \n",
      "제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\n",
      " \n",
      "       제4장 근로시간과 휴식\n",
      " \n",
      "제50조(근로시간) ① 1주 간의 근로시간은 휴게시간을 제외하고 40시간을 초과할 수 없다.\n",
      "② 1일의 근로시간은 휴게시간을 제외하고 8시간을 초과할 수 없다.\n",
      "③ 제1항 및 제2항에 ...\n",
      "출처: ./data/labor_law.pdf\n",
      "--------------------------------------------------\n",
      "문서 2:\n",
      "내용: 법제처                                                            9                                                       국가법령정보센터\n",
      "근로기준법\n",
      "[제목개정 2021. 1. 5.]\n",
      " \n",
      "제51조의2(3개월을 초과하는 탄력적 근로시간제) ① 사용자는 근로자대표와의 서면...\n",
      "출처: ./data/labor_law.pdf\n",
      "--------------------------------------------------\n",
      "문서 3:\n",
      "내용: 동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 기준) 이 법에서 정하는 근로조건은 최저기준이므로 근로 관계 당사자는 이 기준을 이유로 근로조건\n",
      "을 낮출 수 없다.\n",
      " \n",
      "제4조(근로조건의 결정) 근로조건은 근로자와 사용자가 동등한...\n",
      "출처: ./data/labor_law.pdf\n",
      "--------------------------------------------------\n",
      "문서 4:\n",
      "내용: 통상적으로 소정근로시간을 초과하여 근로할 필요가 있는 경우에는 그 업무의 수행에 통상 필요한 시간을 근로한\n",
      "것으로 본다.\n",
      "② 제1항 단서에도 불구하고 그 업무에 관하여 근로자대표와의 서면 합의를 한 경우에는 그 합의에서 정하는 시간\n",
      "을 그 업무의 수행에 통상 필요한 시간으로 본다.\n",
      "③ 업무의 성질에 비추어 업무 수행 방법을 근로자의 재량에 위임할 필요가 있...\n",
      "출처: ./data/labor_law.pdf\n",
      "--------------------------------------------------\n",
      "문서 5:\n",
      "내용: 한다.\n",
      " \n",
      "제21조(전차금 상계의 금지) 사용자는 전차금(前借金)이나 그 밖에 근로할 것을 조건으로 하는 전대(前貸)채권과 임금\n",
      "을 상계하지 못한다.\n",
      " \n",
      "제22조(강제 저금의 금지) ① 사용자는 근로계약에 덧붙여 강제 저축 또는 저축금의 관리를 규정하는 계약을 체결하지\n",
      "못한다.\n",
      "② 사용자가 근로자의 위탁으로 저축을 관리하는 경우에는 다음 각 호의 사항을 지...\n",
      "출처: ./data/labor_law.pdf\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 벡터 저장소를 Retriever로 변환\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # 상위 5개 결과\n",
    ")\n",
    "\n",
    "# 검색 실행\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"문서 {i+1}:\")\n",
    "    print(f\"내용: {doc.page_content[:200]}...\")\n",
    "    print(f\"출처: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d1339",
   "metadata": {},
   "source": [
    "### 2. 임계값 기반 검색\n",
    "\n",
    "#### 📏 점수 임계값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ed0f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1 (유사도: 0.3006):\n",
      "[제목개정 2021. 5. 18.]\n",
      " \n",
      "제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\n",
      " \n",
      "       제4장 근로시간과 휴식\n",
      " \n",
      "제50...\n",
      "\n",
      "문서 2 (유사도: 0.2973):\n",
      "법제처                                                            9                                    ...\n",
      "\n",
      "문서 3 (유사도: 0.2550):\n",
      "동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 ...\n",
      "\n",
      "문서 4 (유사도: 0.2529):\n",
      "통상적으로 소정근로시간을 초과하여 근로할 필요가 있는 경우에는 그 업무의 수행에 통상 필요한 시간을 근로한\n",
      "것으로 본다.\n",
      "② 제1항 단서에도 불구하고 그 업무에 관하여 근로자대표와...\n",
      "\n",
      "문서 5 (유사도: 0.2461):\n",
      "한다.\n",
      " \n",
      "제21조(전차금 상계의 금지) 사용자는 전차금(前借金)이나 그 밖에 근로할 것을 조건으로 하는 전대(前貸)채권과 임금\n",
      "을 상계하지 못한다.\n",
      " \n",
      "제22조(강제 저금의 금지...\n",
      "\n",
      "문서 6 (유사도: 0.2332):\n",
      "쉬운 종류의 근로로 전환하여야 한다.<개정 2012. 2. 1.>\n",
      "⑥ 사업주는 제1항에 따른 출산전후휴가 종료 후에는 휴가 전과 동일한 업무 또는 동등한 수준의 임금을 지급하는\n",
      "직...\n",
      "\n",
      "문서 7 (유사도: 0.2273):\n",
      "[본조신설 2021. 1. 5.]\n",
      " \n",
      "제52조(선택적 근로시간제) ① 사용자는 취업규칙(취업규칙에 준하는 것을 포함한다)에 따라 업무의 시작 및 종료 시각\n",
      "을 근로자의 결정에 맡기...\n",
      "\n",
      "문서 8 (유사도: 0.2274):\n",
      "법제처                                                            3                                    ...\n",
      "\n",
      "문서 9 (유사도: 0.2259):\n",
      "법제처                                                            1                                    ...\n",
      "\n",
      "문서 10 (유사도: 0.2255):\n",
      "③ 4주 동안(4주 미만으로 근로하는 경우에는 그 기간)을 평균하여 1주 동안의 소정근로시간이 15시간 미만인 근로\n",
      "자에 대하여는 제55조와 제60조를 적용하지 아니한다.<개정 2...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 점수 임계값 기반 검색\n",
    "threshold_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.1,  # 0.3 이상의 유사도만\n",
    "        \"k\": 10                  # 최대 10개까지\n",
    "    }\n",
    ")\n",
    "\n",
    "retrieved_docs = threshold_retriever.invoke(query)\n",
    "\n",
    "# 실제 유사도 점수 확인\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    # 실제 유사도 계산\n",
    "    doc_embedding = embeddings.embed_query(doc.page_content)\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "    \n",
    "    print(f\"문서 {i+1} (유사도: {similarity:.4f}):\")\n",
    "    print(f\"{doc.page_content[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f5a0c",
   "metadata": {},
   "source": [
    "### 3. MMR (Maximal Marginal Relevance) 검색\n",
    "\n",
    "#### 🎯 다양성을 고려한 검색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e66269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR 검색 결과:\n",
      "문서 1: [제목개정 2021. 5. 18.]\n",
      " \n",
      "제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\n",
      " \n",
      "       제4장 근로시간과 휴식\n",
      " \n",
      "제50조(근로시간) ① 1주 간의 근로시간은 휴게시간을 제외하고 40시간을 초과할 수 없다.\n",
      "②...\n",
      "\n",
      "문서 2: 법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021...\n",
      "\n",
      "문서 3: 제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "써 근로자의 자유의사에 어긋나는 근로를 강요하지 못한다....\n",
      "\n",
      "문서 4: 새로운 내용...\n",
      "\n",
      "문서 5: 서는 아니 된다.\n",
      "⑦ 제2항에 따라 직장 내 괴롭힘 발생 사실을 조사한 사람, 조사 내용을 보고받은 사람 및 그 밖에 조사 과정에 참여\n",
      "한 사람은 해당 조사 과정에서 알게 된 비밀을 피해근로자등의 의사에 반하여 다른 사람에게 누설하여서는 아니 된\n",
      "다. 다만, 조사와 관...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MMR 검색 - 관련성과 다양성의 균형\n",
    "mmr_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # 최종 반환할 문서 수\n",
    "        \"fetch_k\": 20,         # 초기 후보 문서 수\n",
    "        \"lambda_mult\": 0.5     # 관련성 vs 다양성 (0=최대 다양성, 1=최대 관련성)\n",
    "    }\n",
    ")\n",
    "\n",
    "mmr_docs = mmr_retriever.invoke(query)\n",
    "\n",
    "print(\"MMR 검색 결과:\")\n",
    "for i, doc in enumerate(mmr_docs):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d898f7d",
   "metadata": {},
   "source": [
    "#### 🔧 lambda_mult 파라미터 실험\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 lambda_mult 값으로 실험\n",
    "lambda_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    retriever = chroma_db.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"fetch_k\": 10,\n",
    "            \"lambda_mult\": lambda_val\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    docs = retriever.invoke(query)\n",
    "    print(f\"\\nLambda {lambda_val} 결과:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"  {i+1}. {doc.page_content[:100]}...\")\n",
    "    \n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40825374",
   "metadata": {},
   "source": [
    "### 4. 고급 검색 기법\n",
    "\n",
    "#### 🎛️ 메타데이터 필터링과 검색 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4e00bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타데이터 기반 필터링 결과:\n",
      "문서 1: [제목개정 2021. 5. 18.]\n",
      " \n",
      "제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\n",
      " \n",
      "       제4장 근로시간과 휴식\n",
      " \n",
      "제50조(근로시간) ① 1주 간의 근로시간은 휴게시간을 제외하고 40시간을 초과할 수 없다.\n",
      "②...\n",
      "\n",
      "문서 2: 법제처                                                            9                                                       국가법령정보센터\n",
      "근로기준법\n",
      "[제목개정 2021. 1. 5...\n",
      "\n",
      "문서 3: 동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 기준) 이 법에서 정하는 근로조건은 최저기준이므로 근로 관계 당사자는 이 기준을 이유로 근...\n",
      "\n",
      "문서 4: 통상적으로 소정근로시간을 초과하여 근로할 필요가 있는 경우에는 그 업무의 수행에 통상 필요한 시간을 근로한\n",
      "것으로 본다.\n",
      "② 제1항 단서에도 불구하고 그 업무에 관하여 근로자대표와의 서면 합의를 한 경우에는 그 합의에서 정하는 시간\n",
      "을 그 업무의 수행에 통상 필요한 시...\n",
      "\n",
      "문서 5: 한다.\n",
      " \n",
      "제21조(전차금 상계의 금지) 사용자는 전차금(前借金)이나 그 밖에 근로할 것을 조건으로 하는 전대(前貸)채권과 임금\n",
      "을 상계하지 못한다.\n",
      " \n",
      "제22조(강제 저금의 금지) ① 사용자는 근로계약에 덧붙여 강제 저축 또는 저축금의 관리를 규정하는 계약을 체결하지...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 기반 필터링 retriever\n",
    "filtered_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"filter\": {\n",
    "            \"source\": \"./data/labor_law.pdf\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "filtered_results = filtered_retriever.invoke(query)\n",
    "\n",
    "print(\"메타데이터 기반 필터링 결과:\")\n",
    "for i, doc in enumerate(filtered_results):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656541aa",
   "metadata": {},
   "source": [
    "#### 🔄 동적 검색 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739cbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicRetriever:\n",
    "    def __init__(self, vectorstore, embeddings):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.embeddings = embeddings\n",
    "    \n",
    "    def retrieve(self, query, search_type=\"auto\", k=5):\n",
    "        \"\"\"쿼리 특성에 따라 동적으로 검색 전략 선택\"\"\"\n",
    "        \n",
    "        # 쿼리 복잡도 분석\n",
    "        query_length = len(query.split())\n",
    "        \n",
    "        if query_length <= 3:\n",
    "            # 짧은 쿼리: 높은 임계값\n",
    "            search_type = \"similarity_score_threshold\"\n",
    "            search_kwargs = {\"score_threshold\": 0.25, \"k\": k}\n",
    "        elif query_length > 10:\n",
    "            # 긴 쿼리: MMR로 다양성 확보\n",
    "            search_type = \"mmr\"\n",
    "            search_kwargs = {\"k\": k, \"fetch_k\": k*3, \"lambda_mult\": 0.3}\n",
    "        else:\n",
    "            # 중간 길이: 기본 유사도 검색\n",
    "            search_type = \"similarity\"\n",
    "            search_kwargs = {\"k\": k}\n",
    "        \n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_type=search_type,\n",
    "            search_kwargs=search_kwargs\n",
    "        )\n",
    "        \n",
    "        return retriever.invoke(query)\n",
    "\n",
    "# 사용 예시\n",
    "dynamic_retriever = DynamicRetriever(chroma_db, embeddings)\n",
    "\n",
    "queries = [\n",
    "    \"탄력근로\",  # 짧은 쿼리\n",
    "    \"탄력 근로에 대해 설명해주세요\",  # 중간 쿼리\n",
    "    \"탄력 근로 제도의 장점과 단점, 그리고 실제 적용 사례를 포함하여 자세히 설명해주세요\"  # 긴 쿼리\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n쿼리: {query}\")\n",
    "    print(f\"길이: {len(query.split())} 단어\")\n",
    "    docs = dynamic_retriever.retrieve(query)\n",
    "    print(f\"검색 결과: {len(docs)}개 문서\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e667b",
   "metadata": {},
   "source": [
    "### 🎯 실습 5: 검색 전략 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 질문에 대해 다른 검색 전략들의 결과를 비교해보세요\n",
    "test_query = \"근로시간 단축에 대한 규정은 무엇인가요?\"\n",
    "\n",
    "strategies = {\n",
    "    \"similarity\": {\"k\": 5},\n",
    "    \"similarity_score_threshold\": {\"score_threshold\": 0.3, \"k\": 10},\n",
    "    \"mmr\": {\"k\": 5, \"fetch_k\": 15, \"lambda_mult\": 0.5}\n",
    "}\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5231bd3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RAG 체인 구현\n",
    "\n",
    "### 🎯 RAG 체인이란?\n",
    "검색(Retrieval)과 생성(Generation)을 연결하여 외부 지식을 기반으로 답변을 생성하는 파이프라인입니다.\n",
    "\n",
    "### 🔄 RAG 워크플로우\n",
    "```\n",
    "사용자 질문 → 관련 문서 검색 → 컨텍스트 구성 → LLM 프롬프트 → 답변 생성\n",
    "```\n",
    "\n",
    "### 1. 프롬프트 템플릿 설계\n",
    "\n",
    "#### 📝 기본 RAG 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "883b1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 기본 RAG 프롬프트 템플릿\n",
    "basic_template = \"\"\"주어진 컨텍스트를 기반으로 질문에 답변하세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "basic_prompt = ChatPromptTemplate.from_template(basic_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b3127",
   "metadata": {},
   "source": [
    "#### 🎨 고급 RAG 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39c836c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"당신은 전문적인 문서 분석 AI입니다. 주어진 **컨텍스트**를 바탕으로 사용자의 **질문**에 정확하고 유용한 답변을 제공하세요.\n",
    "\n",
    "## 답변 지침\n",
    "- 컨텍스트에 있는 정보만을 사용하여 답변하세요\n",
    "- 확실하지 않은 정보는 \"명확하지 않습니다\"라고 명시하세요\n",
    "- 답변은 논리적이고 구조화된 형태로 제공하세요\n",
    "- 가능한 경우 구체적인 예시나 수치를 포함하세요\n",
    "- 출처를 표시하세요\n",
    "\n",
    "## 답변 형식\n",
    "**핵심 답변:** (질문에 대한 직접적인 답변)\n",
    "\n",
    "**세부 설명:** (추가적인 설명이나 배경 정보)\n",
    "\n",
    "**관련 정보:** (컨텍스트에서 발견된 연관 정보)\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "## 컨텍스트\n",
    "{context}\n",
    "\n",
    "## 질문\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "advanced_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", user_prompt)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cdf3ac",
   "metadata": {},
   "source": [
    "#### 🌟 도메인별 특화 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_template = \"\"\"당신은 법률 문서 전문 AI입니다. 법률 조항을 정확히 해석하고 설명해주세요.\n",
    "\n",
    "## 법률 해석 원칙\n",
    "- 조문의 정확한 인용을 포함하세요\n",
    "- 법적 용어는 일반인이 이해할 수 있도록 설명하세요\n",
    "- 예외 조항이나 단서가 있다면 반드시 언급하세요\n",
    "- 관련 법령이나 시행령도 함께 언급하세요\n",
    "\n",
    "## 관련 법률 조항\n",
    "{context}\n",
    "\n",
    "## 법률 질의\n",
    "{question}\n",
    "\n",
    "## 법률 답변\n",
    "**해당 조항:** (관련 법률 조항 인용)\n",
    "\n",
    "**조항 해석:** (조항의 의미와 적용 범위)\n",
    "\n",
    "**주의사항:** (예외 조항이나 제한 사항)\n",
    "\n",
    "**답변:**\"\"\"\n",
    "\n",
    "legal_prompt = ChatPromptTemplate.from_template(legal_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2074b",
   "metadata": {},
   "source": [
    "### 2. LLM 설정\n",
    "\n",
    "#### 🤖 기본 모델 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "befd3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 프로덕션용 설정\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0.1,        # 일관성 있는 답변\n",
    "    max_tokens=1000,        # 답변 길이 제한\n",
    "    top_p=0.9,              # 다양성 제어\n",
    "    frequency_penalty=0.1,  # 반복 방지\n",
    "    presence_penalty=0.1    # 새로운 주제 장려\n",
    ")\n",
    "\n",
    "# 빠른 응답용 설정\n",
    "fast_llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=500    # 답변 길이 제한\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57167c",
   "metadata": {},
   "source": [
    "#### 🔧 모델별 최적 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1059563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확성 중시 (법률, 의료 등)\n",
    "precise_llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0,           # 가장 확실한 답변\n",
    "    top_p=0.1,              # 보수적인 선택\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "# 창의성 중시 (마케팅, 콘텐츠 등)\n",
    "creative_llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,        # 창의적 답변\n",
    "    top_p=0.95,            # 다양한 선택\n",
    "    frequency_penalty=0.2,\n",
    "    presence_penalty=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54638f88",
   "metadata": {},
   "source": [
    "### 3. RAG 체인 구성\n",
    "\n",
    "#### 🔗 기본 LCEL 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c379da04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**핵심 답변:**  \n",
      "탄력적 근로시간제(탄력 근로)는 일정 기간(2주~6개월) 동안 근로시간을 평균하여 법정 근로시간(주 40시간, 일 8시간)을 맞추는 제도입니다. 특정 주나 특정일에 법정 근로시간을 초과해 일할 수 있지만, 전체 단위기간의 평균이 기준을 넘지 않아야 합니다.\n",
      "\n",
      "**세부 설명:**  \n",
      "탄력적 근로시간제는 업무량이 특정 시기에 집중되는 경우 등, 근로시간을 유연하게 운영할 필요가 있을 때 활용됩니다.  \n",
      "- **3개월 이내 탄력적 근로시간제(제51조):**  \n",
      "  - 취업규칙 등에 따라 2주 이내의 일정 단위기간을 평균하여 1주 근로시간이 40시간을 넘지 않으면, 특정 주·일에 법정 근로시간을 초과해 근무할 수 있습니다.\n",
      "- **3개월 초과~6개월 이내 탄력적 근로시간제(제51조의2):**  \n",
      "  - 근로자대표와 서면 합의가 필요합니다.\n",
      "  - 단위기간(3~6개월) 동안 주 평균 40시간을 넘지 않아야 하며, 특정 주는 52시간, 특정 일은 12시간을 초과할 수 없습니다.\n",
      "  - 근로일 종료 후 다음 근로일 시작 전까지 연속 11시간 이상의 휴식시간을 보장해야 합니다(불가피한 경우 제외).\n",
      "\n",
      "**관련 정보:**  \n",
      "- 제50조: 1주 40시간, 1일 8시간 초과 불가(휴게시간 제외)\n",
      "- 제51조: 3개월 이내 탄력적 근로시간제\n",
      "- 제51조의2: 3~6개월 탄력적 근로시간제, 주 52시간/일 12시간 한도, 연속 11시간 휴식\n",
      "- 단위기간 내 평균이 기준을 넘지 않으면 특정 시기에 집중근무 가능\n",
      "\n",
      "**출처:**  \n",
      "- 근로기준법 제50조, 제51조, 제51조의2 (컨텍스트)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"문서 리스트를 문자열로 포맷\"\"\"\n",
    "    return \"\\n\\n\".join([\n",
    "        f\"{doc.page_content}\" \n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "\n",
    "# 기본 RAG 체인\n",
    "basic_rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | advanced_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "result = basic_rag_chain.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c118a3b",
   "metadata": {},
   "source": [
    "#### 🎯 고급 RAG 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7536552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: **핵심 답변:**  \n",
      "탄력적 근로시간제(탄력 근로)는 일정 기간(2주~6개월) 동안 근로시간을 평균하여 법정 근로시간(주 40시간, 일 8시간)을 초과하지 않는 범위 내에서, 특정한 날이나 주에 근로시간을 탄력적으로 조정할 수 있는 제도입니다. 3개월 이내와 3개월 초과 6개월 이내의 두 가지 유형이 있습니다.\n",
      "\n",
      "**세부 설명:**  \n",
      "1. **3개월 이내의 탄력적 근로시간제**  \n",
      "   - 취업규칙 등에서 정한 바에 따라 2주 이내의 일정 단위기간을 평균하여 1주 근로시간이 40시간(제50조제1항)을 넘지 않는 범위에서, 특정 주 또는 특정일에 법정 근로시간을 초과하여 근로할 수 있습니다.  \n",
      "   - (출처: 문서 1, p.7)\n",
      "\n",
      "2. **3개월을 초과하는 탄력적 근로시간제(최대 6개월)**  \n",
      "   - 근로자대표와의 서면 합의가 필요합니다.\n",
      "   - 3개월 초과 6개월 이내의 단위기간을 평균하여 1주 근로시간이 40시간을 넘지 않는 범위에서, 특정 주에는 최대 52시간, 특정일에는 최대 12시간까지 근로할 수 있습니다.\n",
      "   - 사용자는 근로일 종료 후 다음 근로일 개시 전까지 연속하여 11시간 이상의 휴식 시간을 부여해야 합니다(불가피한 경우 제외).\n",
      "   - (출처: 문서 2, p.8)\n",
      "\n",
      "**관련 정보:**  \n",
      "- 탄력적 근로시간제는 취업규칙 또는 근로자대표와의 서면 합의 등 일정한 절차를 거쳐야 하며, 단위기간·근로시간 등 구체적인 사항을 명확히 정해야 합니다.\n",
      "- 법정근로시간(주 40시간, 일 8시간)은 평균 기준이며, 특정 시기에 집중근무가 필요한 업종 등에 활용됩니다.\n",
      "- (출처: 문서 1, p.7; 문서 2, p.8)\n",
      "\n",
      "검색된 문서 수: 5\n",
      "평균 관련도: 0.7298\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "import json\n",
    "\n",
    "class AdvancedRAGChain:\n",
    "    def __init__(self, retriever, llm, prompt_template):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.prompt_template = prompt_template\n",
    "        \n",
    "    def format_docs_with_metadata(self, docs: List) -> str:\n",
    "        \"\"\"메타데이터를 포함한 문서 포맷팅\"\"\"\n",
    "        formatted_docs = []\n",
    "        for i, doc in enumerate(docs):\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            page = doc.metadata.get('page', 'N/A')\n",
    "            \n",
    "            formatted_doc = f\"\"\"\n",
    "[문서 {i+1}]\n",
    "출처: {source}\n",
    "페이지: {page}\n",
    "내용: {doc.page_content}\n",
    "\"\"\"\n",
    "            formatted_docs.append(formatted_doc)\n",
    "        \n",
    "        return \"\\n\".join(formatted_docs)\n",
    "    \n",
    "    def retrieve_with_scores(self, query: str, k: int = 5) -> tuple:\n",
    "        \"\"\"점수와 함께 문서 검색\"\"\"\n",
    "        docs_with_scores = self.retriever.vectorstore.similarity_search_with_score(query, k=k)\n",
    "        docs = [doc for doc, score in docs_with_scores]\n",
    "        scores = [score for doc, score in docs_with_scores]\n",
    "        return docs, scores\n",
    "    \n",
    "    def invoke(self, query: str) -> Dict:\n",
    "        \"\"\"향상된 RAG 실행\"\"\"\n",
    "        # 문서 검색\n",
    "        docs, scores = self.retrieve_with_scores(query)\n",
    "\n",
    "        # 일정 점수가 하한선 이하인 문서는 제외\n",
    "        if not docs:\n",
    "            return {\n",
    "                \"answer\": \"해당 쿼리에 대한 관련 문서를 찾을 수 없습니다.\",\n",
    "                \"source_documents\": [],\n",
    "                \"relevance_scores\": [],\n",
    "                \"context\": \"\"\n",
    "            }   \n",
    "        else:\n",
    "            # 점수가 낮은 문서 제외\n",
    "            docs = [doc for doc, score in zip(docs, scores) if score > 0.2]\n",
    "            scores = [score for score in scores if score > 0.2]\n",
    "        \n",
    "        # 컨텍스트 구성\n",
    "        context = self.format_docs_with_metadata(docs)\n",
    "        \n",
    "        # 프롬프트 구성 및 LLM 호출\n",
    "        prompt = self.prompt_template.format(context=context, question=query)\n",
    "        response = self.llm.invoke(prompt)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response.content,\n",
    "            \"source_documents\": docs,\n",
    "            \"relevance_scores\": scores,\n",
    "            \"context\": context\n",
    "        }\n",
    "\n",
    "# 고급 RAG 체인 사용\n",
    "advanced_rag = AdvancedRAGChain(retriever, llm, advanced_prompt)\n",
    "result = advanced_rag.invoke(\"탄력 근로에 대해 설명해주세요\")\n",
    "\n",
    "print(\"답변:\", result[\"answer\"])\n",
    "print(f\"\\n검색된 문서 수: {len(result['source_documents'])}\")\n",
    "print(f\"평균 관련도: {sum(result['relevance_scores'])/len(result['relevance_scores']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc6522",
   "metadata": {},
   "source": [
    "### 🎯 실습 6: 완전한 RAG 시스템 구축      ~ 17:50분까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac50b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실습 1\n",
    "\n",
    "\n",
    "# 다음 웹 페이지들을 로드하고 메타데이터를 출력해보세요\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/concepts/\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "web_loader = WebBaseLoader(web_paths=urls)\n",
    "web_docs = web_loader.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs)}\")\n",
    "print(f\"첫 번째 문서 메타데이터: {web_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b1459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686bb888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 요구사항을 만족하는 RAG 시스템을 구축해보세요:\n",
    "# 1. 여러 문서 형식 지원 (PDF, 웹, 텍스트)\n",
    "# 2. 동적 검색 전략 선택\n",
    "# 3. 도메인별 프롬프트 템플릿\n",
    "# 4. 응답 품질 평가\n",
    "\n",
    "class ComprehensiveRAGSystem:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_documents(self, sources):\n",
    "        \"\"\"다양한 소스에서 문서 로드\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "    \n",
    "    def setup_vector_store(self, documents):\n",
    "        \"\"\"벡터 저장소 구성\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "    \n",
    "    def query(self, question, domain=\"general\"):\n",
    "        \"\"\"도메인별 질의응답\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "\n",
    "# 여기에 구현 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647b5f0c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 문제 예시 답안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c661407",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실습 1\n",
    "\n",
    "\n",
    "# 다음 웹 페이지들을 로드하고 메타데이터를 출력해보세요\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/concepts/\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "web_loader = WebBaseLoader(web_paths=urls)\n",
    "web_docs = web_loader.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs)}\")\n",
    "print(f\"첫 번째 문서 메타데이터: {web_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ca86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실습 2\n",
    "\n",
    "# 다음 텍스트를 다양한 방법으로 분할하고 결과를 비교해보세요\n",
    "sample_text = \"\"\"\n",
    "인공지능은 현대 기술의 핵심입니다. \n",
    "머신러닝을 통해 컴퓨터는 학습할 수 있습니다.\n",
    "\n",
    "딥러닝은 신경망을 기반으로 합니다.\n",
    "자연어 처리는 텍스트를 이해하는 기술입니다.\n",
    "\n",
    "컴퓨터 비전은 이미지를 분석합니다.\n",
    "강화학습은 행동을 통해 학습합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "# 기본 문자 단위 분할기\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",  # 두 줄 단위로 분할\n",
    "    chunk_size=100,    # 청크 크기\n",
    "    chunk_overlap=20,  # 중복 크기\n",
    "    length_function=len,  # 길이 측정 함수\n",
    "    is_separator_regex=False  # 정규식 여부\n",
    ")\n",
    "# 텍스트 분할\n",
    "char_chunks = char_splitter.split_text(sample_text)\n",
    "print(f\"문자 단위 분할 결과: {len(char_chunks)} 청크\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실습 3\n",
    "\n",
    "# 다음 질문들에 대해 다른 임베딩 모델들의 검색 성능을 비교해보세요\n",
    "queries = [\n",
    "    \"기계학습이란 무엇인가요?\",\n",
    "    \"이미지 인식 기술에 대해 설명해주세요\",\n",
    "    \"언어 모델의 작동 원리는?\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "def compare_embedding_models(queries, doc_embeddings, documents, embeddings_models):\n",
    "    \"\"\"여러 임베딩 모델을 사용하여 쿼리와 문서 간 유사도 비교\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model in embeddings_models.items():\n",
    "        results[model_name] = []\n",
    "        for query in queries:\n",
    "            result = find_most_similar(query, doc_embeddings, documents, model)\n",
    "            results[model_name].append({\n",
    "                \"query\": query,\n",
    "                \"document\": result[\"document\"],\n",
    "                \"similarity\": result[\"similarity\"],\n",
    "                \"index\": result[\"index\"]\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 임베딩 모델들 정의\n",
    "embeddings_models = {\n",
    "    \"OpenAI\": embeddings_model,\n",
    "    \"BGE-M3\": embeddings_bge,\n",
    "    \"GTE\": embedding_gte,\n",
    "    \"Ollama\": embeddings_ollama\n",
    "}   \n",
    "\n",
    "# 모델 비교\n",
    "comparison_results = compare_embedding_models(queries, doc_embeddings, documents, embeddings_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2bc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실습 4\n",
    "\n",
    "# 1. 웹에서 문서 로드\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/concepts/\"\n",
    "]\n",
    "web_loader = WebBaseLoader(web_paths=urls)\n",
    "web_docs = web_loader.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs)}\")\n",
    "\n",
    "# 2. 적절한 크기로 분할\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(web_docs)\n",
    "print(f\"분할된 청크 수: {len(chunks)}\")\n",
    "\n",
    "# 3. 임베딩 및 저장\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"web_docs\",\n",
    "    persist_directory=\"./web_chroma_db\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}  # 유사도 메트릭\n",
    ")\n",
    "print(f\"저장된 문서 수: {chroma_db._collection.count()}\")\n",
    "\n",
    "# 4. 검색 테스트\n",
    "query = \"LangChain 튜토리얼에 대해 알려주세요\"\n",
    "similar_docs = chroma_db.similarity_search(\n",
    "    query=query,\n",
    "    k=5,  # 상위 5개 결과\n",
    ")\n",
    "print(f\"검색 결과 수: {len(similar_docs)}\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a35c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실습 5\n",
    "\n",
    "# 같은 질문에 대해 다른 검색 전략들의 결과를 비교해보세요\n",
    "test_query = \"근로시간 단축에 대한 규정은 무엇인가요?\"\n",
    "\n",
    "strategies = {\n",
    "    \"similarity\": {\"k\": 5},\n",
    "    \"similarity_score_threshold\": {\"score_threshold\": 0.3, \"k\": 10},\n",
    "    \"mmr\": {\"k\": 5, \"fetch_k\": 15, \"lambda_mult\": 0.5}\n",
    "}\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "for strategy, params in strategies.items():\n",
    "    print(f\"\\n검색 전략: {strategy}\")\n",
    "    retriever = chroma_db.as_retriever(\n",
    "        search_type=strategy,\n",
    "        search_kwargs=params\n",
    "    )\n",
    "    \n",
    "    results = retriever.invoke(test_query)\n",
    "    \n",
    "    print(f\"검색 결과 수: {len(results)}\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"문서 {i+1}: {doc.page_content[:100]}...\")\n",
    "        print(\"-\" * 40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실습 6\n",
    "\n",
    "\n",
    "# 다음 요구사항을 만족하는 RAG 시스템을 구축해보세요:\n",
    "# 1. 여러 문서 형식 지원 (PDF, 웹, 텍스트)\n",
    "# 2. 동적 검색 전략 선택\n",
    "# 3. 도메인별 프롬프트 템플릿\n",
    "# 4. 응답 품질 평가\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader, TextLoader\n",
    "\n",
    "class ComprehensiveRAGSystem:\n",
    "    def __init__(self):\n",
    "        \"\"\"RAG 시스템 초기화\"\"\"\n",
    "        self.documents = []\n",
    "        self.vector_store = None\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        self.retriever = None\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.1)\n",
    "    \n",
    "    def load_documents(self, sources):\n",
    "        \"\"\"다양한 소스에서 문서 로드\"\"\"\n",
    "        for source in sources:\n",
    "            if source.endswith('.pdf'):\n",
    "                loader = PyPDFLoader(source)\n",
    "            elif source.startswith('http'):\n",
    "                loader = WebBaseLoader(web_paths=[source])\n",
    "            else:\n",
    "                loader = TextLoader(source)\n",
    "            \n",
    "            docs = loader.load()\n",
    "            self.documents.extend(docs)\n",
    "    \n",
    "    def setup_vector_store(self, documents):\n",
    "        \"\"\"벡터 저장소 구성\"\"\"\n",
    "        self.vector_store = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=self.embeddings,\n",
    "            collection_name=\"rag_system\"\n",
    "        )\n",
    "    \n",
    "    def query(self, question, domain=\"legal\"):\n",
    "        \"\"\"도메인별 질의응답\"\"\"\n",
    "        self.retriever = self.vector_store.as_retriever()\n",
    "        context = self.retriever.invoke(question)\n",
    "\n",
    "        # 도메인별 프롬프트 템플릿 선택\n",
    "        if domain == \"legal\":\n",
    "            prompt_template = ChatPromptTemplate.from_template(\n",
    "                \"주어진 컨텍스트를 기반으로 법률가 관점에서 질문에 답변하세요.\\n\\n\"\n",
    "                \"컨텍스트:\\n{context}\\n\\n\"\n",
    "                \"질문: {question}\\n\\n\"\n",
    "                \"답변:\"\n",
    "            )\n",
    "        elif domain == \"technical\":\n",
    "            prompt_template = ChatPromptTemplate.from_template(\n",
    "                \"주어진 컨텍스트를 기반으로 기술 전문가 관점에서 질문에 답변하세요.\\n\\n\"\n",
    "                \"컨텍스트:\\n{context}\\n\\n\"\n",
    "                \"질문: {question}\\n\\n\"\n",
    "                \"답변:\"\n",
    "            )\n",
    "        else:\n",
    "            prompt_template = ChatPromptTemplate.from_template(\n",
    "                \"주어진 컨텍스트를 기반으로 질문에 답변하세요.\\n\\n\"\n",
    "                \"컨텍스트:\\n{context}\\n\\n\"\n",
    "                \"질문: {question}\\n\\n\"\n",
    "                \"답변:\"\n",
    "            )\n",
    "\n",
    "        # 프롬프트 구성 및 LLM 호출\n",
    "        prompt = prompt_template.format(context=context, question=question)\n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response\n",
    "\n",
    "# 사용 예시\n",
    "rag_system = ComprehensiveRAGSystem()\n",
    "rag_system.load_documents([\n",
    "    \"./data/labor_law.pdf\",\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/concepts/\"\n",
    "])\n",
    "rag_system.setup_vector_store(rag_system.documents)\n",
    "\n",
    "result = rag_system.query(\"탄력 근로에 대해 설명해주세요\", domain=\"legal\")\n",
    "print(\"답변:\", result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03fd6c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktds-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
